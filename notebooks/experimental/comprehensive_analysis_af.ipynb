{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comprehensive Model Analysis & Comparison\n",
    "**Notebook n√†y bao g·ªìm:**\n",
    "1. Feature Importance Analysis\n",
    "2. LIME - Local Interpretable Model-agnostic Explanations\n",
    "3. SHAP - SHapley Additive exPlanations\n",
    "4. Model Comparison (LightGBM, CatBoost, XGBoost, Ensemble)\n",
    "5. Stacking Ensemble v·ªõi Meta-Learner (Ridge Regression)\n",
    "6. Hyperparameter Optimization v·ªõi Optuna\n",
    "7. Complete Training Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from pathlib import Path\n",
    "import sys\n",
    "sys.path.append(str(Path.cwd().parent.parent))\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import catboost as cb\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import shap\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "from src.config import RANDOM_STATE\n",
    "from src.utils import set_seed\n",
    "from src.data_loader import load_and_prepare_data\n",
    "from src.features import prepare_features_for_modeling, FeatureEngineer\n",
    "from src.evaluation import calculate_metrics, print_metrics\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "set_seed(RANDOM_STATE)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feat = pd.read_csv('../../data/processed/train_final.csv')\n",
    "test_feat = pd.read_csv('../../data/processedtest_final.csv')\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_feat, valid_feat = train_test_split(train_feat, test_size=0.2, random_state=RANDOM_STATE)\n",
    "engineer = FeatureEngineer()\n",
    "feature_cols = engineer.get_feature_columns(train_feat)\n",
    "categorical_cols = [c for c in feature_cols if c in engineer.cat_cols]\n",
    "target_col = 'COMPLETION_RATE' \n",
    "X_train = train_feat[feature_cols].copy()\n",
    "y_train = train_feat[target_col]\n",
    "X_valid = valid_feat[feature_cols].copy()\n",
    "y_valid = valid_feat[target_col]\n",
    "X_test = test_feat[feature_cols].copy()\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "encoder = OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1)\n",
    "if categorical_cols:\n",
    "    X_train[categorical_cols] = encoder.fit_transform(X_train[categorical_cols].astype(str))\n",
    "    X_valid[categorical_cols] = encoder.transform(X_valid[categorical_cols].astype(str))\n",
    "    X_test[categorical_cols] = encoder.transform(X_test[categorical_cols].astype(str))\n",
    "valid_full_df = valid_feat\n",
    "test_full_df = test_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features already prepared from previous cell\n",
      "\n",
      " Features ready: 24 features\n",
      "  Categorical (encoded): 2\n",
      "  Numerical: 22\n",
      "\n",
      "Dtype check:\n",
      "float64    18\n",
      "int64       6\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Features already prepared from previous cell\")\n",
    "X_train_final = X_train.copy()\n",
    "X_valid_final = X_valid.copy()\n",
    "y_train_final = y_train.copy()\n",
    "y_valid_final = y_valid.copy()\n",
    "X_test_final  = X_test.copy() if X_test is not None else None\n",
    "valid_credits_dangky = valid_feat['TC_DANGKY'].values\n",
    "y_valid_credits = valid_feat['TC_HOANTHANH'].values\n",
    "print(f\"\\n Features ready: {X_train_final.shape[1]} features\")\n",
    "print(f\"  Categorical (encoded): {len(categorical_cols)}\")\n",
    "print(f\"  Numerical: {X_train_final.shape[1] - len(categorical_cols)}\")\n",
    "print(\"\\nDtype check:\")\n",
    "print(X_train_final.dtypes.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Feature importance analysis will be performed after model training\n"
     ]
    }
   ],
   "source": [
    "def plot_feature_importance_comparison(models_dict, feature_names, top_n=20):\n",
    "    \"\"\"\n",
    "    So s√°nh feature importance c·ªßa nhi·ªÅu models\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(20, 16))\n",
    "    axes = axes.ravel()\n",
    "    for idx, (name, model) in enumerate(models_dict.items()):\n",
    "        if hasattr(model, 'feature_importances_'):\n",
    "            importance = model.feature_importances_\n",
    "        else:\n",
    "            continue\n",
    "        imp_df = pd.DataFrame({\n",
    "            'feature': feature_names,\n",
    "            'importance': importance\n",
    "        }).sort_values('importance', ascending=False).head(top_n)\n",
    "        sns.barplot(data=imp_df, y='feature', x='importance', ax=axes[idx], palette='viridis')\n",
    "        axes[idx].set_title(f'{name} - Top {top_n} Features', fontsize=14, fontweight='bold')\n",
    "        axes[idx].set_xlabel('Importance', fontsize=12)\n",
    "        axes[idx].set_ylabel('')\n",
    "        axes[idx].grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('output/evaluation/feature_importance_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    return imp_df\n",
    "print(\" Feature importance analysis will be performed after model training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prepare Data for Different Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Data prepared for all model types\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "X_train_encoded = X_train.copy()\n",
    "X_valid_encoded = X_valid.copy()\n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    if col in X_train_encoded.columns:\n",
    "        le = LabelEncoder()\n",
    "        X_train_encoded[col] = le.fit_transform(X_train_encoded[col].astype(str))\n",
    "        X_valid_encoded[col] = le.transform(X_valid_encoded[col].astype(str))\n",
    "        label_encoders[col] = le\n",
    "X_train_xgb = X_train.copy()\n",
    "X_valid_xgb = X_valid.copy()\n",
    "for col in categorical_cols:\n",
    "    if col in X_train_xgb.columns:\n",
    "        X_train_xgb[col] = X_train_xgb[col].astype('category')\n",
    "        X_valid_xgb[col] = X_valid_xgb[col].astype('category')\n",
    "X_train_cb = X_train.copy()\n",
    "X_valid_cb = X_valid.copy()\n",
    "cat_features_idx = [X_train_cb.columns.get_loc(col) for col in categorical_cols if col in X_train_cb.columns]\n",
    "print(\" Data prepared for all model types\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Hyperparameter Optimization with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===  OPTUNA HYPERPARAMETER OPTIMIZATION ===\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n===  OPTUNA HYPERPARAMETER OPTIMIZATION ===\")\n",
    "Path('output/evaluation').mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 XGBoost Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-04 04:08:57,506]\u001b[0m A new study created in memory with name: no-name-5ee150e9-b8e2-4414-893e-34a0dc5b287e\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Optimizing XGBoost ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06b98319b92f484bb41a04002deec85d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\n--- Optimizing XGBoost ---\")\n",
    "cat_cols = X_train_xgb.select_dtypes(include=\"category\").columns\n",
    "\n",
    "for col in cat_cols:\n",
    "    X_train_xgb[col] = X_train_xgb[col].astype(int).astype(\"category\")\n",
    "    X_valid_xgb[col] = X_valid_xgb[col].astype(int).astype(\"category\")\n",
    "def objective_xgb(trial):\n",
    "    params = {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.005, 0.05),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.6, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.6, 1.0),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0.0, 10.0),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0.0, 10.0),\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 10),\n",
    "        \"n_estimators\": 2000,\n",
    "        \"objective\": \"reg:squarederror\",\n",
    "        \"n_jobs\": -1,\n",
    "        \"random_state\": 42,\n",
    "        \"enable_categorical\": True,\n",
    "        \"tree_method\": \"hist\"\n",
    "    }\n",
    "    model = xgb.XGBRegressor(**params)\n",
    "\n",
    "    model.fit(\n",
    "        X_train_xgb,\n",
    "        y_train,\n",
    "        eval_set=[(X_valid_xgb, y_valid)],\n",
    "        verbose=False\n",
    "    )\n",
    "    preds = model.predict(X_valid_xgb)\n",
    "    preds = np.clip(preds, 0, 1)\n",
    "\n",
    "    pred_credits = preds * valid_credits_dangky\n",
    "    rmse = np.sqrt(mean_squared_error(y_valid_credits, pred_credits))\n",
    "\n",
    "    return rmse\n",
    "study_xgb = optuna.create_study(\n",
    "    direction=\"minimize\",\n",
    "    sampler=TPESampler(seed=42)\n",
    ")\n",
    "\n",
    "study_xgb.optimize(\n",
    "    objective_xgb,\n",
    "    n_trials=100,\n",
    "    show_progress_bar=True\n",
    ")\n",
    "print(f\"Best XGBoost RMSE: {study_xgb.best_value:.4f}\")\n",
    "print(\"Best XGBoost Params:\")\n",
    "print(study_xgb.best_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 LightGBM Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-04 03:57:34,057]\u001b[0m A new study created in memory with name: no-name-12d2953c-9804-4dcd-b5c1-824caeb57bd1\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Optimizing LightGBM ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8a277d6e74c4ef897bff497436ceb6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-04 03:57:42,441]\u001b[0m Trial 0 finished with value: 3.670843387877848 and parameters: {'learning_rate': 0.021854305348131316, 'max_depth': 10, 'subsample': 0.892797576724562, 'feature_fraction': 0.8394633936788146, 'lambda_l1': 1.5601864044243652, 'lambda_l2': 1.5599452033620265, 'min_child_samples': 1}. Best is trial 0 with value: 3.670843387877848.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 03:57:46,134]\u001b[0m Trial 1 finished with value: 3.681975852524905 and parameters: {'learning_rate': 0.04397792655987209, 'max_depth': 7, 'subsample': 0.8832290311184181, 'feature_fraction': 0.608233797718321, 'lambda_l1': 9.699098521619943, 'lambda_l2': 8.324426408004218, 'min_child_samples': 3}. Best is trial 0 with value: 3.670843387877848.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 03:57:55,238]\u001b[0m Trial 2 finished with value: 3.7132684015506245 and parameters: {'learning_rate': 0.01318212352431953, 'max_depth': 4, 'subsample': 0.7216968971838151, 'feature_fraction': 0.8099025726528951, 'lambda_l1': 4.319450186421157, 'lambda_l2': 2.9122914019804194, 'min_child_samples': 7}. Best is trial 0 with value: 3.670843387877848.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 03:58:07,471]\u001b[0m Trial 3 finished with value: 3.6968218858988364 and parameters: {'learning_rate': 0.011277223729341883, 'max_depth': 5, 'subsample': 0.7465447373174767, 'feature_fraction': 0.7824279936868144, 'lambda_l1': 7.851759613930136, 'lambda_l2': 1.9967378215835974, 'min_child_samples': 6}. Best is trial 0 with value: 3.670843387877848.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 03:58:14,568]\u001b[0m Trial 4 finished with value: 3.7195903486882194 and parameters: {'learning_rate': 0.03165865559879191, 'max_depth': 3, 'subsample': 0.8430179407605753, 'feature_fraction': 0.6682096494749166, 'lambda_l1': 0.6505159298527952, 'lambda_l2': 9.488855372533333, 'min_child_samples': 10}. Best is trial 0 with value: 3.670843387877848.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 03:58:20,627]\u001b[0m Trial 5 finished with value: 3.6844652557657516 and parameters: {'learning_rate': 0.04137788066524075, 'max_depth': 5, 'subsample': 0.6390688456025535, 'feature_fraction': 0.8736932106048627, 'lambda_l1': 4.4015249373960135, 'lambda_l2': 1.2203823484477883, 'min_child_samples': 5}. Best is trial 0 with value: 3.670843387877848.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 03:58:33,405]\u001b[0m Trial 6 finished with value: 3.690740043246245 and parameters: {'learning_rate': 0.006547483450184828, 'max_depth': 10, 'subsample': 0.7035119926400067, 'feature_fraction': 0.8650089137415928, 'lambda_l1': 3.1171107608941098, 'lambda_l2': 5.200680211778108, 'min_child_samples': 6}. Best is trial 0 with value: 3.670843387877848.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 03:58:47,741]\u001b[0m Trial 7 finished with value: 3.682262982326712 and parameters: {'learning_rate': 0.013318450498648719, 'max_depth': 10, 'subsample': 0.9100531293444458, 'feature_fraction': 0.9757995766256756, 'lambda_l1': 8.948273504276488, 'lambda_l2': 5.978999788110851, 'min_child_samples': 10}. Best is trial 0 with value: 3.670843387877848.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 03:58:57,318]\u001b[0m Trial 8 finished with value: 3.728436969641359 and parameters: {'learning_rate': 0.008982162592336378, 'max_depth': 4, 'subsample': 0.6180909155642152, 'feature_fraction': 0.7301321323053057, 'lambda_l1': 3.8867728968948203, 'lambda_l2': 2.713490317738959, 'min_child_samples': 9}. Best is trial 0 with value: 3.670843387877848.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 03:59:08,044]\u001b[0m Trial 9 finished with value: 3.685184130154292 and parameters: {'learning_rate': 0.02105389970121152, 'max_depth': 5, 'subsample': 0.8170784332632994, 'feature_fraction': 0.6563696899899051, 'lambda_l1': 8.021969807540398, 'lambda_l2': 0.7455064367977082, 'min_child_samples': 10}. Best is trial 0 with value: 3.670843387877848.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 03:59:14,432]\u001b[0m Trial 10 finished with value: 3.682197901415951 and parameters: {'learning_rate': 0.028114851067799384, 'max_depth': 8, 'subsample': 0.9878148443151463, 'feature_fraction': 0.9729161367647149, 'lambda_l1': 0.15367737328104325, 'lambda_l2': 3.9804334222017683, 'min_child_samples': 1}. Best is trial 0 with value: 3.670843387877848.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 03:59:18,678]\u001b[0m Trial 11 finished with value: 3.672431407510694 and parameters: {'learning_rate': 0.04838879171557265, 'max_depth': 8, 'subsample': 0.8953622178900082, 'feature_fraction': 0.6062964611680564, 'lambda_l1': 6.174544729930211, 'lambda_l2': 7.98271706039643, 'min_child_samples': 1}. Best is trial 0 with value: 3.670843387877848.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 03:59:26,770]\u001b[0m Trial 12 finished with value: 3.6737996468134204 and parameters: {'learning_rate': 0.03840830510015067, 'max_depth': 8, 'subsample': 0.9592177900403767, 'feature_fraction': 0.8904427828213222, 'lambda_l1': 6.525898752936659, 'lambda_l2': 6.789480648985753, 'min_child_samples': 1}. Best is trial 0 with value: 3.670843387877848.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 03:59:33,643]\u001b[0m Trial 13 finished with value: 3.6651229683030166 and parameters: {'learning_rate': 0.0489075662462504, 'max_depth': 9, 'subsample': 0.9135976306648336, 'feature_fraction': 0.7515996911499221, 'lambda_l1': 2.3482669798365476, 'lambda_l2': 7.438375372588293, 'min_child_samples': 3}. Best is trial 13 with value: 3.6651229683030166.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 03:59:44,859]\u001b[0m Trial 14 finished with value: 3.667432127888027 and parameters: {'learning_rate': 0.0215047821778368, 'max_depth': 9, 'subsample': 0.9409660504218818, 'feature_fraction': 0.7556140425255179, 'lambda_l1': 2.0459697486015402, 'lambda_l2': 4.285476768652429, 'min_child_samples': 3}. Best is trial 13 with value: 3.6651229683030166.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 03:59:51,102]\u001b[0m Trial 15 finished with value: 3.668418801332915 and parameters: {'learning_rate': 0.03401031583706385, 'max_depth': 9, 'subsample': 0.9492344958198303, 'feature_fraction': 0.7694791890533237, 'lambda_l1': 2.15209606762166, 'lambda_l2': 4.2564353575109, 'min_child_samples': 3}. Best is trial 13 with value: 3.6651229683030166.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 04:00:03,694]\u001b[0m Trial 16 finished with value: 3.6701381991744477 and parameters: {'learning_rate': 0.021447035219836583, 'max_depth': 7, 'subsample': 0.7809305251510433, 'feature_fraction': 0.7061798774967332, 'lambda_l1': 2.8091319026250448, 'lambda_l2': 6.812027153973699, 'min_child_samples': 3}. Best is trial 13 with value: 3.6651229683030166.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 04:00:13,537]\u001b[0m Trial 17 finished with value: 3.670302015287792 and parameters: {'learning_rate': 0.017289791434225203, 'max_depth': 9, 'subsample': 0.9917702367090977, 'feature_fraction': 0.7288484340585257, 'lambda_l1': 1.4019001455047932, 'lambda_l2': 9.712720806331921, 'min_child_samples': 4}. Best is trial 13 with value: 3.6651229683030166.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 04:00:17,654]\u001b[0m Trial 18 finished with value: 3.6735866945565503 and parameters: {'learning_rate': 0.04886651708865862, 'max_depth': 9, 'subsample': 0.8517314664119261, 'feature_fraction': 0.7583344034261105, 'lambda_l1': 3.097007797167165, 'lambda_l2': 7.702510210140549, 'min_child_samples': 4}. Best is trial 13 with value: 3.6651229683030166.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 04:00:27,217]\u001b[0m Trial 19 finished with value: 3.679810295968631 and parameters: {'learning_rate': 0.02574588717696944, 'max_depth': 6, 'subsample': 0.9363623384900699, 'feature_fraction': 0.6807171468064964, 'lambda_l1': 5.6456923184747385, 'lambda_l2': 5.087850346069933, 'min_child_samples': 2}. Best is trial 13 with value: 3.6651229683030166.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 04:00:33,642]\u001b[0m Trial 20 finished with value: 3.672299039963195 and parameters: {'learning_rate': 0.033219517128336096, 'max_depth': 9, 'subsample': 0.7866515214377883, 'feature_fraction': 0.9183471047574291, 'lambda_l1': 1.1583465233856705, 'lambda_l2': 3.5670396970807094, 'min_child_samples': 4}. Best is trial 13 with value: 3.6651229683030166.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 04:00:39,453]\u001b[0m Trial 21 finished with value: 3.6667295438497582 and parameters: {'learning_rate': 0.036900555074168014, 'max_depth': 9, 'subsample': 0.9500588602845759, 'feature_fraction': 0.7938036465254895, 'lambda_l1': 2.0537600060377983, 'lambda_l2': 4.290279013500598, 'min_child_samples': 3}. Best is trial 13 with value: 3.6651229683030166.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 04:00:44,171]\u001b[0m Trial 22 finished with value: 3.670590296869183 and parameters: {'learning_rate': 0.039232482403266204, 'max_depth': 8, 'subsample': 0.9303601830288182, 'feature_fraction': 0.8111577236211219, 'lambda_l1': 2.1839820816049493, 'lambda_l2': 5.870313094306413, 'min_child_samples': 2}. Best is trial 13 with value: 3.6651229683030166.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 04:00:49,529]\u001b[0m Trial 23 finished with value: 3.666962478195166 and parameters: {'learning_rate': 0.044827525119797276, 'max_depth': 10, 'subsample': 0.9646783246633943, 'feature_fraction': 0.7499974247598126, 'lambda_l1': 2.400784928737373, 'lambda_l2': 4.204170866110897, 'min_child_samples': 5}. Best is trial 13 with value: 3.6651229683030166.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 04:00:54,209]\u001b[0m Trial 24 finished with value: 3.6677090801845327 and parameters: {'learning_rate': 0.04517748479479154, 'max_depth': 10, 'subsample': 0.9800692918392917, 'feature_fraction': 0.8274053419415468, 'lambda_l1': 3.5833223893692816, 'lambda_l2': 0.04524458886034566, 'min_child_samples': 8}. Best is trial 13 with value: 3.6651229683030166.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 04:00:58,927]\u001b[0m Trial 25 finished with value: 3.6739574256580707 and parameters: {'learning_rate': 0.03708396768794737, 'max_depth': 10, 'subsample': 0.8617978052052571, 'feature_fraction': 0.7185994132758311, 'lambda_l1': 5.161301248935951, 'lambda_l2': 3.104979439839574, 'min_child_samples': 5}. Best is trial 13 with value: 3.6651229683030166.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 04:01:02,523]\u001b[0m Trial 26 finished with value: 3.674048088312546 and parameters: {'learning_rate': 0.045465224770985455, 'max_depth': 7, 'subsample': 0.9628196337088033, 'feature_fraction': 0.7822056704194154, 'lambda_l1': 0.3193571243524458, 'lambda_l2': 6.153072250624987, 'min_child_samples': 5}. Best is trial 13 with value: 3.6651229683030166.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 04:01:06,976]\u001b[0m Trial 27 finished with value: 3.671223125771918 and parameters: {'learning_rate': 0.049895701721540286, 'max_depth': 9, 'subsample': 0.9119801050744422, 'feature_fraction': 0.6917452580888157, 'lambda_l1': 1.1033259901056314, 'lambda_l2': 4.656048361232713, 'min_child_samples': 2}. Best is trial 13 with value: 3.6651229683030166.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 04:01:11,791]\u001b[0m Trial 28 finished with value: 3.671921867490861 and parameters: {'learning_rate': 0.04217215726737743, 'max_depth': 8, 'subsample': 0.8213072318507065, 'feature_fraction': 0.7486227209707546, 'lambda_l1': 2.6543844343463983, 'lambda_l2': 7.162330641997612, 'min_child_samples': 7}. Best is trial 13 with value: 3.6651229683030166.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 04:01:18,139]\u001b[0m Trial 29 finished with value: 3.663929559900427 and parameters: {'learning_rate': 0.036051088156784025, 'max_depth': 10, 'subsample': 0.9995771940264574, 'feature_fraction': 0.639405821062781, 'lambda_l1': 1.8656371491129793, 'lambda_l2': 8.871698766914264, 'min_child_samples': 4}. Best is trial 29 with value: 3.663929559900427.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 04:01:25,907]\u001b[0m Trial 30 finished with value: 3.665760185392755 and parameters: {'learning_rate': 0.028826676027377728, 'max_depth': 10, 'subsample': 0.9908205095365941, 'feature_fraction': 0.6280148270273732, 'lambda_l1': 0.9463293039602205, 'lambda_l2': 8.435856802534596, 'min_child_samples': 4}. Best is trial 29 with value: 3.663929559900427.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 04:01:33,957]\u001b[0m Trial 31 finished with value: 3.6670024694806984 and parameters: {'learning_rate': 0.029026210278905885, 'max_depth': 10, 'subsample': 0.996391065514728, 'feature_fraction': 0.6413607644703521, 'lambda_l1': 1.7008849216127602, 'lambda_l2': 8.77477486925607, 'min_child_samples': 4}. Best is trial 29 with value: 3.663929559900427.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 04:01:38,804]\u001b[0m Trial 32 finished with value: 3.6690920133472344 and parameters: {'learning_rate': 0.035756060312526115, 'max_depth': 10, 'subsample': 0.8777718346547334, 'feature_fraction': 0.630973552724562, 'lambda_l1': 0.6781449479426264, 'lambda_l2': 8.799025118174708, 'min_child_samples': 3}. Best is trial 29 with value: 3.663929559900427.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 04:01:50,437]\u001b[0m Trial 33 finished with value: 3.665596144199346 and parameters: {'learning_rate': 0.02540614521107418, 'max_depth': 9, 'subsample': 0.9183892878185055, 'feature_fraction': 0.6306130911255259, 'lambda_l1': 1.6513367378593902, 'lambda_l2': 8.966495673808112, 'min_child_samples': 4}. Best is trial 29 with value: 3.663929559900427.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 04:02:02,214]\u001b[0m Trial 34 finished with value: 3.664464263395563 and parameters: {'learning_rate': 0.024939631526684002, 'max_depth': 10, 'subsample': 0.9183420885727315, 'feature_fraction': 0.6176710995390509, 'lambda_l1': 1.4117883096987196, 'lambda_l2': 8.988899007900779, 'min_child_samples': 4}. Best is trial 29 with value: 3.663929559900427.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 04:02:30,328]\u001b[0m Trial 35 finished with value: 3.671319472618586 and parameters: {'learning_rate': 0.017067380982998488, 'max_depth': 9, 'subsample': 0.9093716412767583, 'feature_fraction': 0.6041393755876386, 'lambda_l1': 0.07063578405737991, 'lambda_l2': 9.323159548964753, 'min_child_samples': 6}. Best is trial 29 with value: 3.663929559900427.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 04:02:42,847]\u001b[0m Trial 36 finished with value: 3.6744585930914124 and parameters: {'learning_rate': 0.02351206041732697, 'max_depth': 6, 'subsample': 0.8792320564502485, 'feature_fraction': 0.6635495129562176, 'lambda_l1': 1.5550762568762295, 'lambda_l2': 9.104744455324628, 'min_child_samples': 2}. Best is trial 29 with value: 3.663929559900427.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 04:02:52,124]\u001b[0m Trial 37 finished with value: 3.67213206515942 and parameters: {'learning_rate': 0.025130393559174048, 'max_depth': 8, 'subsample': 0.9214689772507048, 'feature_fraction': 0.6452960965002609, 'lambda_l1': 3.553872142362664, 'lambda_l2': 9.982835861660028, 'min_child_samples': 5}. Best is trial 29 with value: 3.663929559900427.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 04:03:19,681]\u001b[0m Trial 38 finished with value: 3.6682241912312574 and parameters: {'learning_rate': 0.018361567675556793, 'max_depth': 10, 'subsample': 0.8311743160057392, 'feature_fraction': 0.6852212686797511, 'lambda_l1': 4.402399363816463, 'lambda_l2': 7.552780822316743, 'min_child_samples': 6}. Best is trial 29 with value: 3.663929559900427.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 04:04:21,141]\u001b[0m Trial 39 finished with value: 3.7195525027112994 and parameters: {'learning_rate': 0.031040636059073555, 'max_depth': 3, 'subsample': 0.7243788131741488, 'feature_fraction': 0.621626267923875, 'lambda_l1': 3.1670088315361893, 'lambda_l2': 8.407015551038203, 'min_child_samples': 4}. Best is trial 29 with value: 3.663929559900427.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 04:04:49,609]\u001b[0m Trial 40 finished with value: 3.6680893374526415 and parameters: {'learning_rate': 0.02565481522984426, 'max_depth': 7, 'subsample': 0.8976493233180726, 'feature_fraction': 0.6585604181548562, 'lambda_l1': 0.7024416835107101, 'lambda_l2': 7.989659779784503, 'min_child_samples': 7}. Best is trial 29 with value: 3.663929559900427.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 04:05:02,474]\u001b[0m Trial 41 finished with value: 3.6649789356859968 and parameters: {'learning_rate': 0.029249562888196252, 'max_depth': 10, 'subsample': 0.9762333672911824, 'feature_fraction': 0.6270133804450526, 'lambda_l1': 0.8454187183315277, 'lambda_l2': 8.417368391107672, 'min_child_samples': 4}. Best is trial 29 with value: 3.663929559900427.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 04:05:09,532]\u001b[0m Trial 42 finished with value: 3.6663843750077794 and parameters: {'learning_rate': 0.031276342542585336, 'max_depth': 10, 'subsample': 0.975306884914546, 'feature_fraction': 0.6193934423780236, 'lambda_l1': 1.615810932176403, 'lambda_l2': 9.172678571705958, 'min_child_samples': 3}. Best is trial 29 with value: 3.663929559900427.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 04:05:19,221]\u001b[0m Trial 43 finished with value: 3.6638058740223562 and parameters: {'learning_rate': 0.023638940752612036, 'max_depth': 9, 'subsample': 0.8652231531275829, 'feature_fraction': 0.6481371991480913, 'lambda_l1': 1.7629904619179366, 'lambda_l2': 8.803973112221515, 'min_child_samples': 4}. Best is trial 43 with value: 3.6638058740223562.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 04:05:29,981]\u001b[0m Trial 44 finished with value: 3.6758965679108386 and parameters: {'learning_rate': 0.019824745697504392, 'max_depth': 10, 'subsample': 0.874371694973418, 'feature_fraction': 0.6023206680100046, 'lambda_l1': 9.986409325592858, 'lambda_l2': 8.162234241856119, 'min_child_samples': 5}. Best is trial 43 with value: 3.6638058740223562.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 04:05:43,251]\u001b[0m Trial 45 finished with value: 3.6712234852239005 and parameters: {'learning_rate': 0.014028490087070536, 'max_depth': 9, 'subsample': 0.8950721288565732, 'feature_fraction': 0.7034648806909332, 'lambda_l1': 2.684769928647432, 'lambda_l2': 7.104968897323846, 'min_child_samples': 3}. Best is trial 43 with value: 3.6638058740223562.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 04:05:55,928]\u001b[0m Trial 46 finished with value: 3.6683570170609667 and parameters: {'learning_rate': 0.041308621967921365, 'max_depth': 10, 'subsample': 0.9689520678616279, 'feature_fraction': 0.6706454700946517, 'lambda_l1': 0.5743755146497709, 'lambda_l2': 9.651188472000483, 'min_child_samples': 4}. Best is trial 43 with value: 3.6638058740223562.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 04:06:06,646]\u001b[0m Trial 47 finished with value: 3.6705104370733923 and parameters: {'learning_rate': 0.027434295873428906, 'max_depth': 9, 'subsample': 0.6514288280341656, 'feature_fraction': 0.6479042040185756, 'lambda_l1': 1.1630339672879162, 'lambda_l2': 7.635965643460107, 'min_child_samples': 2}. Best is trial 43 with value: 3.6638058740223562.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 04:06:16,870]\u001b[0m Trial 48 finished with value: 3.6690962126837996 and parameters: {'learning_rate': 0.023895814682982432, 'max_depth': 8, 'subsample': 0.9341601626642814, 'feature_fraction': 0.6710559300757173, 'lambda_l1': 4.124793902675544, 'lambda_l2': 8.549115750228166, 'min_child_samples': 5}. Best is trial 43 with value: 3.6638058740223562.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 04:06:25,602]\u001b[0m Trial 49 finished with value: 3.666842741216701 and parameters: {'learning_rate': 0.032410324230082194, 'max_depth': 10, 'subsample': 0.9564685533356921, 'feature_fraction': 0.702188044568451, 'lambda_l1': 1.8925140816179753, 'lambda_l2': 9.83796081829032, 'min_child_samples': 4}. Best is trial 43 with value: 3.6638058740223562.\u001b[0m\n",
      "Best LightGBM RMSE: 3.6638\n",
      "Best LightGBM Params: {'learning_rate': 0.023638940752612036, 'max_depth': 9, 'subsample': 0.8652231531275829, 'feature_fraction': 0.6481371991480913, 'lambda_l1': 1.7629904619179366, 'lambda_l2': 8.803973112221515, 'min_child_samples': 4}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Optimizing LightGBM ---\")\n",
    "def objective_lgb(trial):\n",
    "    params = {\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.05),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'feature_fraction': trial.suggest_float('feature_fraction', 0.6, 1.0),\n",
    "        'lambda_l1': trial.suggest_float('lambda_l1', 0, 10),\n",
    "        'lambda_l2': trial.suggest_float('lambda_l2', 0, 10),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 1, 10),\n",
    "        'n_estimators': 2000,\n",
    "        'objective': 'regression',\n",
    "        'random_state': 42,\n",
    "        'n_jobs': -1,\n",
    "        'verbosity': -1\n",
    "    }\n",
    "    model = lgb.LGBMRegressor(**params)\n",
    "    model.fit(\n",
    "        X_train_encoded, y_train,\n",
    "        eval_set=[(X_valid_encoded, y_valid)],\n",
    "        callbacks=[lgb.early_stopping(100, verbose=False)]\n",
    "    )\n",
    "    preds = model.predict(X_valid_encoded)\n",
    "    preds_clipped = np.clip(preds, 0, 1)\n",
    "    pred_credits = preds_clipped * valid_credits_dangky\n",
    "    rmse = np.sqrt(mean_squared_error(y_valid_credits, pred_credits))\n",
    "    return rmse\n",
    "\n",
    "study_lgb = optuna.create_study(direction='minimize', sampler=TPESampler(seed=42))\n",
    "study_lgb.optimize(objective_lgb, n_trials=50, show_progress_bar=True)\n",
    "print(f\"Best LightGBM RMSE: {study_lgb.best_value:.4f}\")\n",
    "print(f\"Best LightGBM Params: {study_lgb.best_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 CatBoost Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Optimizing CatBoost ---\")\n",
    "def objective_cb(trial):\n",
    "    params = {\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.05),\n",
    "        'depth': trial.suggest_int('depth', 3, 10),\n",
    "        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1, 10),\n",
    "        'random_strength': trial.suggest_float('random_strength', 0.5, 5.0),\n",
    "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 1, 20),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'rsm': trial.suggest_float('rsm', 0.6, 1.0),\n",
    "        'iterations': 2000,\n",
    "        'loss_function': 'RMSE',\n",
    "        'random_seed': 42,\n",
    "        'thread_count': -1,\n",
    "        'verbose': False,\n",
    "        'bootstrap_type': 'Bernoulli',\n",
    "        'cat_features': cat_features_idx if cat_features_idx else None\n",
    "    }\n",
    "    model = CatBoostRegressor(**params)\n",
    "    model.fit(\n",
    "        X_train_cb, y_train,\n",
    "        eval_set=(X_valid_cb, y_valid),\n",
    "        early_stopping_rounds=100,\n",
    "        verbose=False\n",
    "    )\n",
    "    preds = model.predict(X_valid_cb)\n",
    "    preds_clipped = np.clip(preds, 0, 1)\n",
    "    pred_credits = preds_clipped * valid_credits_dangky\n",
    "    rmse = np.sqrt(mean_squared_error(y_valid_credits, pred_credits))\n",
    "    return rmse\n",
    "\n",
    "study_cb = optuna.create_study(direction='minimize', sampler=TPESampler(seed=42))\n",
    "study_cb.optimize(objective_cb, n_trials=50, show_progress_bar=True)\n",
    "print(f\"Best CatBoost RMSE: {study_cb.best_value:.4f}\")\n",
    "print(f\"Best CatBoost Params: {study_cb.best_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Plot Optuna Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
    "studies = [study_xgb, study_lgb, study_cb]\n",
    "names = ['XGBoost', 'LightGBM', 'CatBoost']\n",
    "for idx, (study, name) in enumerate(zip(studies, names)):\n",
    "    trials_df = study.trials_dataframe()\n",
    "    axes[idx].plot(trials_df['number'], trials_df['value'], marker='o', alpha=0.6)\n",
    "    axes[idx].axhline(y=study.best_value, color='r', linestyle='--', label=f'Best: {study.best_value:.4f}')\n",
    "    axes[idx].set_xlabel('Trial', fontsize=12)\n",
    "    axes[idx].set_ylabel('RMSE', fontsize=12)\n",
    "    axes[idx].set_title(f'{name} Optimization History', fontsize=14, fontweight='bold')\n",
    "    axes[idx].legend()\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('output/evaluation/optuna_optimization_history.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"\\n Optuna optimization complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train Final Models with Best Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== TRAINING FINAL MODELS WITH BEST PARAMETERS ===\")\n",
    "models = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Train XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Training XGBoost with best params ---\")\n",
    "best_xgb_params = study_xgb.best_params.copy()\n",
    "best_xgb_params.update({\n",
    "    'n_estimators': 2000,\n",
    "    'objective': 'reg:squarederror',\n",
    "    'n_jobs': -1,\n",
    "    'random_state': 42,\n",
    "    'enable_categorical': True,\n",
    "    'tree_method': 'hist'\n",
    "})\n",
    "model_xgb = xgb.XGBRegressor(**best_xgb_params)\n",
    "model_xgb.fit(\n",
    "    X_train_xgb, y_train,\n",
    "    eval_set=[(X_valid_xgb, y_valid)],\n",
    "    verbose=False\n",
    ")\n",
    "models['XGBoost'] = model_xgb\n",
    "print(\" XGBoost trained\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Train LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Training LightGBM with best params ---\")\n",
    "best_lgb_params = study_lgb.best_params.copy()\n",
    "best_lgb_params.update({\n",
    "    'n_estimators': 2000,\n",
    "    'objective': 'regression',\n",
    "    'random_state': 42,\n",
    "    'n_jobs': -1,\n",
    "    'verbosity': -1\n",
    "})\n",
    "model_lgb = lgb.LGBMRegressor(**best_lgb_params)\n",
    "model_lgb.fit(\n",
    "    X_train_encoded, y_train,\n",
    "    eval_set=[(X_valid_encoded, y_valid)],\n",
    "    callbacks=[lgb.early_stopping(100, verbose=False)]\n",
    ")\n",
    "models['LightGBM'] = model_lgb\n",
    "print(\" LightGBM trained\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Train CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Training CatBoost with best params ---\")\n",
    "best_cb_params = study_cb.best_params.copy()\n",
    "best_cb_params.update({\n",
    "    'iterations': 2000,\n",
    "    'loss_function': 'RMSE',\n",
    "    'random_seed': 42,\n",
    "    'thread_count': -1,\n",
    "    'verbose': False,\n",
    "    'bootstrap_type': 'Bernoulli',\n",
    "    'cat_features': cat_features_idx if cat_features_idx else None\n",
    "})\n",
    "model_cb = CatBoostRegressor(**best_cb_params)\n",
    "model_cb.fit(\n",
    "    X_train_cb, y_train,\n",
    "    eval_set=(X_valid_cb, y_valid),\n",
    "    early_stopping_rounds=100,\n",
    "    verbose=False\n",
    ")\n",
    "models['CatBoost'] = model_cb\n",
    "print(\" CatBoost trained\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Evaluation & Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== MODEL EVALUATION ===\")\n",
    "results = []\n",
    "predictions_dict = {}\n",
    "\n",
    "# XGBoost\n",
    "pred_xgb = model_xgb.predict(X_valid_xgb)\n",
    "pred_xgb_clipped = np.clip(pred_xgb, 0, 1)\n",
    "pred_xgb_credits = pred_xgb_clipped * valid_credits_dangky\n",
    "predictions_dict['XGBoost'] = pred_xgb_credits\n",
    "\n",
    "rmse_xgb = np.sqrt(mean_squared_error(y_valid_credits, pred_xgb_credits))\n",
    "mae_xgb = mean_absolute_error(y_valid_credits, pred_xgb_credits)\n",
    "r2_xgb = r2_score(y_valid_credits, pred_xgb_credits)\n",
    "acc_xgb = (np.abs(pred_xgb_credits - y_valid_credits) <= 0.5).mean() * 100\n",
    "\n",
    "results.append({\n",
    "    'Model': 'XGBoost',\n",
    "    'RMSE': rmse_xgb,\n",
    "    'MAE': mae_xgb,\n",
    "    'R2': r2_xgb,\n",
    "    'Accuracy': acc_xgb\n",
    "})\n",
    "\n",
    "# LightGBM\n",
    "pred_lgb = model_lgb.predict(X_valid_encoded)\n",
    "pred_lgb_clipped = np.clip(pred_lgb, 0, 1)\n",
    "pred_lgb_credits = pred_lgb_clipped * valid_credits_dangky\n",
    "predictions_dict['LightGBM'] = pred_lgb_credits\n",
    "\n",
    "rmse_lgb = np.sqrt(mean_squared_error(y_valid_credits, pred_lgb_credits))\n",
    "mae_lgb = mean_absolute_error(y_valid_credits, pred_lgb_credits)\n",
    "r2_lgb = r2_score(y_valid_credits, pred_lgb_credits)\n",
    "acc_lgb = (np.abs(pred_lgb_credits - y_valid_credits) <= 0.5).mean() * 100\n",
    "\n",
    "results.append({\n",
    "    'Model': 'LightGBM',\n",
    "    'RMSE': rmse_lgb,\n",
    "    'MAE': mae_lgb,\n",
    "    'R2': r2_lgb,\n",
    "    'Accuracy': acc_lgb\n",
    "})\n",
    "\n",
    "# CatBoost\n",
    "pred_cb = model_cb.predict(X_valid_cb)\n",
    "pred_cb_clipped = np.clip(pred_cb, 0, 1)\n",
    "pred_cb_credits = pred_cb_clipped * valid_credits_dangky\n",
    "predictions_dict['CatBoost'] = pred_cb_credits\n",
    "\n",
    "rmse_cb = np.sqrt(mean_squared_error(y_valid_credits, pred_cb_credits))\n",
    "mae_cb = mean_absolute_error(y_valid_credits, pred_cb_credits)\n",
    "r2_cb = r2_score(y_valid_credits, pred_cb_credits)\n",
    "acc_cb = (np.abs(pred_cb_credits - y_valid_credits) <= 0.5).mean() * 100\n",
    "\n",
    "results.append({\n",
    "    'Model': 'CatBoost',\n",
    "    'RMSE': rmse_cb,\n",
    "    'MAE': mae_cb,\n",
    "    'R2': r2_cb,\n",
    "    'Accuracy': acc_cb\n",
    "})\n",
    "\n",
    "# Simple Ensemble (Average)\n",
    "pred_ensemble = (pred_xgb_credits + pred_lgb_credits + pred_cb_credits) / 3\n",
    "predictions_dict['Simple Ensemble'] = pred_ensemble\n",
    "\n",
    "rmse_ensemble = np.sqrt(mean_squared_error(y_valid_credits, pred_ensemble))\n",
    "mae_ensemble = mean_absolute_error(y_valid_credits, pred_ensemble)\n",
    "r2_ensemble = r2_score(y_valid_credits, pred_ensemble)\n",
    "acc_ensemble = (np.abs(pred_ensemble - y_valid_credits) <= 0.5).mean() * 100\n",
    "\n",
    "results.append({\n",
    "    'Model': 'Simple Ensemble',\n",
    "    'RMSE': rmse_ensemble,\n",
    "    'MAE': mae_ensemble,\n",
    "    'R2': r2_ensemble,\n",
    "    'Accuracy': acc_ensemble\n",
    "})\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values('RMSE')\n",
    "print(\"\\n\" + results_df.to_string(index=False))\n",
    "results_df.to_csv('output/evaluation/model_comparison_results.csv', index=False)\n",
    "print(\"\\n‚úÖ Results saved to output/evaluation/model_comparison_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualization - Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "metrics = ['RMSE', 'MAE', 'R2', 'Accuracy']\n",
    "for idx, metric in enumerate(metrics):\n",
    "    ax = axes[idx // 2, idx % 2]\n",
    "    sns.barplot(data=results_df, x='Model', y=metric, ax=ax, palette='viridis')\n",
    "    ax.set_title(f'Model Comparison - {metric}', fontsize=14, fontweight='bold')\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_ylabel(metric, fontsize=12)\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    for container in ax.containers:\n",
    "        ax.bar_label(container, fmt='%.4f' if metric != 'Accuracy' else '%.2f%%', fontsize=9)\n",
    "plt.tight_layout()\n",
    "plt.savefig('output/evaluation/model_comparison_charts.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Feature Importance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== FEATURE IMPORTANCE ANALYSIS ===\")\n",
    "feature_names = X_train_encoded.columns.tolist()\n",
    "models_for_fi = {\n",
    "    'XGBoost': model_xgb,\n",
    "    'LightGBM': model_lgb,\n",
    "    'CatBoost': model_cb\n",
    "}\n",
    "imp_df = plot_feature_importance_comparison(models_for_fi, feature_names, top_n=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. SHAP Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== üîç SHAP ANALYSIS ===\")\n",
    "print(\"Using LightGBM for SHAP analysis...\")\n",
    "explainer = shap.TreeExplainer(model_lgb)\n",
    "shap_values = explainer.shap_values(X_valid_encoded[:1000])\n",
    "print(\" SHAP values calculated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "shap.summary_plot(shap_values, X_valid_encoded[:1000], show=False)\n",
    "plt.tight_layout()\n",
    "plt.savefig('output/evaluation/shap_summary_plot.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\" SHAP summary plot saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "shap.summary_plot(shap_values, X_valid_encoded[:1000], plot_type=\"bar\", show=False)\n",
    "plt.tight_layout()\n",
    "plt.savefig('output/evaluation/shap_feature_importance.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\" SHAP feature importance saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. LIME Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== LIME ANALYSIS ===\")\n",
    "explainer_lime = lime.lime_tabular.LimeTabularExplainer(\n",
    "    X_train_encoded.values,\n",
    "    feature_names=feature_names,\n",
    "    mode='regression',\n",
    "    random_state=42\n",
    ")\n",
    "pred_errors = np.abs(predictions_dict['LightGBM'] - y_valid_credits)\n",
    "best_idx = pred_errors.argmin()\n",
    "worst_idx = pred_errors.argmax()\n",
    "median_idx = np.argsort(pred_errors)[len(pred_errors)//2]\n",
    "cases = {\n",
    "    'best': best_idx,\n",
    "    'worst': worst_idx,\n",
    "    'median': median_idx\n",
    "}\n",
    "for case_name, idx in cases.items():\n",
    "    exp = explainer_lime.explain_instance(\n",
    "        X_valid_encoded.iloc[idx].values,\n",
    "        model_lgb.predict,\n",
    "        num_features=10\n",
    "    )\n",
    "    fig = exp.as_pyplot_figure()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'output/evaluation/lime_explanation_{case_name}.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    exp.save_to_file(f'output/evaluation/lime_explanation_{case_name}.html')\n",
    "    print(f\" LIME {case_name} case saved\")\n",
    "print(\"\\n LIME analysis complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Final Comparison & Best Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== FINAL MODEL SELECTION ===\")\n",
    "final_results_df = results_df.copy()\n",
    "best_model_name = final_results_df.iloc[0]['Model']\n",
    "print(f\"\\n Best Model: {best_model_name}\")\n",
    "print(f\"   RMSE: {final_results_df.iloc[0]['RMSE']:.4f}\")\n",
    "print(f\"   MAE:  {final_results_df.iloc[0]['MAE']:.4f}\")\n",
    "print(f\"   R¬≤:   {final_results_df.iloc[0]['R2']:.4f}\")\n",
    "print(f\"   Accuracy: {final_results_df.iloc[0]['Accuracy']:.2f}%\")\n",
    "final_results_df.to_csv('output/evaluation/final_model_comparison.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Prediction Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "axes = axes.ravel()\n",
    "for idx, (model_name, preds) in enumerate(predictions_dict.items()):\n",
    "    axes[idx].scatter(y_valid_credits, preds, alpha=0.3, s=10)\n",
    "    axes[idx].plot([0, y_valid_credits.max()], [0, y_valid_credits.max()], 'r--', lw=2)\n",
    "    axes[idx].set_xlabel('Actual Credits', fontsize=12)\n",
    "    axes[idx].set_ylabel('Predicted Credits', fontsize=12)\n",
    "    axes[idx].set_title(f'{model_name} Predictions', fontsize=14, fontweight='bold')\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "    result = results_df[results_df['Model'] == model_name].iloc[0]\n",
    "    axes[idx].text(0.05, 0.95, f\"RMSE: {result['RMSE']:.4f}\\nR¬≤: {result['R2']:.4f}\",\n",
    "                   transform=axes[idx].transAxes, fontsize=10,\n",
    "                   verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "plt.tight_layout()\n",
    "plt.savefig('output/evaluation/predictions_scatter_all_models.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"\\n Prediction distribution analysis complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== ERROR ANALYSIS ===\")\n",
    "best_predictions = predictions_dict[best_model_name]\n",
    "errors = best_predictions - y_valid_credits\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "axes[0, 0].hist(errors, bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[0, 0].axvline(x=0, color='r', linestyle='--', lw=2)\n",
    "axes[0, 0].set_xlabel('Error (Predicted - Actual)', fontsize=12)\n",
    "axes[0, 0].set_ylabel('Frequency', fontsize=12)\n",
    "axes[0, 0].set_title('Error Distribution', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "axes[0, 1].scatter(best_predictions, errors, alpha=0.3, s=10)\n",
    "axes[0, 1].axhline(y=0, color='r', linestyle='--', lw=2)\n",
    "axes[0, 1].set_xlabel('Predicted Credits', fontsize=12)\n",
    "axes[0, 1].set_ylabel('Error', fontsize=12)\n",
    "axes[0, 1].set_title('Residual Plot', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "abs_errors = np.abs(errors)\n",
    "axes[1, 0].scatter(best_predictions, abs_errors, alpha=0.3, s=10)\n",
    "axes[1, 0].set_xlabel('Predicted Credits', fontsize=12)\n",
    "axes[1, 0].set_ylabel('Absolute Error', fontsize=12)\n",
    "axes[1, 0].set_title('Absolute Error Plot', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "percentiles = [10, 25, 50, 75, 90, 95, 99]\n",
    "error_percentiles = np.percentile(abs_errors, percentiles)\n",
    "axes[1, 1].bar(range(len(percentiles)), error_percentiles, tick_label=[f'{p}%' for p in percentiles])\n",
    "axes[1, 1].set_xlabel('Percentile', fontsize=12)\n",
    "axes[1, 1].set_ylabel('Absolute Error', fontsize=12)\n",
    "axes[1, 1].set_title('Error Percentiles', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].grid(True, alpha=0.3, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'output/evaluation/error_analysis_{best_model_name.replace(\" \", \"_\")}.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(f\"\\nError Statistics - {best_model_name}:\")\n",
    "print(f\"  Mean Error: {errors.mean():.4f}\")\n",
    "print(f\"  Std Error: {errors.std():.4f}\")\n",
    "print(f\"  Mean Absolute Error: {abs_errors.mean():.4f}\")\n",
    "print(f\"  Median Absolute Error: {np.median(abs_errors):.4f}\")\n",
    "print(f\"\\nError Percentiles:\")\n",
    "for p, val in zip(percentiles, error_percentiles):\n",
    "    print(f\"  {p}th percentile: {val:.4f}\")\n",
    "print(\"\\n Error analysis complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Save Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from pathlib import Path\n",
    "Path('models').mkdir(exist_ok=True)\n",
    "if best_model_name == 'Simple Ensemble':\n",
    "    fallback_model_name = 'LightGBM'\n",
    "    best_model = models[fallback_model_name]\n",
    "    save_name = fallback_model_name\n",
    "else:\n",
    "    best_model = models[best_model_name]\n",
    "    save_name = best_model_name\n",
    "model_path = Path('models') / f'best_model_{save_name.replace(\" \", \"_\")}.pkl'\n",
    "joblib.dump(best_model, model_path)\n",
    "feature_info = {\n",
    "    'feature_cols': feature_cols,\n",
    "    'categorical_cols': categorical_cols,\n",
    "    'label_encoders': label_encoders\n",
    "}\n",
    "joblib.dump(feature_info, Path('models') / 'feature_info.pkl')\n",
    "print(f\" Best model saved: {model_path}\")\n",
    "print(\" Feature info saved: models/feature_info.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPREHENSIVE ANALYSIS SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\n1. MODELS TRAINED:\")\n",
    "for model_name in models.keys():\n",
    "    print(f\"    {model_name}\")\n",
    "print(\"\\n2. BEST MODEL:\")\n",
    "print(f\"   {best_model_name}\")\n",
    "best_result = final_results_df.iloc[0]\n",
    "print(f\"   RMSE: {best_result['RMSE']:.4f}\")\n",
    "print(f\"   MAE:  {best_result['MAE']:.4f}\")\n",
    "print(f\"   R¬≤:   {best_result['R2']:.4f}\")\n",
    "print(f\"   Accuracy: {best_result['Accuracy']:.2f}%\")\n",
    "print(\"\\n3. ANALYSES PERFORMED:\")\n",
    "print(\"    Hyperparameter Optimization (Optuna - 50 trials each)\")\n",
    "print(\"    Feature Importance (all models)\")\n",
    "print(\"    SHAP Analysis (summary, importance plots)\")\n",
    "print(\"    LIME Analysis (3 cases: best, worst, median)\")\n",
    "print(\"    Error Analysis\")\n",
    "print(\"    Prediction Distribution Analysis\")\n",
    "print(\"\\n4. FILES SAVED:\")\n",
    "saved_files = [\n",
    "    'output/evaluation/optuna_optimization_history.png',\n",
    "    'output/evaluation/model_comparison_results.csv',\n",
    "    'output/evaluation/model_comparison_charts.png',\n",
    "    'output/evaluation/feature_importance_comparison.png',\n",
    "    'output/evaluation/shap_summary_plot.png',\n",
    "    'output/evaluation/shap_feature_importance.png',\n",
    "    'output/evaluation/lime_explanation_*.png/html',\n",
    "    'output/evaluation/final_model_comparison.csv',\n",
    "    'output/evaluation/predictions_scatter_all_models.png',\n",
    "    f'output/evaluation/error_analysis_{best_model_name.replace(\" \", \"_\")}.png',\n",
    "    f'models/best_model_{save_name.replace(\" \", \"_\")}.pkl',\n",
    "    'models/feature_info.pkl'\n",
    "]\n",
    "for file in saved_files:\n",
    "    print(f\"    {file}\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" ANALYSIS COMPLETE!\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nAll results saved to output/evaluation/\")\n",
    "print(\"Best model saved to models/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
