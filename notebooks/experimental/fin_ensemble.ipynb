{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46c668ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "ACADEMIC_PATH = r'../../data/raw/academic_records.csv'\n",
    "ADMISSION_PATH = r'../../data/raw/admission.csv'\n",
    "TEST_PATH = r'../../data/raw/test.csv'\n",
    "academic_records = pd.read_csv(ACADEMIC_PATH)\n",
    "admission = pd.read_csv(ADMISSION_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2978ec2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- üöÄ B·∫ÆT ƒê·∫¶U QUY TR√åNH L√ÄM S·∫†CH D·ªÆ LI·ªÜU (FIXED VERSION) ---\n",
      "-> ƒêang x·ª≠ l√Ω c·ªôt HOC_KY...\n",
      "--- ‚úÖ HO√ÄN T·∫§T. K√≠ch th∆∞·ªõc data: (105726, 14) ---\n",
      "Sample HOC_KY_INT: [20231, 20232, 20211, 20212, 20221]\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "MA_SO_SV",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "HOC_KY",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "CPA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "GPA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "TC_DANGKY",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "TC_HOANTHANH",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "HOC_KY_INT",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "NAM_TUYENSINH",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "PTXT",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "TOHOP_XT",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "DIEM_TRUNGTUYEN",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "DIEM_CHUAN",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "COMPLETION_RATE",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ADMISSION_GAP",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "30446ada-301b-4f17-b114-d28221099231",
       "rows": [
        [
         "0",
         "00003e092652",
         "HK1 2023-2024",
         "1.64",
         "1.97",
         "18",
         "15",
         "20231",
         "2023",
         "100",
         "A00",
         "21.32",
         "20.25",
         "0.8333333332870371",
         "1.0700000000000003"
        ],
        [
         "1",
         "00003e092652",
         "HK2 2023-2024",
         "1.53",
         "2.05",
         "18",
         "13",
         "20232",
         "2023",
         "100",
         "A00",
         "21.32",
         "20.25",
         "0.7222222221820987",
         "1.0700000000000003"
        ],
        [
         "2",
         "000e15519006",
         "HK1 2021-2022",
         "3.85",
         "3.85",
         "9",
         "9",
         "20211",
         "2021",
         "1",
         "D07",
         "23.84",
         "22.43",
         "0.9999999998888889",
         "1.4100000000000001"
        ],
        [
         "3",
         "000e15519006",
         "HK2 2021-2022",
         "2.77",
         "3.12",
         "19",
         "19",
         "20212",
         "2021",
         "1",
         "D07",
         "23.84",
         "22.43",
         "0.9999999999473684",
         "1.4100000000000001"
        ],
        [
         "4",
         "000e15519006",
         "HK1 2022-2023",
         "2.83",
         "2.98",
         "21",
         "21",
         "20221",
         "2021",
         "1",
         "D07",
         "23.84",
         "22.43",
         "0.999999999952381",
         "1.4100000000000001"
        ]
       ],
       "shape": {
        "columns": 14,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MA_SO_SV</th>\n",
       "      <th>HOC_KY</th>\n",
       "      <th>CPA</th>\n",
       "      <th>GPA</th>\n",
       "      <th>TC_DANGKY</th>\n",
       "      <th>TC_HOANTHANH</th>\n",
       "      <th>HOC_KY_INT</th>\n",
       "      <th>NAM_TUYENSINH</th>\n",
       "      <th>PTXT</th>\n",
       "      <th>TOHOP_XT</th>\n",
       "      <th>DIEM_TRUNGTUYEN</th>\n",
       "      <th>DIEM_CHUAN</th>\n",
       "      <th>COMPLETION_RATE</th>\n",
       "      <th>ADMISSION_GAP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00003e092652</td>\n",
       "      <td>HK1 2023-2024</td>\n",
       "      <td>1.64</td>\n",
       "      <td>1.97</td>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "      <td>20231</td>\n",
       "      <td>2023</td>\n",
       "      <td>100</td>\n",
       "      <td>A00</td>\n",
       "      <td>21.32</td>\n",
       "      <td>20.25</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00003e092652</td>\n",
       "      <td>HK2 2023-2024</td>\n",
       "      <td>1.53</td>\n",
       "      <td>2.05</td>\n",
       "      <td>18</td>\n",
       "      <td>13</td>\n",
       "      <td>20232</td>\n",
       "      <td>2023</td>\n",
       "      <td>100</td>\n",
       "      <td>A00</td>\n",
       "      <td>21.32</td>\n",
       "      <td>20.25</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>1.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000e15519006</td>\n",
       "      <td>HK1 2021-2022</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.85</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>20211</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>D07</td>\n",
       "      <td>23.84</td>\n",
       "      <td>22.43</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000e15519006</td>\n",
       "      <td>HK2 2021-2022</td>\n",
       "      <td>2.77</td>\n",
       "      <td>3.12</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>20212</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>D07</td>\n",
       "      <td>23.84</td>\n",
       "      <td>22.43</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000e15519006</td>\n",
       "      <td>HK1 2022-2023</td>\n",
       "      <td>2.83</td>\n",
       "      <td>2.98</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>20221</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>D07</td>\n",
       "      <td>23.84</td>\n",
       "      <td>22.43</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       MA_SO_SV         HOC_KY   CPA   GPA  TC_DANGKY  TC_HOANTHANH  \\\n",
       "0  00003e092652  HK1 2023-2024  1.64  1.97         18            15   \n",
       "1  00003e092652  HK2 2023-2024  1.53  2.05         18            13   \n",
       "2  000e15519006  HK1 2021-2022  3.85  3.85          9             9   \n",
       "3  000e15519006  HK2 2021-2022  2.77  3.12         19            19   \n",
       "4  000e15519006  HK1 2022-2023  2.83  2.98         21            21   \n",
       "\n",
       "   HOC_KY_INT  NAM_TUYENSINH PTXT TOHOP_XT  DIEM_TRUNGTUYEN  DIEM_CHUAN  \\\n",
       "0       20231           2023  100      A00            21.32       20.25   \n",
       "1       20232           2023  100      A00            21.32       20.25   \n",
       "2       20211           2021    1      D07            23.84       22.43   \n",
       "3       20212           2021    1      D07            23.84       22.43   \n",
       "4       20221           2021    1      D07            23.84       22.43   \n",
       "\n",
       "   COMPLETION_RATE  ADMISSION_GAP  \n",
       "0         0.833333           1.07  \n",
       "1         0.722222           1.07  \n",
       "2         1.000000           1.41  \n",
       "3         1.000000           1.41  \n",
       "4         1.000000           1.41  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# --- H√ÄM M·ªöI: X·ª≠ l√Ω ƒë·ªãnh d·∫°ng h·ªçc k·ª≥ ph·ª©c t·∫°p ---\n",
    "def parse_semester_string(sem_str):\n",
    "    \"\"\"\n",
    "    Chuy·ªÉn ƒë·ªïi chu·ªói nh∆∞ 'HK1 2023-2024' th√†nh m√£ s·ªë 20231 ƒë·ªÉ sort ƒë∆∞·ª£c.\n",
    "    Logic: NƒÉm * 10 + K·ª≥\n",
    "    \"\"\"\n",
    "    s = str(sem_str).strip()\n",
    "    \n",
    "    # Tr∆∞·ªùng h·ª£p 1: D·∫°ng s·ªë s·∫µn (VD: 20231)\n",
    "    if s.isdigit():\n",
    "        return int(s)\n",
    "    \n",
    "    # Tr∆∞·ªùng h·ª£p 2: D·∫°ng ch·ªØ (VD: HK1 2023-2024 ho·∫∑c H·ªçc k·ª≥ 1 nƒÉm 2023)\n",
    "    # T√¨m t·∫•t c·∫£ c√°c con s·ªë trong chu·ªói\n",
    "    digits = re.findall(r'\\d+', s)\n",
    "    \n",
    "    if len(digits) >= 2:\n",
    "        # Gi·∫£ s·ª≠ s·ªë nh·ªè l√† k·ª≥, s·ªë l·ªõn (4 ch·ªØ s·ªë) l√† nƒÉm\n",
    "        # T√¨m nƒÉm (th∆∞·ªùng l√† s·ªë c√≥ 4 ch·ªØ s·ªë ƒë·∫ßu ti√™n t√¨m th·∫•y)\n",
    "        years = [int(d) for d in digits if len(d) == 4]\n",
    "        sems = [int(d) for d in digits if len(d) == 1]\n",
    "        \n",
    "        if years and sems:\n",
    "            year = years[0]\n",
    "            sem = sems[0]\n",
    "            return year * 10 + sem\n",
    "            \n",
    "    return 0 # Kh√¥ng x√°c ƒë·ªãnh\n",
    "\n",
    "def clean_data_pipeline_v3(admission, academic_records):\n",
    "    print(\"--- üöÄ B·∫ÆT ƒê·∫¶U QUY TR√åNH L√ÄM S·∫†CH D·ªÆ LI·ªÜU (FIXED VERSION) ---\")\n",
    "    \n",
    "    adm = admission.copy()\n",
    "    acad = academic_records.copy()\n",
    "    \n",
    "    # 1. Chu·∫©n h√≥a ID\n",
    "    adm['MA_SO_SV'] = adm['MA_SO_SV'].astype(str)\n",
    "    acad['MA_SO_SV'] = acad['MA_SO_SV'].astype(str)\n",
    "    \n",
    "    # ---------------------------------------------------------\n",
    "    # [FIX QUAN TR·ªåNG] X·ª≠ l√Ω HOC_KY th√¥ng minh h∆°n\n",
    "    # ---------------------------------------------------------\n",
    "    print(\"-> ƒêang x·ª≠ l√Ω c·ªôt HOC_KY...\")\n",
    "    # T·∫°o c·ªôt HOC_KY_INT d√πng ƒë·ªÉ sort (VD: 20231)\n",
    "    acad['HOC_KY_INT'] = acad['HOC_KY'].apply(parse_semester_string)\n",
    "    \n",
    "    # Ki·ªÉm tra xem c√≥ d√≤ng n√†o b·ªã l·ªói (b·∫±ng 0) kh√¥ng\n",
    "    error_count = (acad['HOC_KY_INT'] == 0).sum()\n",
    "    if error_count > 0:\n",
    "        print(f\"   ‚ö†Ô∏è C·∫£nh b√°o: C√≥ {error_count} d√≤ng kh√¥ng ƒë·ªçc ƒë∆∞·ª£c HOC_KY.\")\n",
    "\n",
    "    # Merge d·ªØ li·ªáu\n",
    "    df = pd.merge(acad, adm, on='MA_SO_SV', how='left')\n",
    "    \n",
    "    # S·∫Øp x·∫øp theo Time-series chu·∫©n x√°c d·ª±a tr√™n c·ªôt v·ª´a t·∫°o\n",
    "    df = df.sort_values(by=['MA_SO_SV', 'HOC_KY_INT']).reset_index(drop=True)\n",
    "    \n",
    "    # ---------------------------------------------------------\n",
    "    # 2. X·ª¨ L√ù S·ªê LI·ªÜU & LOGIC\n",
    "    # ---------------------------------------------------------\n",
    "    cols_float = ['GPA', 'CPA', 'DIEM_TRUNGTUYEN', 'DIEM_CHUAN']\n",
    "    cols_int = ['TC_DANGKY', 'TC_HOANTHANH']\n",
    "    \n",
    "    for col in cols_float:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "        \n",
    "    for col in cols_int:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "    # Logic: Ho√†n th√†nh <= ƒêƒÉng k√Ω\n",
    "    df['TC_HOANTHANH'] = np.minimum(df['TC_HOANTHANH'], df['TC_DANGKY'])\n",
    "    \n",
    "    # Target Transformation\n",
    "    df['COMPLETION_RATE'] = df['TC_HOANTHANH'] / (df['TC_DANGKY'] + 1e-9)\n",
    "    df['COMPLETION_RATE'] = df['COMPLETION_RATE'].clip(0, 1)\n",
    "\n",
    "    # Clip ƒëi·ªÉm s·ªë\n",
    "    df['GPA'] = df['GPA'].clip(0, 4.0)\n",
    "    df['CPA'] = df['CPA'].clip(0, 4.0)\n",
    "\n",
    "    # Admission Gap Feature\n",
    "    if 'DIEM_TRUNGTUYEN' in df.columns and 'DIEM_CHUAN' in df.columns:\n",
    "        df['ADMISSION_GAP'] = df['DIEM_TRUNGTUYEN'] - df['DIEM_CHUAN']\n",
    "    \n",
    "    # L·ªçc r√°c\n",
    "    initial_len = len(df)\n",
    "    df = df[df['TC_DANGKY'] > 0]\n",
    "    \n",
    "    print(f\"--- ‚úÖ HO√ÄN T·∫§T. K√≠ch th∆∞·ªõc data: {df.shape} ---\")\n",
    "    print(\"Sample HOC_KY_INT:\", df['HOC_KY_INT'].head().tolist())\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Ch·∫°y th·ª≠ l·∫°i\n",
    "df_clean = clean_data_pipeline_v3(admission, academic_records)\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28294b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- B·∫ÆT ƒê·∫¶U PIPELINE ---\n",
      "--- üöÄ 1. PREPROCESSING DATA ---\n",
      "--- üöÄ 1. PREPROCESSING DATA ---\n",
      "--- ‚ö° 2. FEATURE ENGINEERING (FULL POWER) ---\n",
      "‚úÖ Xong! S·ªë l∆∞·ª£ng Features: 24\n",
      "Sample Features: ['TC_DANGKY', 'PTXT', 'TOHOP_XT', 'DIEM_TRUNGTUYEN', 'DIEM_CHUAN']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. C√ÅC H√ÄM TI·ªÜN √çCH (UTILS)\n",
    "# ==============================================================================\n",
    "\n",
    "def parse_semester_string(sem_str):\n",
    "    \"\"\"\n",
    "    Chuy·ªÉn ƒë·ªïi 'HK1 2023-2024' -> 20231 (Int) ƒë·ªÉ sort time-series.\n",
    "    \"\"\"\n",
    "    s = str(sem_str).strip()\n",
    "    if s.isdigit(): return int(s)\n",
    "    \n",
    "    digits = re.findall(r'\\d+', s)\n",
    "    if len(digits) >= 2:\n",
    "        years = [int(d) for d in digits if len(d) == 4]\n",
    "        sems = [int(d) for d in digits if len(d) == 1]\n",
    "        if years and sems:\n",
    "            return years[0] * 10 + sems[0]\n",
    "    return 0\n",
    "\n",
    "def fast_slope(y):\n",
    "    \"\"\"\n",
    "    T√≠nh h·ªá s·ªë g√≥c (Trend) nhanh.\n",
    "    Input: Array numpy (c√≥ th·ªÉ ch·ª©a NaN).\n",
    "    \"\"\"\n",
    "    # L·ªçc b·ªè NaN tr∆∞·ªõc khi t√≠nh (Quan tr·ªçng!)\n",
    "    y_clean = y[~np.isnan(y)]\n",
    "    n = len(y_clean)\n",
    "    if n < 2: return 0.0\n",
    "    \n",
    "    x = np.arange(n)\n",
    "    x_mean = np.mean(x)\n",
    "    y_mean = np.mean(y_clean)\n",
    "    \n",
    "    numerator = np.sum((x - x_mean) * (y_clean - y_mean))\n",
    "    denominator = np.sum((x - x_mean) ** 2)\n",
    "    \n",
    "    return numerator / (denominator + 1e-6)\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. DATA PREPROCESSING PIPELINE\n",
    "# ==============================================================================\n",
    "\n",
    "def clean_data_pipeline(admission, academic_records, is_test=False):\n",
    "    print(\"--- üöÄ 1. PREPROCESSING DATA ---\")\n",
    "    adm = admission.copy()\n",
    "    acad = academic_records.copy()\n",
    "    \n",
    "    # Chu·∫©n h√≥a ID\n",
    "    adm['MA_SO_SV'] = adm['MA_SO_SV'].astype(str)\n",
    "    acad['MA_SO_SV'] = acad['MA_SO_SV'].astype(str)\n",
    "    \n",
    "    # T·∫°o Time-Index\n",
    "    acad['semester_order'] = acad['HOC_KY'].apply(parse_semester_string)\n",
    "    \n",
    "    # Merge\n",
    "    df = pd.merge(acad, adm, on='MA_SO_SV', how='left')\n",
    "    \n",
    "    # Sort Time-Series (C·ª∞C K·ª≤ QUAN TR·ªåNG)\n",
    "    df = df.sort_values(by=['MA_SO_SV', 'semester_order']).reset_index(drop=True)\n",
    "    \n",
    "    # Numeric conversion\n",
    "    cols_float = ['GPA', 'CPA', 'DIEM_TRUNGTUYEN', 'DIEM_CHUAN']\n",
    "    cols_int = ['TC_DANGKY', 'TC_HOANTHANH']\n",
    "    \n",
    "    for col in cols_float:\n",
    "        if col in df.columns: df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    for col in cols_int:\n",
    "        if col in df.columns: df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "    # Logic clean\n",
    "    if not is_test:\n",
    "        df['TC_HOANTHANH'] = np.minimum(df['TC_HOANTHANH'], df['TC_DANGKY'])\n",
    "        df['GPA'] = df['GPA'].clip(0, 4.0)\n",
    "        df['CPA'] = df['CPA'].clip(0, 4.0)\n",
    "    \n",
    "    # Target Transformation (Ch·ªâ d√πng cho train)\n",
    "    if not is_test:\n",
    "        df['COMPLETION_RATE'] = df['TC_HOANTHANH'] / (df['TC_DANGKY'] + 1e-9)\n",
    "        df['COMPLETION_RATE'] = df['COMPLETION_RATE'].clip(0, 1)\n",
    "\n",
    "    return df\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. FEATURE ENGINEERING CLASS (CORE)\n",
    "# ==============================================================================\n",
    "\n",
    "class FeatureEngineer:    \n",
    "    def __init__(self):\n",
    "        # C√°c c·ªôt Category s·∫Ω gi·ªØ l·∫°i\n",
    "        self.cat_cols = ['PTXT', 'TOHOP_XT', 'MA_NGANH', 'KV_UT', 'KHOA_VIEN'] \n",
    "\n",
    "    def create_features(self, df):\n",
    "        print(\"--- ‚ö° 2. FEATURE ENGINEERING (FULL POWER) ---\")\n",
    "        df = df.copy()\n",
    "        \n",
    "        # Sort l·∫°i cho ch·∫Øc ch·∫Øn\n",
    "        df = df.sort_values(['MA_SO_SV', 'semester_order']).reset_index(drop=True)\n",
    "        \n",
    "        # Convert Category\n",
    "        for col in self.cat_cols:\n",
    "            if col in df.columns:\n",
    "                df[col] = df[col].astype(str).astype('category')\n",
    "\n",
    "        # Groupby object\n",
    "        g = df.groupby('MA_SO_SV')\n",
    "\n",
    "        # ---------------------------------------------------------\n",
    "        # A. BASE LAGS (C·ª±c k·ª≥ quan tr·ªçng: D√πng shift(1) ƒë·ªÉ tr√°nh Leakage)\n",
    "        # ---------------------------------------------------------\n",
    "        # T·∫°o bi·∫øn Raw (ch·ª©a NaN) ƒë·ªÉ t√≠nh to√°n th·ªëng k√™ ch√≠nh x√°c h∆°n\n",
    "        df['Prev_GPA_Raw'] = g['GPA'].shift(1)\n",
    "        \n",
    "        # T·∫°o bi·∫øn Fill (ƒë·ªÉ model d√πng tr·ª±c ti·∫øp)\n",
    "        df['Prev_GPA'] = df['Prev_GPA_Raw'].fillna(-1)\n",
    "        df['Prev_CPA'] = g['CPA'].shift(1).fillna(-1)\n",
    "        df['Prev_TC_HOANTHANH'] = g['TC_HOANTHANH'].shift(1).fillna(0)\n",
    "        df['Prev_TC_DANGKY'] = g['TC_DANGKY'].shift(1).fillna(0)\n",
    "        \n",
    "        # C·ªù nƒÉm nh·∫•t (Ch∆∞a c√≥ l·ªãch s·ª≠)\n",
    "        df['is_freshman'] = (df['Prev_TC_DANGKY'] == 0).astype(int)\n",
    "\n",
    "        # ---------------------------------------------------------\n",
    "        # B. G·ªåI C√ÅC NH√ìM FEATURE\n",
    "        # ---------------------------------------------------------\n",
    "        df = self._create_admission_features(df)\n",
    "        df = self._create_history_features(df)\n",
    "        df = self._create_trend_features(df)  # <--- Slope, Volatility n·∫±m ·ªü ƒë√¢y\n",
    "        df = self._create_risk_features(df)\n",
    "        \n",
    "        # D·ªçn d·∫πp c·ªôt t·∫°m\n",
    "        if 'Prev_GPA_Raw' in df.columns:\n",
    "            df = df.drop(columns=['Prev_GPA_Raw'])\n",
    "            \n",
    "        return df\n",
    "\n",
    "    def _create_admission_features(self, df):\n",
    "        # Kho·∫£ng c√°ch ƒëi·ªÉm ƒë·∫ßu v√†o\n",
    "        if 'DIEM_TRUNGTUYEN' in df.columns and 'DIEM_CHUAN' in df.columns:\n",
    "            df['diem_vuot_chuan'] = df['DIEM_TRUNGTUYEN'] - df['DIEM_CHUAN']\n",
    "        \n",
    "        # Tu·ªïi (gi·∫£ ƒë·ªãnh nƒÉm hi·ªán t·∫°i 2025/2026)\n",
    "        if 'NAM_TUYENSINH' in df.columns:\n",
    "            df['nam_tuoi'] = 2026 - df['NAM_TUYENSINH']\n",
    "            \n",
    "        # S·ªë k·ª≥ ƒë√£ h·ªçc (t√≠nh t·ª´ nƒÉm nh·∫≠p h·ªçc)\n",
    "        df['semester_number'] = df.groupby('MA_SO_SV').cumcount() + 1\n",
    "        return df\n",
    "\n",
    "    def _create_history_features(self, df):\n",
    "        # 1. Delta GPA-CPA: ƒêang h·ªçc t·ªët h∆°n hay t·ªá h∆°n trung b√¨nh t√≠ch l≈©y?\n",
    "        df['prev_gpa_cpa_diff'] = df['Prev_GPA'] - df['Prev_CPA']\n",
    "        \n",
    "        # 2. T·ª∑ l·ªá ho√†n th√†nh k·ª≥ tr∆∞·ªõc\n",
    "        df['prev_completion_rate'] = df['Prev_TC_HOANTHANH'] / (df['Prev_TC_DANGKY'] + 1e-9)\n",
    "        \n",
    "        # 3. Load Factor (√Åp l·ª±c): ƒêƒÉng k√Ω k·ª≥ n√†y / S·ª©c h·ªçc trung b√¨nh\n",
    "        avg_capacity = df.groupby('MA_SO_SV')['Prev_TC_HOANTHANH'].transform(\n",
    "            lambda x: x.rolling(window=5, min_periods=1).mean()\n",
    "        ).fillna(15)\n",
    "        \n",
    "        df['load_factor'] = df['TC_DANGKY'] / (avg_capacity + 1e-9)\n",
    "        \n",
    "        # Bi·∫øn c·ªù: R·ªõt m√¥n k·ª≥ tr∆∞·ªõc\n",
    "        df['failed_last_sem'] = (df['Prev_TC_HOANTHANH'] < df['Prev_TC_DANGKY']).astype(int)\n",
    "        \n",
    "        return df\n",
    "\n",
    "    def _create_trend_features(self, df):\n",
    "        # S·ª≠ d·ª•ng Prev_GPA_Raw (c√≥ NaN) ƒë·ªÉ t√≠nh Slope ch√≠nh x√°c\n",
    "        # N·∫øu d√πng Prev_GPA (c√≥ -1), Slope s·∫Ω b·ªã sai l·ªách l·ªõn\n",
    "        g_raw = df.groupby('MA_SO_SV')['Prev_GPA_Raw']\n",
    "        \n",
    "        # 1. GPA Slope (Xu h∆∞·ªõng ƒëi·ªÉm)\n",
    "        df['gpa_trend_slope'] = g_raw.transform(\n",
    "            lambda x: x.rolling(window=3, min_periods=2).apply(fast_slope, raw=True)\n",
    "        ).fillna(0)\n",
    "        \n",
    "        # 2. [RECOVERED] GPA Volatility (ƒê·ªô ·ªïn ƒë·ªãnh)\n",
    "        df['gpa_volatility'] = g_raw.transform(\n",
    "            lambda x: x.rolling(window=4, min_periods=2).std()\n",
    "        ).fillna(0)\n",
    "        \n",
    "        # 3. T√≠ch l≈©y t√≠n ch·ªâ (History)\n",
    "        grouped = df.groupby('MA_SO_SV')\n",
    "        cum_dangky = grouped['Prev_TC_DANGKY'].cumsum()\n",
    "        cum_hoanthanh = grouped['Prev_TC_HOANTHANH'].cumsum()\n",
    "        \n",
    "        df['total_credits_failed'] = cum_dangky - cum_hoanthanh\n",
    "        df['accumulated_fail_ratio'] = df['total_credits_failed'] / (cum_dangky + 1e-9)\n",
    "        \n",
    "        # 4. [RECOVERED] Credit Velocity (T·ªëc ƒë·ªô h·ªçc)\n",
    "        semester_count = grouped.cumcount() + 1\n",
    "        df['credit_velocity'] = cum_hoanthanh / semester_count\n",
    "        \n",
    "        return df\n",
    "\n",
    "    def _create_risk_features(self, df):\n",
    "        # H√†nh vi \"G·ª° g·∫°c\" (Aggressive Recovery): R·ªõt m√¥n k·ª≥ tr∆∞·ªõc -> ƒêƒÉng k√Ω nhi·ªÅu h∆°n k·ª≥ n√†y\n",
    "        more_credits = (df['TC_DANGKY'] > df['Prev_TC_DANGKY'])\n",
    "        df['aggressive_recovery'] = (df['failed_last_sem'] & more_credits).astype(int)\n",
    "        \n",
    "        # K·ª≥ v·ªçng ho√†n th√†nh (Expected Credits) = ƒêƒÉng k√Ω * T·ª∑ l·ªá ƒë·∫≠u to√†n c·ª•c c·ªßa SV ƒë√≥\n",
    "        df['expected_real_credits'] = df['TC_DANGKY'] * (1 - df['accumulated_fail_ratio'])\n",
    "        \n",
    "        return df\n",
    "\n",
    "    def get_feature_columns(self, df):\n",
    "        \"\"\"T·ª± ƒë·ªông l·∫•y danh s√°ch feature d·ª±a tr√™n prefix\"\"\"\n",
    "        \n",
    "        # Whitelist c√°c prefix\n",
    "        valid_prefixes = [\n",
    "            'Prev_', 'prev_', 'sem_', 'diem_', 'nam_', 'is_', \n",
    "            'load_', 'aggressive_', 'gpa_', 'total_', 'accumulated_',\n",
    "            'credit_', 'expected_', 'failed_'\n",
    "        ]\n",
    "        \n",
    "        valid_exact = ['TC_DANGKY', 'DIEM_TRUNGTUYEN', 'DIEM_CHUAN', 'semester_number']\n",
    "        valid_exact.extend(self.cat_cols)\n",
    "        \n",
    "        final_cols = []\n",
    "        # C√°c c·ªôt target/meta c·∫ßn lo·∫°i b·ªè\n",
    "        ignore_cols = ['TC_HOANTHANH', 'GPA', 'CPA', 'semester_order', 'MA_SO_SV', 'HOC_KY', 'COMPLETION_RATE', 'Prev_GPA_Raw']\n",
    "        \n",
    "        for col in df.columns:\n",
    "            if col in ignore_cols: continue\n",
    "            \n",
    "            is_valid = False\n",
    "            if col in valid_exact: is_valid = True\n",
    "            else:\n",
    "                for prefix in valid_prefixes:\n",
    "                    if col.startswith(prefix):\n",
    "                        is_valid = True\n",
    "                        break\n",
    "            \n",
    "            if is_valid: final_cols.append(col)\n",
    "                \n",
    "        return final_cols\n",
    "\n",
    "# ==============================================================================\n",
    "# 4. EXECUTION BLOCK (CH·∫†Y TH·ª¨)\n",
    "# ==============================================================================\n",
    "\n",
    "\n",
    "test_raw = pd.read_csv(TEST_PATH)\n",
    "\n",
    "print(\"--- B·∫ÆT ƒê·∫¶U PIPELINE ---\")\n",
    "\n",
    "# 1. Clean Data\n",
    "df_train_raw = clean_data_pipeline(admission, academic_records, is_test=False)\n",
    "\n",
    "# 2. Chu·∫©n b·ªã Test (G√°n dummy values ƒë·ªÉ ch·∫°y ƒë∆∞·ª£c pipeline)\n",
    "test_copy = test_raw.copy()\n",
    "for col in ['TC_HOANTHANH', 'GPA', 'CPA']: test_copy[col] = 0\n",
    "df_test_raw = clean_data_pipeline(admission, test_copy, is_test=True)\n",
    "\n",
    "# 3. G·ªôp Train + Test ƒë·ªÉ t·∫°o feature (Tr√°nh bi√™n gi·ªõi gi·ªØa c√°c k·ª≥ b·ªã ƒë·ª©t g√£y)\n",
    "df_train_raw['set_type'] = 'TRAIN'\n",
    "df_test_raw['set_type'] = 'TEST'\n",
    "full_df = pd.concat([df_train_raw, df_test_raw], ignore_index=True)\n",
    "\n",
    "# 4. Feature Engineering\n",
    "fe = FeatureEngineer()\n",
    "full_df_fe = fe.create_features(full_df)\n",
    "\n",
    "# 5. T√°ch l·∫°i Train/Test\n",
    "train_final = full_df_fe[full_df_fe['set_type'] == 'TRAIN'].copy()\n",
    "test_final = full_df_fe[full_df_fe['set_type'] == 'TEST'].copy()\n",
    "\n",
    "# 6. L·∫•y features & Target\n",
    "feature_cols = fe.get_feature_columns(train_final)\n",
    "X = train_final[feature_cols]\n",
    "y = train_final['TC_HOANTHANH'] # Ho·∫∑c d√πng COMPLETION_RATE n·∫øu mu·ªën\n",
    "\n",
    "print(f\"‚úÖ Xong! S·ªë l∆∞·ª£ng Features: {len(feature_cols)}\")\n",
    "print(f\"Sample Features: {feature_cols[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e1a5350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- ‚úÇÔ∏è 3. SPLITTING TRAIN/VALID/TEST ---\n",
      "üìå Train size: (90582, 24)\n",
      "üìå Valid size: (15144, 24)\n",
      "üìå Test size:  (16502, 24)\n",
      "üìå Categorical Features: ['PTXT', 'TOHOP_XT']\n",
      "\n",
      "--- üöÄ 4. ACTIVATING STACKING ENSEMBLE ---\n",
      "   -> Training XGBoost...\n",
      "   -> Training LightGBM...\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[266]\tvalid_0's rmse: 0.21248\n",
      "   -> Training CatBoost...\n",
      "\n",
      "--- üîÑ Layer 2: Blending & Prediction ---\n",
      "üìä Tr·ªçng s·ªë Stacking: XGB: 0.22 | LGB: 0.29 | CAT: 0.49\n",
      "\n",
      ">>> ‚úÖ RMSE Stacking (Valid - HK2 23/24): 3.7427\n",
      "\n",
      "üéâ ƒê√£ xu·∫•t file th√†nh c√¥ng: submission_final_stacking.csv\n",
      "        MA_SO_SV  PRED_TC_HOANTHANH\n",
      "2   00003e092652          14.947369\n",
      "3   00027b0dec4c          17.174156\n",
      "10  000e15519006          17.446657\n",
      "13  000ea6e12003          15.980199\n",
      "16  00109b845a3d           5.040422\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# 5. CHU·∫®N B·ªä D·ªÆ LI·ªÜU CHO TRAINING (THE BRIDGE)\n",
    "# ==============================================================================\n",
    "print(\"\\n--- ‚úÇÔ∏è 3. SPLITTING TRAIN/VALID/TEST ---\")\n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# ƒê·ªãnh nghƒ©a m·ªëc th·ªùi gian (Theo ƒë·ªÅ b√†i)\n",
    "SPLIT_SEM = 20231  # Train ƒë·∫øn h·∫øt HK1 2023-2024\n",
    "VALID_SEM = 20232  # Valid l√† HK2 2023-2024\n",
    "\n",
    "# T·∫°o Mask ƒë·ªÉ l·ªçc d·ªØ li·ªáu\n",
    "# L∆∞u √Ω: train_final c·ªßa b·∫°n ƒëang ch·ª©a c·∫£ Train v√† Valid\n",
    "mask_train = train_final['semester_order'] <= SPLIT_SEM\n",
    "mask_valid = train_final['semester_order'] == VALID_SEM\n",
    "\n",
    "# 1. ƒê·ªãnh nghƒ©a t·∫≠p TRAIN (D√πng ƒë·ªÉ d·∫°y model)\n",
    "X_train = train_final[mask_train][feature_cols]\n",
    "# Model h·ªçc T·ª∑ l·ªá (Rate) ch·ª© kh√¥ng h·ªçc s·ªë t√≠n ch·ªâ -> Quy v·ªÅ [0, 1]\n",
    "y_train = train_final[mask_train]['TC_HOANTHANH'] / (train_final[mask_train]['TC_DANGKY'] + 1e-9)\n",
    "y_train = y_train.clip(0, 1)\n",
    "\n",
    "# 2. ƒê·ªãnh nghƒ©a t·∫≠p VALID (D√πng ƒë·ªÉ ki·ªÉm tra & Stacking)\n",
    "X_valid = train_final[mask_valid][feature_cols]\n",
    "y_valid_rate = train_final[mask_valid]['TC_HOANTHANH'] / (train_final[mask_valid]['TC_DANGKY'] + 1e-9)\n",
    "y_valid_rate = y_valid_rate.clip(0, 1)\n",
    "# C√°c bi·∫øn d√πng ƒë·ªÉ ƒëo l∆∞·ªùng RMSE th·ª±c t·∫ø\n",
    "y_valid_credits = train_final[mask_valid]['TC_HOANTHANH'] \n",
    "valid_dangky = train_final[mask_valid]['TC_DANGKY']\n",
    "\n",
    "# 3. ƒê·ªãnh nghƒ©a t·∫≠p TEST (D√πng ƒë·ªÉ n·ªôp b√†i)\n",
    "X_test = test_final[feature_cols]\n",
    "test_dangky = test_final['TC_DANGKY']\n",
    "\n",
    "# X√°c ƒë·ªãnh danh s√°ch c·ªôt Category cho CatBoost\n",
    "# (L·∫•y t·ª´ feature_cols nh·ªØng c·ªôt n·∫±m trong danh s√°ch cat_cols c·ªßa b·∫°n)\n",
    "cat_features_list = ['PTXT', 'TOHOP_XT', 'MA_NGANH', 'KV_UT', 'KHOA_VIEN']\n",
    "valid_cat_features = [c for c in feature_cols if c in cat_features_list]\n",
    "\n",
    "print(f\"üìå Train size: {X_train.shape}\")\n",
    "print(f\"üìå Valid size: {X_valid.shape}\")\n",
    "print(f\"üìå Test size:  {X_test.shape}\")\n",
    "print(f\"üìå Categorical Features: {valid_cat_features}\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 6. HU·∫§N LUY·ªÜN STACKING ENSEMBLE (LAYER 1)\n",
    "# ==============================================================================\n",
    "print(\"\\n--- üöÄ 4. ACTIVATING STACKING ENSEMBLE ---\")\n",
    "\n",
    "# --- MODEL 1: XGBOOST ---\n",
    "print(\"   -> Training XGBoost...\")\n",
    "xgb_params = {\n",
    "    'n_estimators': 2000,\n",
    "    'learning_rate': 0.02,\n",
    "    'max_depth': 6,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'objective': 'reg:squarederror',\n",
    "    'n_jobs': -1,\n",
    "    'random_state': 42,\n",
    "    'enable_categorical': True, # ƒê√£ b·∫≠t h·ªó tr·ª£ category\n",
    "    'tree_method': 'hist',\n",
    "    'early_stopping_rounds': 100\n",
    "}\n",
    "model_xgb = xgb.XGBRegressor(**xgb_params)\n",
    "model_xgb.fit(X_train, y_train, eval_set=[(X_valid, y_valid_rate)], verbose=False)\n",
    "\n",
    "# --- MODEL 2: LIGHTGBM ---\n",
    "print(\"   -> Training LightGBM...\")\n",
    "lgb_params = {\n",
    "    'n_estimators': 2000,\n",
    "    'learning_rate': 0.02,\n",
    "    'num_leaves': 31,\n",
    "    'objective': 'rmse',\n",
    "    'metric': 'rmse',\n",
    "    'n_jobs': -1,\n",
    "    'random_state': 42,\n",
    "    'verbose': -1\n",
    "}\n",
    "model_lgb = lgb.LGBMRegressor(**lgb_params)\n",
    "model_lgb.fit(\n",
    "    X_train, y_train, \n",
    "    eval_set=[(X_valid, y_valid_rate)], \n",
    "    eval_metric='rmse',\n",
    "    callbacks=[lgb.early_stopping(100), lgb.log_evaluation(0)]\n",
    ")\n",
    "\n",
    "# --- MODEL 3: CATBOOST ---\n",
    "print(\"   -> Training CatBoost...\")\n",
    "cat_params = {\n",
    "    'iterations': 2000,\n",
    "    'learning_rate': 0.02,\n",
    "    'depth': 6,\n",
    "    'loss_function': 'RMSE',\n",
    "    'verbose': 0, # T·∫Øt log cho g·ªçn\n",
    "    'random_state': 42,\n",
    "    'allow_writing_files': False,\n",
    "    'cat_features': valid_cat_features \n",
    "}\n",
    "model_cat = CatBoostRegressor(**cat_params)\n",
    "model_cat.fit(X_train, y_train, eval_set=(X_valid, y_valid_rate), verbose=False)\n",
    "\n",
    "# ==============================================================================\n",
    "# 7. LAYER 2: META-LEARNER (RIDGE REGRESSION) & PREDICTION\n",
    "# ==============================================================================\n",
    "print(\"\\n--- üîÑ Layer 2: Blending & Prediction ---\")\n",
    "\n",
    "# 1. T·∫°o Meta-Features (D·ª± b√°o c·ªßa 3 model tr√™n t·∫≠p Valid v√† Test)\n",
    "def get_preds(model, X):\n",
    "    return np.clip(model.predict(X), 0, 1)\n",
    "\n",
    "# Predict Valid\n",
    "pred_xgb_valid = get_preds(model_xgb, X_valid)\n",
    "pred_lgb_valid = get_preds(model_lgb, X_valid)\n",
    "pred_cat_valid = get_preds(model_cat, X_valid)\n",
    "\n",
    "# Predict Test\n",
    "pred_xgb_test = get_preds(model_xgb, X_test)\n",
    "pred_lgb_test = get_preds(model_lgb, X_test)\n",
    "pred_cat_test = get_preds(model_cat, X_test)\n",
    "\n",
    "# 2. X√¢y d·ª±ng Dataset cho Layer 2\n",
    "X_meta_valid = pd.DataFrame({'XGB': pred_xgb_valid, 'LGB': pred_lgb_valid, 'CAT': pred_cat_valid})\n",
    "X_meta_test = pd.DataFrame({'XGB': pred_xgb_test, 'LGB': pred_lgb_test, 'CAT': pred_cat_test})\n",
    "\n",
    "# 3. Train Meta-Learner (Ridge)\n",
    "meta_model = Ridge(alpha=10.0)\n",
    "meta_model.fit(X_meta_valid, y_valid_rate)\n",
    "\n",
    "# Xem tr·ªçng s·ªë\n",
    "weights = meta_model.coef_\n",
    "print(f\"üìä Tr·ªçng s·ªë Stacking: XGB: {weights[0]:.2f} | LGB: {weights[1]:.2f} | CAT: {weights[2]:.2f}\")\n",
    "\n",
    "# 4. D·ª± b√°o cu·ªëi c√πng (Rate)\n",
    "final_rate_valid = meta_model.predict(X_meta_valid)\n",
    "final_rate_test = meta_model.predict(X_meta_test)\n",
    "\n",
    "# ==============================================================================\n",
    "# 8. H·∫¨U X·ª¨ L√ù & T·∫†O FILE N·ªòP (SUBMISSION)\n",
    "# ==============================================================================\n",
    "\n",
    "def post_process_credits(pred_rate, registered_credits):\n",
    "    \"\"\"Chuy·ªÉn Rate -> Credits v·ªõi c√°c r√†ng bu·ªôc v·∫≠t l√Ω\"\"\"\n",
    "    # Clip Rate\n",
    "    pred_rate = np.clip(pred_rate, 0, 1)\n",
    "    \n",
    "    # Magic Trick: N·∫øu r·∫•t t·ª± tin (>96%), ƒë·∫©y l√™n 100%\n",
    "    pred_rate[pred_rate >= 0.96] = 1.0\n",
    "    \n",
    "    # Convert ra t√≠n ch·ªâ\n",
    "    pred_credits = pred_rate * registered_credits\n",
    "    \n",
    "    # Hard Limit: Kh√¥ng v∆∞·ª£t qu√° ƒëƒÉng k√Ω\n",
    "    pred_credits = np.minimum(pred_credits, registered_credits)\n",
    "    \n",
    "    return pred_credits\n",
    "\n",
    "# ƒê√°nh gi√° RMSE tr√™n t·∫≠p Valid\n",
    "final_credits_valid = post_process_credits(final_rate_valid, valid_dangky)\n",
    "rmse_stacking = np.sqrt(mean_squared_error(y_valid_credits, final_credits_valid))\n",
    "print(f\"\\n>>> ‚úÖ RMSE Stacking (Valid - HK2 23/24): {rmse_stacking:.4f}\")\n",
    "\n",
    "# T·∫°o file n·ªôp b√†i cho Test (HK1 24/25)\n",
    "final_credits_test = post_process_credits(final_rate_test, test_dangky)\n",
    "final_submission = final_credits_test\n",
    "\n",
    "\n",
    "submission_df = pd.DataFrame({\n",
    "    'MA_SO_SV': test_final['MA_SO_SV'],\n",
    "    'PRED_TC_HOANTHANH': final_submission\n",
    "})\n",
    "\n",
    "filename = 'submission_final_stacking.csv'\n",
    "submission_df.to_csv(filename, index=False)\n",
    "print(f\"\\nüéâ ƒê√£ xu·∫•t file th√†nh c√¥ng: {filename}\")\n",
    "print(submission_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6909e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- üìä K·∫æT QU·∫¢ KI·ªÇM TRA ---\n",
      "‚úÖ RMSE : 3.7427 (t√≠n ch·ªâ)\n",
      "‚úÖ R^2  : 0.7158\n",
      "‚úÖ MAPE : 29.43%\n"
     ]
    }
   ],
   "source": [
    "# ...existing code...\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "\n",
    "# ƒê·∫£m b·∫£o final_credits_valid v√† y_valid_credits ƒë√£ s·∫µn s√†ng\n",
    "final_credits_valid = post_process_credits(final_rate_valid, valid_dangky)\n",
    "\n",
    "rmse_val = np.sqrt(mean_squared_error(y_valid_credits, final_credits_valid))\n",
    "r2_val = r2_score(y_valid_credits, final_credits_valid)\n",
    "\n",
    "# MAPE (Ch·ªâ t√≠nh tr√™n nh·ªØng d√≤ng c√≥ ƒëƒÉng k√Ω t√≠n ch·ªâ > 0)\n",
    "mask = y_valid_credits > 0\n",
    "mape_val = mean_absolute_percentage_error(\n",
    "    y_valid_credits[mask],\n",
    "    final_credits_valid[mask]\n",
    ")\n",
    "\n",
    "print(f\"--- üìä K·∫æT QU·∫¢ KI·ªÇM TRA ---\")\n",
    "print(f\"‚úÖ RMSE : {rmse_val:.4f} (t√≠n ch·ªâ)\")\n",
    "print(f\"‚úÖ R^2  : {r2_val:.4f}\")\n",
    "print(f\"‚úÖ MAPE : {mape_val:.2%}\")\n",
    "# ...existing code..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
