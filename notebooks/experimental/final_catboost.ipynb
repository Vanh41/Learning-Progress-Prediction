{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33cb305a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ACADEMIC_PATH = r'../../data/raw/academic_records.csv'\n",
    "ADMISSION_PATH = r'../../data/raw/admission.csv'\n",
    "TEST_PATH = r'../../data/raw/test.csv'\n",
    "academic_records = pd.read_csv(ACADEMIC_PATH)\n",
    "admission = pd.read_csv(ADMISSION_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "baab92f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = '42'\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "np.random.set_state(np.random.RandomState(42).get_state())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24277805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- üöÄ B·∫ÆT ƒê·∫¶U QUY TR√åNH L√ÄM S·∫†CH D·ªÆ LI·ªÜU (FIXED VERSION) ---\n",
      "-> ƒêang x·ª≠ l√Ω c·ªôt HOC_KY...\n",
      "--- ‚úÖ HO√ÄN T·∫§T. K√≠ch th∆∞·ªõc data: (105726, 14) ---\n",
      "Sample HOC_KY_INT: [20231, 20232, 20211, 20212, 20221]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MA_SO_SV</th>\n",
       "      <th>HOC_KY</th>\n",
       "      <th>CPA</th>\n",
       "      <th>GPA</th>\n",
       "      <th>TC_DANGKY</th>\n",
       "      <th>TC_HOANTHANH</th>\n",
       "      <th>HOC_KY_INT</th>\n",
       "      <th>NAM_TUYENSINH</th>\n",
       "      <th>PTXT</th>\n",
       "      <th>TOHOP_XT</th>\n",
       "      <th>DIEM_TRUNGTUYEN</th>\n",
       "      <th>DIEM_CHUAN</th>\n",
       "      <th>COMPLETION_RATE</th>\n",
       "      <th>ADMISSION_GAP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00003e092652</td>\n",
       "      <td>HK1 2023-2024</td>\n",
       "      <td>1.64</td>\n",
       "      <td>1.97</td>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "      <td>20231</td>\n",
       "      <td>2023</td>\n",
       "      <td>100</td>\n",
       "      <td>A00</td>\n",
       "      <td>21.32</td>\n",
       "      <td>20.25</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00003e092652</td>\n",
       "      <td>HK2 2023-2024</td>\n",
       "      <td>1.53</td>\n",
       "      <td>2.05</td>\n",
       "      <td>18</td>\n",
       "      <td>13</td>\n",
       "      <td>20232</td>\n",
       "      <td>2023</td>\n",
       "      <td>100</td>\n",
       "      <td>A00</td>\n",
       "      <td>21.32</td>\n",
       "      <td>20.25</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>1.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000e15519006</td>\n",
       "      <td>HK1 2021-2022</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.85</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>20211</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>D07</td>\n",
       "      <td>23.84</td>\n",
       "      <td>22.43</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000e15519006</td>\n",
       "      <td>HK2 2021-2022</td>\n",
       "      <td>2.77</td>\n",
       "      <td>3.12</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>20212</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>D07</td>\n",
       "      <td>23.84</td>\n",
       "      <td>22.43</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000e15519006</td>\n",
       "      <td>HK1 2022-2023</td>\n",
       "      <td>2.83</td>\n",
       "      <td>2.98</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>20221</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>D07</td>\n",
       "      <td>23.84</td>\n",
       "      <td>22.43</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       MA_SO_SV         HOC_KY   CPA   GPA  TC_DANGKY  TC_HOANTHANH  \\\n",
       "0  00003e092652  HK1 2023-2024  1.64  1.97         18            15   \n",
       "1  00003e092652  HK2 2023-2024  1.53  2.05         18            13   \n",
       "2  000e15519006  HK1 2021-2022  3.85  3.85          9             9   \n",
       "3  000e15519006  HK2 2021-2022  2.77  3.12         19            19   \n",
       "4  000e15519006  HK1 2022-2023  2.83  2.98         21            21   \n",
       "\n",
       "   HOC_KY_INT  NAM_TUYENSINH PTXT TOHOP_XT  DIEM_TRUNGTUYEN  DIEM_CHUAN  \\\n",
       "0       20231           2023  100      A00            21.32       20.25   \n",
       "1       20232           2023  100      A00            21.32       20.25   \n",
       "2       20211           2021    1      D07            23.84       22.43   \n",
       "3       20212           2021    1      D07            23.84       22.43   \n",
       "4       20221           2021    1      D07            23.84       22.43   \n",
       "\n",
       "   COMPLETION_RATE  ADMISSION_GAP  \n",
       "0         0.833333           1.07  \n",
       "1         0.722222           1.07  \n",
       "2         1.000000           1.41  \n",
       "3         1.000000           1.41  \n",
       "4         1.000000           1.41  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# --- H√ÄM M·ªöI: X·ª≠ l√Ω ƒë·ªãnh d·∫°ng h·ªçc k·ª≥ ph·ª©c t·∫°p ---\n",
    "def parse_semester_string(sem_str):\n",
    "    \"\"\"\n",
    "    Chuy·ªÉn ƒë·ªïi chu·ªói nh∆∞ 'HK1 2023-2024' th√†nh m√£ s·ªë 20231 ƒë·ªÉ sort ƒë∆∞·ª£c.\n",
    "    Logic: NƒÉm * 10 + K·ª≥\n",
    "    \"\"\"\n",
    "    s = str(sem_str).strip()\n",
    "    \n",
    "    # Tr∆∞·ªùng h·ª£p 1: D·∫°ng s·ªë s·∫µn (VD: 20231)\n",
    "    if s.isdigit():\n",
    "        return int(s)\n",
    "    \n",
    "    # Tr∆∞·ªùng h·ª£p 2: D·∫°ng ch·ªØ (VD: HK1 2023-2024 ho·∫∑c H·ªçc k·ª≥ 1 nƒÉm 2023)\n",
    "    # T√¨m t·∫•t c·∫£ c√°c con s·ªë trong chu·ªói\n",
    "    digits = re.findall(r'\\d+', s)\n",
    "    \n",
    "    if len(digits) >= 2:\n",
    "        # Gi·∫£ s·ª≠ s·ªë nh·ªè l√† k·ª≥, s·ªë l·ªõn (4 ch·ªØ s·ªë) l√† nƒÉm\n",
    "        # T√¨m nƒÉm (th∆∞·ªùng l√† s·ªë c√≥ 4 ch·ªØ s·ªë ƒë·∫ßu ti√™n t√¨m th·∫•y)\n",
    "        years = [int(d) for d in digits if len(d) == 4]\n",
    "        sems = [int(d) for d in digits if len(d) == 1]\n",
    "        \n",
    "        if years and sems:\n",
    "            year = years[0]\n",
    "            sem = sems[0]\n",
    "            return year * 10 + sem\n",
    "            \n",
    "    return 0 # Kh√¥ng x√°c ƒë·ªãnh\n",
    "\n",
    "def clean_data_pipeline_v3(admission, academic_records):\n",
    "    print(\"--- üöÄ B·∫ÆT ƒê·∫¶U QUY TR√åNH L√ÄM S·∫†CH D·ªÆ LI·ªÜU (FIXED VERSION) ---\")\n",
    "    \n",
    "    adm = admission.copy()\n",
    "    acad = academic_records.copy()\n",
    "    \n",
    "    # 1. Chu·∫©n h√≥a ID\n",
    "    adm['MA_SO_SV'] = adm['MA_SO_SV'].astype(str)\n",
    "    acad['MA_SO_SV'] = acad['MA_SO_SV'].astype(str)\n",
    "    \n",
    "    # ---------------------------------------------------------\n",
    "    # [FIX QUAN TR·ªåNG] X·ª≠ l√Ω HOC_KY th√¥ng minh h∆°n\n",
    "    # ---------------------------------------------------------\n",
    "    print(\"-> ƒêang x·ª≠ l√Ω c·ªôt HOC_KY...\")\n",
    "    # T·∫°o c·ªôt HOC_KY_INT d√πng ƒë·ªÉ sort (VD: 20231)\n",
    "    acad['HOC_KY_INT'] = acad['HOC_KY'].apply(parse_semester_string)\n",
    "    \n",
    "    # Ki·ªÉm tra xem c√≥ d√≤ng n√†o b·ªã l·ªói (b·∫±ng 0) kh√¥ng\n",
    "    error_count = (acad['HOC_KY_INT'] == 0).sum()\n",
    "    if error_count > 0:\n",
    "        print(f\"   ‚ö†Ô∏è C·∫£nh b√°o: C√≥ {error_count} d√≤ng kh√¥ng ƒë·ªçc ƒë∆∞·ª£c HOC_KY.\")\n",
    "\n",
    "    # Merge d·ªØ li·ªáu\n",
    "    df = pd.merge(acad, adm, on='MA_SO_SV', how='left')\n",
    "    \n",
    "    # S·∫Øp x·∫øp theo Time-series chu·∫©n x√°c d·ª±a tr√™n c·ªôt v·ª´a t·∫°o\n",
    "    df = df.sort_values(by=['MA_SO_SV', 'HOC_KY_INT']).reset_index(drop=True)\n",
    "    \n",
    "    # ---------------------------------------------------------\n",
    "    # 2. X·ª¨ L√ù S·ªê LI·ªÜU & LOGIC\n",
    "    # ---------------------------------------------------------\n",
    "    cols_float = ['GPA', 'CPA', 'DIEM_TRUNGTUYEN', 'DIEM_CHUAN']\n",
    "    cols_int = ['TC_DANGKY', 'TC_HOANTHANH']\n",
    "    \n",
    "    for col in cols_float:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "        \n",
    "    for col in cols_int:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "    # Logic: Ho√†n th√†nh <= ƒêƒÉng k√Ω\n",
    "    df['TC_HOANTHANH'] = np.minimum(df['TC_HOANTHANH'], df['TC_DANGKY'])\n",
    "    \n",
    "    # Target Transformation\n",
    "    df['COMPLETION_RATE'] = df['TC_HOANTHANH'] / (df['TC_DANGKY'] + 1e-9)\n",
    "    df['COMPLETION_RATE'] = df['COMPLETION_RATE'].clip(0, 1)\n",
    "\n",
    "    # Clip ƒëi·ªÉm s·ªë\n",
    "    df['GPA'] = df['GPA'].clip(0, 4.0)\n",
    "    df['CPA'] = df['CPA'].clip(0, 4.0)\n",
    "\n",
    "    # Admission Gap Feature\n",
    "    if 'DIEM_TRUNGTUYEN' in df.columns and 'DIEM_CHUAN' in df.columns:\n",
    "        df['ADMISSION_GAP'] = df['DIEM_TRUNGTUYEN'] - df['DIEM_CHUAN']\n",
    "    \n",
    "    # L·ªçc r√°c\n",
    "    initial_len = len(df)\n",
    "    df = df[df['TC_DANGKY'] > 0]\n",
    "    \n",
    "    print(f\"--- ‚úÖ HO√ÄN T·∫§T. K√≠ch th∆∞·ªõc data: {df.shape} ---\")\n",
    "    print(\"Sample HOC_KY_INT:\", df['HOC_KY_INT'].head().tolist())\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Ch·∫°y th·ª≠ l·∫°i\n",
    "df_clean = clean_data_pipeline_v3(admission, academic_records)\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "988378bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- B·∫ÆT ƒê·∫¶U PIPELINE ---\n",
      "--- üöÄ 1. PREPROCESSING DATA ---\n",
      "--- üöÄ 1. PREPROCESSING DATA ---\n",
      "--- ‚ö° 2. FEATURE ENGINEERING (FULL POWER) ---\n",
      "‚úÖ Xong! S·ªë l∆∞·ª£ng Features: 24\n",
      "Sample Features: ['TC_DANGKY', 'PTXT', 'TOHOP_XT', 'DIEM_TRUNGTUYEN', 'DIEM_CHUAN']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. C√ÅC H√ÄM TI·ªÜN √çCH (UTILS)\n",
    "# ==============================================================================\n",
    "\n",
    "def parse_semester_string(sem_str):\n",
    "    \"\"\"\n",
    "    Chuy·ªÉn ƒë·ªïi 'HK1 2023-2024' -> 20231 (Int) ƒë·ªÉ sort time-series.\n",
    "    \"\"\"\n",
    "    s = str(sem_str).strip()\n",
    "    if s.isdigit(): return int(s)\n",
    "    \n",
    "    digits = re.findall(r'\\d+', s)\n",
    "    if len(digits) >= 2:\n",
    "        years = [int(d) for d in digits if len(d) == 4]\n",
    "        sems = [int(d) for d in digits if len(d) == 1]\n",
    "        if years and sems:\n",
    "            return years[0] * 10 + sems[0]\n",
    "    return 0\n",
    "\n",
    "def fast_slope(y):\n",
    "    \"\"\"\n",
    "    T√≠nh h·ªá s·ªë g√≥c (Trend) nhanh.\n",
    "    Input: Array numpy (c√≥ th·ªÉ ch·ª©a NaN).\n",
    "    \"\"\"\n",
    "    # L·ªçc b·ªè NaN tr∆∞·ªõc khi t√≠nh (Quan tr·ªçng!)\n",
    "    y_clean = y[~np.isnan(y)]\n",
    "    n = len(y_clean)\n",
    "    if n < 2: return 0.0\n",
    "    \n",
    "    x = np.arange(n)\n",
    "    x_mean = np.mean(x)\n",
    "    y_mean = np.mean(y_clean)\n",
    "    \n",
    "    numerator = np.sum((x - x_mean) * (y_clean - y_mean))\n",
    "    denominator = np.sum((x - x_mean) ** 2)\n",
    "    \n",
    "    return numerator / (denominator + 1e-6)\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. DATA PREPROCESSING PIPELINE\n",
    "# ==============================================================================\n",
    "\n",
    "def clean_data_pipeline(admission, academic_records, is_test=False):\n",
    "    print(\"--- üöÄ 1. PREPROCESSING DATA ---\")\n",
    "    adm = admission.copy()\n",
    "    acad = academic_records.copy()\n",
    "    \n",
    "    # Chu·∫©n h√≥a ID\n",
    "    adm['MA_SO_SV'] = adm['MA_SO_SV'].astype(str)\n",
    "    acad['MA_SO_SV'] = acad['MA_SO_SV'].astype(str)\n",
    "    \n",
    "    # T·∫°o Time-Index\n",
    "    acad['semester_order'] = acad['HOC_KY'].apply(parse_semester_string)\n",
    "    \n",
    "    # Merge\n",
    "    df = pd.merge(acad, adm, on='MA_SO_SV', how='left')\n",
    "    \n",
    "    # Sort Time-Series (C·ª∞C K·ª≤ QUAN TR·ªåNG)\n",
    "    df = df.sort_values(by=['MA_SO_SV', 'semester_order']).reset_index(drop=True)\n",
    "    \n",
    "    # Numeric conversion\n",
    "    cols_float = ['GPA', 'CPA', 'DIEM_TRUNGTUYEN', 'DIEM_CHUAN']\n",
    "    cols_int = ['TC_DANGKY', 'TC_HOANTHANH']\n",
    "    \n",
    "    for col in cols_float:\n",
    "        if col in df.columns: df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    for col in cols_int:\n",
    "        if col in df.columns: df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "    # Logic clean\n",
    "    if not is_test:\n",
    "        df['TC_HOANTHANH'] = np.minimum(df['TC_HOANTHANH'], df['TC_DANGKY'])\n",
    "        df['GPA'] = df['GPA'].clip(0, 4.0)\n",
    "        df['CPA'] = df['CPA'].clip(0, 4.0)\n",
    "    \n",
    "    # Target Transformation (Ch·ªâ d√πng cho train)\n",
    "    if not is_test:\n",
    "        df['COMPLETION_RATE'] = df['TC_HOANTHANH'] / (df['TC_DANGKY'] + 1e-9)\n",
    "        df['COMPLETION_RATE'] = df['COMPLETION_RATE'].clip(0, 1)\n",
    "\n",
    "    return df\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. FEATURE ENGINEERING CLASS (CORE)\n",
    "# ==============================================================================\n",
    "\n",
    "class FeatureEngineer:    \n",
    "    def __init__(self):\n",
    "        # C√°c c·ªôt Category s·∫Ω gi·ªØ l·∫°i\n",
    "        self.cat_cols = ['PTXT', 'TOHOP_XT', 'MA_NGANH', 'KV_UT', 'KHOA_VIEN'] \n",
    "\n",
    "    def create_features(self, df):\n",
    "        print(\"--- ‚ö° 2. FEATURE ENGINEERING (FULL POWER) ---\")\n",
    "        df = df.copy()\n",
    "        \n",
    "        # Sort l·∫°i cho ch·∫Øc ch·∫Øn\n",
    "        df = df.sort_values(['MA_SO_SV', 'semester_order']).reset_index(drop=True)\n",
    "        \n",
    "        # Convert Category\n",
    "        for col in self.cat_cols:\n",
    "            if col in df.columns:\n",
    "                df[col] = df[col].astype(str).astype('category')\n",
    "\n",
    "        # Groupby object\n",
    "        g = df.groupby('MA_SO_SV')\n",
    "\n",
    "        # ---------------------------------------------------------\n",
    "        # A. BASE LAGS (C·ª±c k·ª≥ quan tr·ªçng: D√πng shift(1) ƒë·ªÉ tr√°nh Leakage)\n",
    "        # ---------------------------------------------------------\n",
    "        # T·∫°o bi·∫øn Raw (ch·ª©a NaN) ƒë·ªÉ t√≠nh to√°n th·ªëng k√™ ch√≠nh x√°c h∆°n\n",
    "        df['Prev_GPA_Raw'] = g['GPA'].shift(1)\n",
    "        \n",
    "        # T·∫°o bi·∫øn Fill (ƒë·ªÉ model d√πng tr·ª±c ti·∫øp)\n",
    "        df['Prev_GPA'] = df['Prev_GPA_Raw'].fillna(-1)\n",
    "        df['Prev_CPA'] = g['CPA'].shift(1).fillna(-1)\n",
    "        df['Prev_TC_HOANTHANH'] = g['TC_HOANTHANH'].shift(1).fillna(0)\n",
    "        df['Prev_TC_DANGKY'] = g['TC_DANGKY'].shift(1).fillna(0)\n",
    "        \n",
    "        # C·ªù nƒÉm nh·∫•t (Ch∆∞a c√≥ l·ªãch s·ª≠)\n",
    "        df['is_freshman'] = (df['Prev_TC_DANGKY'] == 0).astype(int)\n",
    "\n",
    "        # ---------------------------------------------------------\n",
    "        # B. G·ªåI C√ÅC NH√ìM FEATURE\n",
    "        # ---------------------------------------------------------\n",
    "        df = self._create_admission_features(df)\n",
    "        df = self._create_history_features(df)\n",
    "        df = self._create_trend_features(df)  # <--- Slope, Volatility n·∫±m ·ªü ƒë√¢y\n",
    "        df = self._create_risk_features(df)\n",
    "        \n",
    "        # D·ªçn d·∫πp c·ªôt t·∫°m\n",
    "        if 'Prev_GPA_Raw' in df.columns:\n",
    "            df = df.drop(columns=['Prev_GPA_Raw'])\n",
    "            \n",
    "        return df\n",
    "\n",
    "    def _create_admission_features(self, df):\n",
    "        # Kho·∫£ng c√°ch ƒëi·ªÉm ƒë·∫ßu v√†o\n",
    "        if 'DIEM_TRUNGTUYEN' in df.columns and 'DIEM_CHUAN' in df.columns:\n",
    "            df['diem_vuot_chuan'] = df['DIEM_TRUNGTUYEN'] - df['DIEM_CHUAN']\n",
    "        \n",
    "        # Tu·ªïi (gi·∫£ ƒë·ªãnh nƒÉm hi·ªán t·∫°i 2025/2026)\n",
    "        if 'NAM_TUYENSINH' in df.columns:\n",
    "            df['nam_tuoi'] = 2026 - df['NAM_TUYENSINH']\n",
    "            \n",
    "        # S·ªë k·ª≥ ƒë√£ h·ªçc (t√≠nh t·ª´ nƒÉm nh·∫≠p h·ªçc)\n",
    "        df['semester_number'] = df.groupby('MA_SO_SV').cumcount() + 1\n",
    "        return df\n",
    "\n",
    "    def _create_history_features(self, df):\n",
    "        # 1. Delta GPA-CPA: ƒêang h·ªçc t·ªët h∆°n hay t·ªá h∆°n trung b√¨nh t√≠ch l≈©y?\n",
    "        df['prev_gpa_cpa_diff'] = df['Prev_GPA'] - df['Prev_CPA']\n",
    "        \n",
    "        # 2. T·ª∑ l·ªá ho√†n th√†nh k·ª≥ tr∆∞·ªõc\n",
    "        df['prev_completion_rate'] = df['Prev_TC_HOANTHANH'] / (df['Prev_TC_DANGKY'] + 1e-9)\n",
    "        \n",
    "        # 3. Load Factor (√Åp l·ª±c): ƒêƒÉng k√Ω k·ª≥ n√†y / S·ª©c h·ªçc trung b√¨nh\n",
    "        avg_capacity = df.groupby('MA_SO_SV')['Prev_TC_HOANTHANH'].transform(\n",
    "            lambda x: x.rolling(window=5, min_periods=1).mean()\n",
    "        ).fillna(15)\n",
    "        \n",
    "        df['load_factor'] = df['TC_DANGKY'] / (avg_capacity + 1e-9)\n",
    "        \n",
    "        # Bi·∫øn c·ªù: R·ªõt m√¥n k·ª≥ tr∆∞·ªõc\n",
    "        df['failed_last_sem'] = (df['Prev_TC_HOANTHANH'] < df['Prev_TC_DANGKY']).astype(int)\n",
    "        \n",
    "        return df\n",
    "\n",
    "    def _create_trend_features(self, df):\n",
    "        # S·ª≠ d·ª•ng Prev_GPA_Raw (c√≥ NaN) ƒë·ªÉ t√≠nh Slope ch√≠nh x√°c\n",
    "        # N·∫øu d√πng Prev_GPA (c√≥ -1), Slope s·∫Ω b·ªã sai l·ªách l·ªõn\n",
    "        g_raw = df.groupby('MA_SO_SV')['Prev_GPA_Raw']\n",
    "        \n",
    "        # 1. GPA Slope (Xu h∆∞·ªõng ƒëi·ªÉm)\n",
    "        df['gpa_trend_slope'] = g_raw.transform(\n",
    "            lambda x: x.rolling(window=3, min_periods=2).apply(fast_slope, raw=True)\n",
    "        ).fillna(0)\n",
    "        \n",
    "        # 2. [RECOVERED] GPA Volatility (ƒê·ªô ·ªïn ƒë·ªãnh)\n",
    "        df['gpa_volatility'] = g_raw.transform(\n",
    "            lambda x: x.rolling(window=4, min_periods=2).std()\n",
    "        ).fillna(0)\n",
    "        \n",
    "        # 3. T√≠ch l≈©y t√≠n ch·ªâ (History)\n",
    "        grouped = df.groupby('MA_SO_SV')\n",
    "        cum_dangky = grouped['Prev_TC_DANGKY'].cumsum()\n",
    "        cum_hoanthanh = grouped['Prev_TC_HOANTHANH'].cumsum()\n",
    "        \n",
    "        df['total_credits_failed'] = cum_dangky - cum_hoanthanh\n",
    "        df['accumulated_fail_ratio'] = df['total_credits_failed'] / (cum_dangky + 1e-9)\n",
    "        \n",
    "        # 4. [RECOVERED] Credit Velocity (T·ªëc ƒë·ªô h·ªçc)\n",
    "        semester_count = grouped.cumcount() + 1\n",
    "        df['credit_velocity'] = cum_hoanthanh / semester_count\n",
    "        \n",
    "        return df\n",
    "\n",
    "    def _create_risk_features(self, df):\n",
    "        # H√†nh vi \"G·ª° g·∫°c\" (Aggressive Recovery): R·ªõt m√¥n k·ª≥ tr∆∞·ªõc -> ƒêƒÉng k√Ω nhi·ªÅu h∆°n k·ª≥ n√†y\n",
    "        more_credits = (df['TC_DANGKY'] > df['Prev_TC_DANGKY'])\n",
    "        df['aggressive_recovery'] = (df['failed_last_sem'] & more_credits).astype(int)\n",
    "        \n",
    "        # K·ª≥ v·ªçng ho√†n th√†nh (Expected Credits) = ƒêƒÉng k√Ω * T·ª∑ l·ªá ƒë·∫≠u to√†n c·ª•c c·ªßa SV ƒë√≥\n",
    "        df['expected_real_credits'] = df['TC_DANGKY'] * (1 - df['accumulated_fail_ratio'])\n",
    "        \n",
    "        return df\n",
    "\n",
    "    def get_feature_columns(self, df):\n",
    "        \"\"\"T·ª± ƒë·ªông l·∫•y danh s√°ch feature d·ª±a tr√™n prefix\"\"\"\n",
    "        \n",
    "        # Whitelist c√°c prefix\n",
    "        valid_prefixes = [\n",
    "            'Prev_', 'prev_', 'sem_', 'diem_', 'nam_', 'is_', \n",
    "            'load_', 'aggressive_', 'gpa_', 'total_', 'accumulated_',\n",
    "            'credit_', 'expected_', 'failed_'\n",
    "        ]\n",
    "        \n",
    "        valid_exact = ['TC_DANGKY', 'DIEM_TRUNGTUYEN', 'DIEM_CHUAN', 'semester_number']\n",
    "        valid_exact.extend(self.cat_cols)\n",
    "        \n",
    "        final_cols = []\n",
    "        # C√°c c·ªôt target/meta c·∫ßn lo·∫°i b·ªè\n",
    "        ignore_cols = ['TC_HOANTHANH', 'GPA', 'CPA', 'semester_order', 'MA_SO_SV', 'HOC_KY', 'COMPLETION_RATE', 'Prev_GPA_Raw']\n",
    "        \n",
    "        for col in df.columns:\n",
    "            if col in ignore_cols: continue\n",
    "            \n",
    "            is_valid = False\n",
    "            if col in valid_exact: is_valid = True\n",
    "            else:\n",
    "                for prefix in valid_prefixes:\n",
    "                    if col.startswith(prefix):\n",
    "                        is_valid = True\n",
    "                        break\n",
    "            \n",
    "            if is_valid: final_cols.append(col)\n",
    "                \n",
    "        return final_cols\n",
    "\n",
    "# ==============================================================================\n",
    "# 4. EXECUTION BLOCK (CH·∫†Y TH·ª¨)\n",
    "# ==============================================================================\n",
    "\n",
    "\n",
    "test_raw = pd.read_csv(TEST_PATH)\n",
    "\n",
    "print(\"--- B·∫ÆT ƒê·∫¶U PIPELINE ---\")\n",
    "\n",
    "# 1. Clean Data\n",
    "df_train_raw = clean_data_pipeline(admission, academic_records, is_test=False)\n",
    "\n",
    "# 2. Chu·∫©n b·ªã Test (G√°n dummy values ƒë·ªÉ ch·∫°y ƒë∆∞·ª£c pipeline)\n",
    "test_copy = test_raw.copy()\n",
    "for col in ['TC_HOANTHANH', 'GPA', 'CPA']: test_copy[col] = 0\n",
    "df_test_raw = clean_data_pipeline(admission, test_copy, is_test=True)\n",
    "\n",
    "# 3. G·ªôp Train + Test ƒë·ªÉ t·∫°o feature (Tr√°nh bi√™n gi·ªõi gi·ªØa c√°c k·ª≥ b·ªã ƒë·ª©t g√£y)\n",
    "df_train_raw['set_type'] = 'TRAIN'\n",
    "df_test_raw['set_type'] = 'TEST'\n",
    "full_df = pd.concat([df_train_raw, df_test_raw], ignore_index=True)\n",
    "\n",
    "# 4. Feature Engineering\n",
    "fe = FeatureEngineer()\n",
    "full_df_fe = fe.create_features(full_df)\n",
    "\n",
    "# 5. T√°ch l·∫°i Train/Test\n",
    "train_final = full_df_fe[full_df_fe['set_type'] == 'TRAIN'].copy()\n",
    "test_final = full_df_fe[full_df_fe['set_type'] == 'TEST'].copy()\n",
    "\n",
    "# 6. L·∫•y features & Target\n",
    "feature_cols = fe.get_feature_columns(train_final)\n",
    "X = train_final[feature_cols]\n",
    "y = train_final['TC_HOANTHANH'] # Ho·∫∑c d√πng COMPLETION_RATE n·∫øu mu·ªën\n",
    "\n",
    "print(f\"‚úÖ Xong! S·ªë l∆∞·ª£ng Features: {len(feature_cols)}\")\n",
    "print(f\"Sample Features: {feature_cols[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b052482",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-04 01:20:15,050]\u001b[0m A new study created in memory with name: no-name-68204a14-9b79-438b-919c-d569773c05bf\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- üöÄ TRAINING PHASE (CATBOOST) ---\n",
      "Train: (90582, 24) | Valid: (15144, 24)\n",
      "Categorical features: 2 detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-04 01:20:54,949]\u001b[0m Trial 0 finished with value: 3.7647938543557884 and parameters: {'learning_rate': 0.020125122806509764, 'depth': 4, 'l2_leaf_reg': 6.394669210571399, 'random_strength': 2.5505972389300653, 'min_data_in_leaf': 6, 'subsample': 0.9129544836328539, 'rsm': 0.7865221705115406}. Best is trial 0 with value: 3.7647938543557884.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 01:21:45,812]\u001b[0m Trial 1 finished with value: 3.765662893969169 and parameters: {'learning_rate': 0.02204424511294725, 'depth': 5, 'l2_leaf_reg': 1.132572610439031, 'random_strength': 4.28875744982133, 'min_data_in_leaf': 11, 'subsample': 0.630565860654738, 'rsm': 0.6414295000207022}. Best is trial 0 with value: 3.7647938543557884.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 01:22:52,206]\u001b[0m Trial 2 finished with value: 3.779204436575518 and parameters: {'learning_rate': 0.01057782897556377, 'depth': 3, 'l2_leaf_reg': 4.571478494211705, 'random_strength': 4.283802833529106, 'min_data_in_leaf': 15, 'subsample': 0.9210142825145325, 'rsm': 0.7080611878117805}. Best is trial 0 with value: 3.7647938543557884.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 01:23:39,168]\u001b[0m Trial 3 finished with value: 3.7748881034243147 and parameters: {'learning_rate': 0.038805849109828455, 'depth': 5, 'l2_leaf_reg': 7.137312314541019, 'random_strength': 2.987607357519818, 'min_data_in_leaf': 19, 'subsample': 0.9096313919742438, 'rsm': 0.983531818807559}. Best is trial 0 with value: 3.7647938543557884.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 01:24:31,065]\u001b[0m Trial 4 finished with value: 3.755137797626358 and parameters: {'learning_rate': 0.03376981490409609, 'depth': 9, 'l2_leaf_reg': 5.642182120551769, 'random_strength': 2.7757419526433074, 'min_data_in_leaf': 8, 'subsample': 0.8554515957610298, 'rsm': 0.6730511792964202}. Best is trial 4 with value: 3.755137797626358.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 01:26:08,552]\u001b[0m Trial 5 finished with value: 3.753144874451797 and parameters: {'learning_rate': 0.015274404257601917, 'depth': 8, 'l2_leaf_reg': 9.607435350390585, 'random_strength': 1.694431181993667, 'min_data_in_leaf': 1, 'subsample': 0.7223741784926677, 'rsm': 0.8194131612747175}. Best is trial 5 with value: 3.753144874451797.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 01:26:34,886]\u001b[0m Trial 6 finished with value: 3.76645679884654 and parameters: {'learning_rate': 0.03838328429310747, 'depth': 5, 'l2_leaf_reg': 4.140031742704243, 'random_strength': 2.0337739943121087, 'min_data_in_leaf': 7, 'subsample': 0.9355359251189294, 'rsm': 0.696297916901197}. Best is trial 5 with value: 3.753144874451797.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 01:26:55,862]\u001b[0m Trial 7 finished with value: 3.785478563317599 and parameters: {'learning_rate': 0.048828123267454976, 'depth': 3, 'l2_leaf_reg': 9.815901771444107, 'random_strength': 3.1049446644428227, 'min_data_in_leaf': 16, 'subsample': 0.9727586931976319, 'rsm': 0.6191888776228439}. Best is trial 5 with value: 3.753144874451797.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 01:27:56,685]\u001b[0m Trial 8 finished with value: 3.7775524206185476 and parameters: {'learning_rate': 0.012012315023847288, 'depth': 3, 'l2_leaf_reg': 9.564436141554793, 'random_strength': 3.2390531110050875, 'min_data_in_leaf': 17, 'subsample': 0.7974339210521586, 'rsm': 0.7766480740836751}. Best is trial 5 with value: 3.753144874451797.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 01:28:15,508]\u001b[0m Trial 9 finished with value: 3.7851660719905795 and parameters: {'learning_rate': 0.04858784176770192, 'depth': 3, 'l2_leaf_reg': 2.313888172410482, 'random_strength': 2.7183036322515277, 'min_data_in_leaf': 20, 'subsample': 0.7038034383185934, 'rsm': 0.7960312958148024}. Best is trial 5 with value: 3.753144874451797.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 01:31:28,699]\u001b[0m Trial 10 finished with value: 3.7456088489376693 and parameters: {'learning_rate': 0.006262369411758976, 'depth': 9, 'l2_leaf_reg': 8.058691980129963, 'random_strength': 0.6396448073811019, 'min_data_in_leaf': 1, 'subsample': 0.7573812580723531, 'rsm': 0.9332070171838015}. Best is trial 10 with value: 3.7456088489376693.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 01:35:33,538]\u001b[0m Trial 11 finished with value: 3.7434044000921585 and parameters: {'learning_rate': 0.0054752493268097144, 'depth': 9, 'l2_leaf_reg': 8.2130577123651, 'random_strength': 0.8609084940278988, 'min_data_in_leaf': 1, 'subsample': 0.7393999856798126, 'rsm': 0.9344658710877101}. Best is trial 11 with value: 3.7434044000921585.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 01:39:34,466]\u001b[0m Trial 12 finished with value: 3.742465254430813 and parameters: {'learning_rate': 0.005230772605704711, 'depth': 8, 'l2_leaf_reg': 8.046856094613936, 'random_strength': 0.5629725560982365, 'min_data_in_leaf': 1, 'subsample': 0.7724183986508066, 'rsm': 0.9637470751606662}. Best is trial 12 with value: 3.742465254430813.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 01:43:07,193]\u001b[0m Trial 13 finished with value: 3.740685303093014 and parameters: {'learning_rate': 0.005368493151467868, 'depth': 7, 'l2_leaf_reg': 7.953658380005995, 'random_strength': 0.5512073083752838, 'min_data_in_leaf': 4, 'subsample': 0.6500970577013601, 'rsm': 0.9062302353719649}. Best is trial 13 with value: 3.740685303093014.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 01:44:26,062]\u001b[0m Trial 14 finished with value: 3.7451973654449495 and parameters: {'learning_rate': 0.0265718493398731, 'depth': 7, 'l2_leaf_reg': 7.8413995738072355, 'random_strength': 1.2956676678288286, 'min_data_in_leaf': 4, 'subsample': 0.6003314704478402, 'rsm': 0.8796977229432092}. Best is trial 13 with value: 3.740685303093014.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 01:46:07,536]\u001b[0m Trial 15 finished with value: 3.74699044274378 and parameters: {'learning_rate': 0.015947765091395574, 'depth': 7, 'l2_leaf_reg': 6.825784527203896, 'random_strength': 0.5310490652033453, 'min_data_in_leaf': 4, 'subsample': 0.664649111381057, 'rsm': 0.9971093554267149}. Best is trial 13 with value: 3.740685303093014.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 01:51:07,560]\u001b[0m Trial 16 finished with value: 3.7436382457898856 and parameters: {'learning_rate': 0.005145917688739881, 'depth': 10, 'l2_leaf_reg': 8.61865467941987, 'random_strength': 1.2876260900308294, 'min_data_in_leaf': 11, 'subsample': 0.828730748471835, 'rsm': 0.8740978769774219}. Best is trial 13 with value: 3.740685303093014.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 01:53:41,253]\u001b[0m Trial 17 finished with value: 3.7508177203181234 and parameters: {'learning_rate': 0.011612062529796676, 'depth': 6, 'l2_leaf_reg': 5.546882016052845, 'random_strength': 1.159682330378717, 'min_data_in_leaf': 3, 'subsample': 0.6750598864547289, 'rsm': 0.9153251239646194}. Best is trial 13 with value: 3.740685303093014.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 01:55:15,390]\u001b[0m Trial 18 finished with value: 3.7405552762827545 and parameters: {'learning_rate': 0.021340888417346375, 'depth': 8, 'l2_leaf_reg': 3.9421067381353634, 'random_strength': 1.996318823637844, 'min_data_in_leaf': 8, 'subsample': 0.7841951767238591, 'rsm': 0.8538050603662779}. Best is trial 18 with value: 3.7405552762827545.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 01:56:30,442]\u001b[0m Trial 19 finished with value: 3.7681421458630275 and parameters: {'learning_rate': 0.02831672414492449, 'depth': 6, 'l2_leaf_reg': 3.829077721952748, 'random_strength': 3.6449065519200463, 'min_data_in_leaf': 9, 'subsample': 0.8322097677907466, 'rsm': 0.8455119033198937}. Best is trial 18 with value: 3.7405552762827545.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 01:57:58,229]\u001b[0m Trial 20 finished with value: 3.7478832676816913 and parameters: {'learning_rate': 0.021745567186321698, 'depth': 8, 'l2_leaf_reg': 3.131203773287776, 'random_strength': 1.9761204001795745, 'min_data_in_leaf': 13, 'subsample': 0.6764040655055281, 'rsm': 0.7440086229878144}. Best is trial 18 with value: 3.7405552762827545.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 02:01:38,086]\u001b[0m Trial 21 finished with value: 3.7504989481289086 and parameters: {'learning_rate': 0.009654825804298887, 'depth': 8, 'l2_leaf_reg': 5.239067603984416, 'random_strength': 4.896268223458766, 'min_data_in_leaf': 5, 'subsample': 0.7821541920501123, 'rsm': 0.9609044986740185}. Best is trial 18 with value: 3.7405552762827545.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 02:03:34,366]\u001b[0m Trial 22 finished with value: 3.756119744542128 and parameters: {'learning_rate': 0.017456895408981196, 'depth': 7, 'l2_leaf_reg': 7.318054676846571, 'random_strength': 1.6827571743287748, 'min_data_in_leaf': 3, 'subsample': 0.8705319559278547, 'rsm': 0.8933866825885037}. Best is trial 18 with value: 3.7405552762827545.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 02:04:58,672]\u001b[0m Trial 23 finished with value: 3.750729965617876 and parameters: {'learning_rate': 0.027286423674379223, 'depth': 10, 'l2_leaf_reg': 6.249651994594736, 'random_strength': 0.9399725858510414, 'min_data_in_leaf': 9, 'subsample': 0.7673779132660259, 'rsm': 0.9595859081536167}. Best is trial 18 with value: 3.7405552762827545.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 02:08:42,184]\u001b[0m Trial 24 finished with value: 3.7487064027477874 and parameters: {'learning_rate': 0.008853344303750302, 'depth': 8, 'l2_leaf_reg': 8.68220861849084, 'random_strength': 2.0769382337059796, 'min_data_in_leaf': 6, 'subsample': 0.80858165641575, 'rsm': 0.8626721704039464}. Best is trial 18 with value: 3.7405552762827545.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 02:10:29,364]\u001b[0m Trial 25 finished with value: 3.748848896485608 and parameters: {'learning_rate': 0.01393668816585604, 'depth': 7, 'l2_leaf_reg': 2.699968281491958, 'random_strength': 1.5686142336284257, 'min_data_in_leaf': 3, 'subsample': 0.7125678674275785, 'rsm': 0.8360902450380981}. Best is trial 18 with value: 3.7405552762827545.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 02:12:02,029]\u001b[0m Trial 26 finished with value: 3.742930517928205 and parameters: {'learning_rate': 0.018875239496847294, 'depth': 6, 'l2_leaf_reg': 4.948821843219313, 'random_strength': 1.018151052755667, 'min_data_in_leaf': 7, 'subsample': 0.6339136057635106, 'rsm': 0.9145951240795408}. Best is trial 18 with value: 3.7405552762827545.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 02:13:06,614]\u001b[0m Trial 27 finished with value: 3.7510132609809257 and parameters: {'learning_rate': 0.03295234179240353, 'depth': 9, 'l2_leaf_reg': 9.064699645905488, 'random_strength': 0.5002616128823788, 'min_data_in_leaf': 2, 'subsample': 0.8789723690199835, 'rsm': 0.962119021128527}. Best is trial 18 with value: 3.7405552762827545.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 02:14:39,433]\u001b[0m Trial 28 finished with value: 3.758785798847119 and parameters: {'learning_rate': 0.023881540204152677, 'depth': 8, 'l2_leaf_reg': 1.6336327080263064, 'random_strength': 2.3628112733107427, 'min_data_in_leaf': 5, 'subsample': 0.7353112342446176, 'rsm': 0.900639513341511}. Best is trial 18 with value: 3.7405552762827545.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 02:18:01,606]\u001b[0m Trial 29 finished with value: 3.7455881924842647 and parameters: {'learning_rate': 0.008226172411538264, 'depth': 7, 'l2_leaf_reg': 6.325740761595759, 'random_strength': 1.3886540949960082, 'min_data_in_leaf': 6, 'subsample': 0.693755749978428, 'rsm': 0.7646193244239327}. Best is trial 18 with value: 3.7405552762827545.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 02:18:41,395]\u001b[0m Trial 30 finished with value: 3.746794178167284 and parameters: {'learning_rate': 0.043780730924748004, 'depth': 6, 'l2_leaf_reg': 3.3307632343693925, 'random_strength': 0.9298253388959243, 'min_data_in_leaf': 13, 'subsample': 0.7549606170391052, 'rsm': 0.8263890010756451}. Best is trial 18 with value: 3.7405552762827545.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 02:20:09,741]\u001b[0m Trial 31 finished with value: 3.749002925213957 and parameters: {'learning_rate': 0.01870876790867105, 'depth': 6, 'l2_leaf_reg': 4.903615743359604, 'random_strength': 0.8396802942738663, 'min_data_in_leaf': 7, 'subsample': 0.6299779157680759, 'rsm': 0.9233009101776111}. Best is trial 18 with value: 3.7405552762827545.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 02:21:21,693]\u001b[0m Trial 32 finished with value: 3.763235460917894 and parameters: {'learning_rate': 0.020207376914744554, 'depth': 4, 'l2_leaf_reg': 4.259737279907563, 'random_strength': 1.116719102291039, 'min_data_in_leaf': 9, 'subsample': 0.6438527560833531, 'rsm': 0.9040606122828557}. Best is trial 18 with value: 3.7405552762827545.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 02:22:48,024]\u001b[0m Trial 33 finished with value: 3.7394734666815412 and parameters: {'learning_rate': 0.024538937142088227, 'depth': 8, 'l2_leaf_reg': 5.962299726877174, 'random_strength': 0.7323269290860022, 'min_data_in_leaf': 5, 'subsample': 0.6079548424913866, 'rsm': 0.8624086843316551}. Best is trial 33 with value: 3.7394734666815412.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 02:23:59,397]\u001b[0m Trial 34 finished with value: 3.7375501726631213 and parameters: {'learning_rate': 0.02401289266058876, 'depth': 8, 'l2_leaf_reg': 7.6669167940072676, 'random_strength': 0.7241326261604519, 'min_data_in_leaf': 4, 'subsample': 0.6134757134927065, 'rsm': 0.8560881438025976}. Best is trial 34 with value: 3.7375501726631213.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 02:25:16,864]\u001b[0m Trial 35 finished with value: 3.749357456109812 and parameters: {'learning_rate': 0.031004845874044423, 'depth': 9, 'l2_leaf_reg': 5.9755986212182055, 'random_strength': 2.3493995518630264, 'min_data_in_leaf': 5, 'subsample': 0.6042662600206451, 'rsm': 0.866790822158349}. Best is trial 34 with value: 3.7375501726631213.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 02:26:44,094]\u001b[0m Trial 36 finished with value: 3.750234425498635 and parameters: {'learning_rate': 0.024943571989453142, 'depth': 8, 'l2_leaf_reg': 6.95082298780883, 'random_strength': 1.5839785684221108, 'min_data_in_leaf': 11, 'subsample': 0.6520450372055381, 'rsm': 0.8026818582116314}. Best is trial 34 with value: 3.7375501726631213.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 02:27:46,840]\u001b[0m Trial 37 finished with value: 3.7560313154043357 and parameters: {'learning_rate': 0.03754575484184253, 'depth': 7, 'l2_leaf_reg': 7.392271861621682, 'random_strength': 3.6667494671864356, 'min_data_in_leaf': 8, 'subsample': 0.6115604512740271, 'rsm': 0.8510888410716001}. Best is trial 34 with value: 3.7375501726631213.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 02:29:06,124]\u001b[0m Trial 38 finished with value: 3.74498470625832 and parameters: {'learning_rate': 0.0231953392962375, 'depth': 9, 'l2_leaf_reg': 6.6415812044484275, 'random_strength': 0.7766627849566257, 'min_data_in_leaf': 4, 'subsample': 0.6218415680530144, 'rsm': 0.8091652161281534}. Best is trial 34 with value: 3.7375501726631213.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 02:30:30,143]\u001b[0m Trial 39 finished with value: 3.7504826122766657 and parameters: {'learning_rate': 0.030007874800802, 'depth': 10, 'l2_leaf_reg': 7.432872308370047, 'random_strength': 1.931708613098794, 'min_data_in_leaf': 8, 'subsample': 0.6524486498559918, 'rsm': 0.7227720938046126}. Best is trial 34 with value: 3.7375501726631213.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 02:31:37,688]\u001b[0m Trial 40 finished with value: 3.7499304454056137 and parameters: {'learning_rate': 0.03617042673288079, 'depth': 8, 'l2_leaf_reg': 5.817055066791931, 'random_strength': 1.504798924740207, 'min_data_in_leaf': 10, 'subsample': 0.6902889908120305, 'rsm': 0.8857322101850242}. Best is trial 34 with value: 3.7375501726631213.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 02:33:51,190]\u001b[0m Trial 41 finished with value: 3.7469186217406296 and parameters: {'learning_rate': 0.014032997975910825, 'depth': 8, 'l2_leaf_reg': 8.996494769964057, 'random_strength': 0.7533684813757391, 'min_data_in_leaf': 2, 'subsample': 0.6253441886744283, 'rsm': 0.937238512690305}. Best is trial 34 with value: 3.7375501726631213.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 02:34:54,418]\u001b[0m Trial 42 finished with value: 3.7374640297906248 and parameters: {'learning_rate': 0.0256259812174494, 'depth': 8, 'l2_leaf_reg': 7.717992409061578, 'random_strength': 0.6167134246647357, 'min_data_in_leaf': 2, 'subsample': 0.7968123245621603, 'rsm': 0.8573055037828949}. Best is trial 42 with value: 3.7374640297906248.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 02:36:29,629]\u001b[0m Trial 43 finished with value: 3.752336573251629 and parameters: {'learning_rate': 0.02568052747450764, 'depth': 9, 'l2_leaf_reg': 7.6637792339169195, 'random_strength': 1.1388211496850706, 'min_data_in_leaf': 6, 'subsample': 0.9541358356715035, 'rsm': 0.8518906091940657}. Best is trial 42 with value: 3.7374640297906248.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 02:37:59,860]\u001b[0m Trial 44 finished with value: 3.7560234521886997 and parameters: {'learning_rate': 0.02136139373104576, 'depth': 7, 'l2_leaf_reg': 8.431363364684582, 'random_strength': 0.7032770424227192, 'min_data_in_leaf': 3, 'subsample': 0.8942715962924688, 'rsm': 0.8315872064572141}. Best is trial 42 with value: 3.7374640297906248.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 02:39:29,650]\u001b[0m Trial 45 finished with value: 3.7497837258272497 and parameters: {'learning_rate': 0.028710551292664116, 'depth': 9, 'l2_leaf_reg': 9.111049252402877, 'random_strength': 1.8255334114930704, 'min_data_in_leaf': 2, 'subsample': 0.8079817166055083, 'rsm': 0.776068608978126}. Best is trial 42 with value: 3.7374640297906248.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 02:40:22,082]\u001b[0m Trial 46 finished with value: 3.739415767747987 and parameters: {'learning_rate': 0.034111802494967855, 'depth': 7, 'l2_leaf_reg': 6.708996633701102, 'random_strength': 1.3412680310450664, 'min_data_in_leaf': 5, 'subsample': 0.732250005200888, 'rsm': 0.8160806874266673}. Best is trial 42 with value: 3.7374640297906248.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 02:41:48,835]\u001b[0m Trial 47 finished with value: 3.75024044147876 and parameters: {'learning_rate': 0.03190292834352343, 'depth': 8, 'l2_leaf_reg': 6.086112184031169, 'random_strength': 1.3559687098810598, 'min_data_in_leaf': 5, 'subsample': 0.7285249844343513, 'rsm': 0.811194965689636}. Best is trial 42 with value: 3.7374640297906248.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 02:42:53,508]\u001b[0m Trial 48 finished with value: 3.7491976007125807 and parameters: {'learning_rate': 0.04211088582226265, 'depth': 9, 'l2_leaf_reg': 6.79766776158385, 'random_strength': 1.103483549486464, 'min_data_in_leaf': 7, 'subsample': 0.8312944919496935, 'rsm': 0.7892565544733384}. Best is trial 42 with value: 3.7374640297906248.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 02:44:02,484]\u001b[0m Trial 49 finished with value: 3.755069866699178 and parameters: {'learning_rate': 0.023374148281876565, 'depth': 5, 'l2_leaf_reg': 6.4873898942022326, 'random_strength': 2.343049384712397, 'min_data_in_leaf': 2, 'subsample': 0.7909712488065999, 'rsm': 0.7538893105771639}. Best is trial 42 with value: 3.7374640297906248.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- ‚úÖ OPTUNA FINISHED ---\n",
      "Best RMSE: 3.7375\n",
      "Best Params: {'learning_rate': 0.0256259812174494, 'depth': 8, 'l2_leaf_reg': 7.717992409061578, 'random_strength': 0.6167134246647357, 'min_data_in_leaf': 2, 'subsample': 0.7968123245621603, 'rsm': 0.8573055037828949}\n",
      "\n",
      "‚úÖ Final model trained (403 trees)\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "print(\"--- üöÄ TRAINING PHASE (CATBOOST) ---\")\n",
    "\n",
    "SPLIT_SEM = 20231\n",
    "VALID_SEM = 20232\n",
    "\n",
    "df_modeling = full_df_fe[full_df_fe['set_type'] == 'TRAIN'].copy()\n",
    "train_mask = df_modeling['semester_order'] <= SPLIT_SEM\n",
    "valid_mask = df_modeling['semester_order'] == VALID_SEM\n",
    "\n",
    "X_train = df_modeling[train_mask][feature_cols].copy()\n",
    "y_train = df_modeling[train_mask]['COMPLETION_RATE']\n",
    "w_train = df_modeling[train_mask]['TC_DANGKY']\n",
    "\n",
    "X_valid = df_modeling[valid_mask][feature_cols].copy()\n",
    "y_valid_rate = df_modeling[valid_mask]['COMPLETION_RATE']\n",
    "y_valid_credits = df_modeling[valid_mask]['TC_HOANTHANH']\n",
    "valid_credits_dangky = df_modeling[valid_mask]['TC_DANGKY']\n",
    "\n",
    "categorical_features = X_train.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "print(f\"Train: {X_train.shape} | Valid: {X_valid.shape}\")\n",
    "if categorical_features:\n",
    "    print(f\"Categorical features: {len(categorical_features)} detected\")\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'iterations': 2000,\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.05),\n",
    "        'depth': trial.suggest_int('depth', 3, 10),\n",
    "        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1, 10),\n",
    "        'random_strength': trial.suggest_float('random_strength', 0.5, 5.0),\n",
    "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 1, 20),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'rsm': trial.suggest_float('rsm', 0.6, 1.0),\n",
    "        'bootstrap_type': 'Bernoulli',  # ‚Üê Fix: Bernoulli ƒë·ªÉ d√πng ƒë∆∞·ª£c subsample\n",
    "        'loss_function': 'RMSE',\n",
    "        'random_seed': 42,\n",
    "        'thread_count': -1,\n",
    "        'verbose': False,\n",
    "        'cat_features': categorical_features if categorical_features else None\n",
    "    }\n",
    "    \n",
    "    model = CatBoostRegressor(**params)\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=(X_valid, y_valid_rate),\n",
    "        early_stopping_rounds=100,\n",
    "        sample_weight=w_train.values if w_train is not None else None,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    pred_rate = model.predict(X_valid)\n",
    "    pred_credits = np.minimum(pred_rate * valid_credits_dangky, valid_credits_dangky)\n",
    "    return np.sqrt(mean_squared_error(y_valid_credits, pred_credits))\n",
    "\n",
    "# ‚úÖ CH·∫†Y OPTUNA V·ªöI LOG M·∫∂C ƒê·ªäNH (KH√îNG TH√äM G√å C·∫¢)\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=50)  # ‚Üê Kh√¥ng c√≥ callbacks, kh√¥ng c√≥ show_progress_bar\n",
    "\n",
    "print(\"\\n--- ‚úÖ OPTUNA FINISHED ---\")\n",
    "print(f\"Best RMSE: {study.best_value:.4f}\")\n",
    "print(\"Best Params:\", study.best_params)\n",
    "\n",
    "# Train final model\n",
    "best_params = study.best_params.copy()\n",
    "best_params.update({\n",
    "    'iterations': 2000,\n",
    "    'loss_function': 'RMSE',\n",
    "    'random_seed': 42,\n",
    "    'thread_count': -1,\n",
    "    'verbose': False,\n",
    "    'bootstrap_type': 'Bernoulli',\n",
    "    'cat_features': categorical_features if categorical_features else None\n",
    "})\n",
    "\n",
    "model_cb = CatBoostRegressor(**best_params)\n",
    "model_cb.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=(X_valid, y_valid_rate),\n",
    "    early_stopping_rounds=100,\n",
    "    sample_weight=w_train.values if w_train is not None else None,\n",
    "    verbose=False\n",
    ")\n",
    "print(f\"\\n‚úÖ Final model trained ({model_cb.tree_count_} trees)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d47204fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rate = model_cb.predict(X_valid)\n",
    "y_pred = y_pred_rate * valid_credits_dangky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9df1b4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# === TRY IMPORT OPTIONAL DEPENDENCIES ===\n",
    "SHAP_AVAILABLE = False\n",
    "LIME_AVAILABLE = False\n",
    "\n",
    "try:\n",
    "    import shap\n",
    "    SHAP_AVAILABLE = True\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è SHAP not available: {str(e)[:80]}\")\n",
    "\n",
    "try:\n",
    "    import lime\n",
    "    import lime.lime_tabular\n",
    "    LIME_AVAILABLE = True\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è LIME not available: {str(e)[:80]}\")\n",
    "\n",
    "# ========================================\n",
    "# METRICS (LU√îN HO·∫†T ƒê·ªòNG)\n",
    "# ========================================\n",
    "\n",
    "def calculate_mape(y_true, y_pred, epsilon=1e-8):\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    mask = np.abs(y_true) > epsilon\n",
    "    if not np.any(mask):\n",
    "        return np.nan\n",
    "    return np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100\n",
    "\n",
    "def calculate_regression_metrics(y_true, y_pred):\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    mape = calculate_mape(y_true, y_pred)\n",
    "    return {'rmse': rmse, 'r2': r2, 'mape': mape}\n",
    "\n",
    "def print_metrics(metrics, prefix=\"\"):\n",
    "    print(f\"{prefix}RMSE: {metrics['rmse']:.4f} | R¬≤: {metrics['r2']:.4f} | MAPE: {metrics['mape']:.2f}%\")\n",
    "\n",
    "# ========================================\n",
    "# FEATURE IMPORTANCE (LU√îN HO·∫†T ƒê·ªòNG)\n",
    "# ========================================\n",
    "\n",
    "def get_feature_importance(model, feature_names=None):\n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        importance = model.feature_importances_\n",
    "    elif hasattr(model, 'get_feature_importance'):  # CatBoost\n",
    "        importance = model.get_feature_importance()\n",
    "    else:\n",
    "        raise ValueError(\"Model kh√¥ng h·ªó tr·ª£ feature importance\")\n",
    "    \n",
    "    if feature_names is None:\n",
    "        feature_names = [f\"Feature_{i}\" for i in range(len(importance))]\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        'feature': feature_names,\n",
    "        'importance': importance\n",
    "    }).sort_values('importance', ascending=False).reset_index(drop=True)\n",
    "    df['importance_pct'] = (df['importance'] / df['importance'].sum() * 100).round(2)\n",
    "    return df\n",
    "\n",
    "def plot_feature_importance(importance_df, top_n=20, title=\"Feature Importance\"):\n",
    "    df_plot = importance_df.head(top_n).copy()\n",
    "    df_plot['feature'] = df_plot['feature'].astype(str)\n",
    "    \n",
    "    fig = px.bar(\n",
    "        df_plot, x='importance', y='feature', orientation='h',\n",
    "        color='importance', color_continuous_scale='Viridis',\n",
    "        text=df_plot['importance_pct'].apply(lambda x: f\"{x}%\"),\n",
    "        title=title\n",
    "    )\n",
    "    fig.update_layout(\n",
    "        yaxis=dict(autorange=\"reversed\"),\n",
    "        xaxis_title=\"Importance\",\n",
    "        yaxis_title=\"Feature\",\n",
    "        height=max(400, top_n * 25),\n",
    "        template=\"plotly_white\"\n",
    "    )\n",
    "    fig.update_traces(textposition='outside')\n",
    "    return fig\n",
    "\n",
    "# ========================================\n",
    "# DATA PREPROCESSING FOR EXPLAINABILITY\n",
    "# ========================================\n",
    "\n",
    "def prepare_data_for_explainers(X, fit_encoders=False, encoders=None):\n",
    "    \"\"\"\n",
    "    Chuy·ªÉn ƒë·ªïi categorical features ‚Üí numeric cho SHAP/LIME.\n",
    "    Tr·∫£ v·ªÅ: (X_numeric, feature_names, categorical_info, encoders)\n",
    "    \"\"\"\n",
    "    if isinstance(X, pd.DataFrame):\n",
    "        X = X.copy()\n",
    "    else:\n",
    "        X = pd.DataFrame(X)\n",
    "    \n",
    "    categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    numeric_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    \n",
    "    new_encoders = {} if encoders is None else encoders.copy()\n",
    "    X_processed = X.copy()\n",
    "    \n",
    "    if categorical_cols:\n",
    "        if fit_encoders:\n",
    "            # Fit m·ªõi encoders\n",
    "            for col in categorical_cols:\n",
    "                le = LabelEncoder()\n",
    "                # X·ª≠ l√Ω missing values tr∆∞·ªõc khi encode\n",
    "                X_processed[col] = X_processed[col].fillna('MISSING').astype(str)\n",
    "                le.fit(X_processed[col])\n",
    "                X_processed[col] = le.transform(X_processed[col])\n",
    "                new_encoders[col] = le\n",
    "        else:\n",
    "            # D√πng encoders c√≥ s·∫µn\n",
    "            for col in categorical_cols:\n",
    "                if col in new_encoders:\n",
    "                    X_processed[col] = X_processed[col].fillna('MISSING').astype(str)\n",
    "                    X_processed[col] = new_encoders[col].transform(X_processed[col])\n",
    "                else:\n",
    "                    # Fallback: g√°n gi√° tr·ªã m·∫∑c ƒë·ªãnh\n",
    "                    X_processed[col] = 0\n",
    "                    warnings.warn(f\"‚ö†Ô∏è Categorical encoder missing for '{col}', using default value 0\")\n",
    "    \n",
    "    # ƒê·∫£m b·∫£o t·∫•t c·∫£ c·ªôt l√† numeric\n",
    "    X_processed = X_processed.astype(float)\n",
    "    \n",
    "    return (\n",
    "        X_processed.values,\n",
    "        X.columns.tolist(),\n",
    "        {'categorical_cols': categorical_cols, 'numeric_cols': numeric_cols},\n",
    "        new_encoders\n",
    "    )\n",
    "\n",
    "# ========================================\n",
    "# SHAP (X·ª¨ L√ù CATEGORICAL T·ª∞ ƒê·ªòNG)\n",
    "# ========================================\n",
    "\n",
    "def get_shap_values(model, X_sample, model_type=None):\n",
    "    if not SHAP_AVAILABLE:\n",
    "        raise RuntimeError(\"SHAP ch∆∞a ƒë∆∞·ª£c c√†i ƒë·∫∑t\")\n",
    "    \n",
    "    # Chu·∫©n b·ªã d·ªØ li·ªáu numeric\n",
    "    X_num, feature_names, _, _ = prepare_data_for_explainers(X_sample, fit_encoders=False)\n",
    "    \n",
    "    if model_type == 'catboost':\n",
    "        explainer = shap.TreeExplainer(model, feature_perturbation=\"tree_path_dependent\")\n",
    "    else:\n",
    "        explainer = shap.TreeExplainer(model)\n",
    "    \n",
    "    shap_values = explainer.shap_values(X_num)\n",
    "    return shap_values, feature_names, X_num\n",
    "\n",
    "def plot_shap_summary(shap_values, X_sample, feature_names, max_display=20, title=\"SHAP Summary Plot\"):\n",
    "    if not SHAP_AVAILABLE:\n",
    "        print(\"‚ö†Ô∏è SHAP kh√¥ng kh·∫£ d·ª•ng - skip plot\")\n",
    "        return None\n",
    "    \n",
    "    # T·∫°o DataFrame SHAP\n",
    "    shap_df = pd.DataFrame(shap_values, columns=feature_names)\n",
    "    mean_abs_shap = shap_df.abs().mean().sort_values(ascending=False)\n",
    "    top_features = mean_abs_shap.head(max_display).index.tolist()\n",
    "    \n",
    "    # Chu·∫©n b·ªã d·ªØ li·ªáu cho beeswarm-style plot\n",
    "    plot_data = []\n",
    "    for feature in top_features[::-1]:  # reverse ƒë·ªÉ feature quan tr·ªçng nh·∫•t ·ªü tr√™n\n",
    "        shap_vals = shap_df[feature].values\n",
    "        feat_vals = X_sample[:, feature_names.index(feature)]\n",
    "        colors = feat_vals  # d√πng gi√° tr·ªã feature ƒë·ªÉ t√¥ m√†u\n",
    "        \n",
    "        for i in range(len(shap_vals)):\n",
    "            plot_data.append({\n",
    "                'feature': feature,\n",
    "                'shap_value': shap_vals[i],\n",
    "                'feature_value': colors[i]\n",
    "            })\n",
    "    \n",
    "    df_plot = pd.DataFrame(plot_data)\n",
    "    \n",
    "    # T·∫°o beeswarm plot b·∫±ng Plotly\n",
    "    fig = px.scatter(\n",
    "        df_plot,\n",
    "        x='shap_value',\n",
    "        y='feature',\n",
    "        color='feature_value',\n",
    "        color_continuous_scale='RdBu',\n",
    "        title=title,\n",
    "        height=max(400, len(top_features) * 30),\n",
    "        hover_data=['feature_value']\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        xaxis_title=\"SHAP Value (impact on model output)\",\n",
    "        yaxis_title=\"Feature\",\n",
    "        template=\"plotly_white\",\n",
    "        showlegend=True\n",
    "    )\n",
    "    fig.add_vline(x=0, line_dash=\"dash\", line_color=\"gray\", line_width=1)\n",
    "    return fig\n",
    "\n",
    "# ========================================\n",
    "# LIME (X·ª¨ L√ù CATEGORICAL ƒê√öNG C√ÅCH)\n",
    "# ========================================\n",
    "\n",
    "def explain_instance_lime(model, X_train, X_instance, feature_names=None, \n",
    "                         categorical_features=None, categorical_names=None, \n",
    "                         num_features=10, num_samples=5000):\n",
    "    if not LIME_AVAILABLE:\n",
    "        raise RuntimeError(\"LIME ch∆∞a ƒë∆∞·ª£c c√†i ƒë·∫∑t\")\n",
    "    \n",
    "    # Chu·∫©n b·ªã training data cho LIME (numeric)\n",
    "    X_train_num, train_feat_names, cat_info, encoders = prepare_data_for_explainers(\n",
    "        X_train, fit_encoders=True\n",
    "    )\n",
    "    \n",
    "    # Chu·∫©n b·ªã instance c·∫ßn gi·∫£i th√≠ch\n",
    "    if isinstance(X_instance, pd.DataFrame):\n",
    "        X_instance = X_instance.copy()\n",
    "    else:\n",
    "        X_instance = pd.DataFrame(X_instance, columns=train_feat_names)\n",
    "    \n",
    "    X_instance_num, _, _, _ = prepare_data_for_explainers(\n",
    "        X_instance, fit_encoders=False, encoders=encoders\n",
    "    )\n",
    "    \n",
    "    # X√°c ƒë·ªãnh categorical feature indices\n",
    "    if categorical_features is None:\n",
    "        categorical_features = [\n",
    "            i for i, col in enumerate(train_feat_names) \n",
    "            if col in cat_info['categorical_cols']\n",
    "        ]\n",
    "    \n",
    "    # T·∫°o categorical_names mapping\n",
    "    if categorical_names is None and cat_info['categorical_cols']:\n",
    "        categorical_names = {}\n",
    "        for col in cat_info['categorical_cols']:\n",
    "            idx = train_feat_names.index(col)\n",
    "            le = encoders.get(col)\n",
    "            if le:\n",
    "                categorical_names[idx] = list(le.classes_)\n",
    "    \n",
    "    # T·∫°o explainer v·ªõi categorical info\n",
    "    explainer = lime.lime_tabular.LimeTabularExplainer(\n",
    "        X_train_num,\n",
    "        feature_names=train_feat_names,\n",
    "        categorical_features=categorical_features,\n",
    "        categorical_names=categorical_names,\n",
    "        mode='regression',\n",
    "        verbose=False,\n",
    "        random_state=42,\n",
    "        kernel_width=3,\n",
    "        discretize_continuous=False  # Gi·ªØ nguy√™n gi√° tr·ªã li√™n t·ª•c\n",
    "    )\n",
    "    \n",
    "    # Gi·∫£i th√≠ch instance\n",
    "    exp = explainer.explain_instance(\n",
    "        X_instance_num[0],\n",
    "        model.predict,\n",
    "        num_features=num_features,\n",
    "        num_samples=num_samples\n",
    "    )\n",
    "    \n",
    "    return exp, encoders\n",
    "\n",
    "def plot_lime_explanation(lime_explanation, title=\"LIME Explanation\"):\n",
    "    if not LIME_AVAILABLE:\n",
    "        print(\"‚ö†Ô∏è LIME kh√¥ng kh·∫£ d·ª•ng - skip plot\")\n",
    "        return None\n",
    "    \n",
    "    exp_list = lime_explanation.as_list()\n",
    "    df = pd.DataFrame(exp_list, columns=['feature', 'weight'])\n",
    "    df = df.sort_values('weight', key=abs, ascending=True).reset_index(drop=True)\n",
    "    colors = ['green' if w > 0 else 'red' for w in df['weight']]\n",
    "    \n",
    "    fig = go.Figure(go.Bar(\n",
    "        y=df['feature'], \n",
    "        x=df['weight'], \n",
    "        orientation='h',\n",
    "        marker_color=colors,\n",
    "        text=df['weight'].apply(lambda x: f\"{x:+.3f}\"),\n",
    "        textposition='auto',\n",
    "    ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        xaxis_title=\"Feature Contribution to Prediction\",\n",
    "        yaxis_title=\"Feature\",\n",
    "        template=\"plotly_white\",\n",
    "        height=300 + len(df) * 35,\n",
    "        xaxis=dict(showgrid=True, zeroline=True, zerolinewidth=2, zerolinecolor='gray')\n",
    "    )\n",
    "    fig.add_vline(x=0, line_dash=\"dash\", line_color=\"gray\", line_width=1)\n",
    "    return fig\n",
    "\n",
    "# ========================================\n",
    "# HELPER: SHOW ALL METRICS & PLOTS\n",
    "# ========================================\n",
    "\n",
    "def show_all(model, X_valid, y_valid, y_pred, \n",
    "             X_train=None, model_type=None, \n",
    "             instance_idx=0, top_n_features=15):\n",
    "    \"\"\"\n",
    "    Hi·ªÉn th·ªã ƒë·∫ßy ƒë·ªß metrics + visualizations cho model.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model : model ƒë√£ train (XGBoost/LightGBM/CatBoost)\n",
    "    X_valid : pd.DataFrame - validation features\n",
    "    y_valid : array-like - true labels (credits)\n",
    "    y_pred : array-like - predicted credits\n",
    "    X_train : pd.DataFrame - training features (c·∫ßn cho LIME)\n",
    "    model_type : str - 'xgboost', 'lightgbm', 'catboost'\n",
    "    instance_idx : int - index c·ªßa instance ƒë·ªÉ gi·∫£i th√≠ch b·∫±ng SHAP/LIME\n",
    "    top_n_features : int - s·ªë feature hi·ªÉn th·ªã trong plots\n",
    "    \"\"\"\n",
    "    # 1. Metrics\n",
    "    print(\"=\"*60)\n",
    "    print(\"üìä REGRESSION METRICS\")\n",
    "    print(\"=\"*60)\n",
    "    metrics = calculate_regression_metrics(y_valid, y_pred)\n",
    "    print_metrics(metrics, \"Validation: \")\n",
    "    print()\n",
    "    \n",
    "    # 2. Feature Importance\n",
    "    print(\"=\"*60)\n",
    "    print(\"üìà FEATURE IMPORTANCE\")\n",
    "    print(\"=\"*60)\n",
    "    imp_df = get_feature_importance(model, feature_names=X_valid.columns.tolist())\n",
    "    fig_imp = plot_feature_importance(imp_df, top_n=top_n_features)\n",
    "    fig_imp.show()\n",
    "    print()\n",
    "    \n",
    "    # 3. SHAP Summary (n·∫øu c√≥)\n",
    "    if SHAP_AVAILABLE and X_valid.shape[0] > 0:\n",
    "        print(\"=\"*60)\n",
    "        print(\"üîç SHAP SUMMARY PLOT\")\n",
    "        print(\"=\"*60)\n",
    "        try:\n",
    "            # Sample 100 instances ƒë·ªÉ t√≠nh SHAP nhanh h∆°n\n",
    "            sample_size = min(100, len(X_valid))\n",
    "            X_sample = X_valid.iloc[:sample_size] if isinstance(X_valid, pd.DataFrame) else X_valid[:sample_size]\n",
    "            \n",
    "            shap_vals, feat_names, X_num = get_shap_values(model, X_sample, model_type=model_type)\n",
    "            fig_shap = plot_shap_summary(shap_vals, X_num, feat_names, max_display=top_n_features)\n",
    "            if fig_shap:\n",
    "                fig_shap.show()\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è SHAP error: {str(e)[:100]}\")\n",
    "    print()\n",
    "    \n",
    "    # 4. LIME Explanation (n·∫øu c√≥)\n",
    "    if LIME_AVAILABLE and X_train is not None and len(X_valid) > instance_idx:\n",
    "        print(\"=\"*60)\n",
    "        print(f\"üî¨ LIME EXPLANATION (Instance #{instance_idx})\")\n",
    "        print(\"=\"*60)\n",
    "        try:\n",
    "            instance = X_valid.iloc[[instance_idx]] if isinstance(X_valid, pd.DataFrame) else X_valid[instance_idx:instance_idx+1]\n",
    "            lime_exp, _ = explain_instance_lime(\n",
    "                model, \n",
    "                X_train=X_train, \n",
    "                X_instance=instance,\n",
    "                feature_names=X_valid.columns.tolist(),\n",
    "                num_features=top_n_features\n",
    "            )\n",
    "            fig_lime = plot_lime_explanation(lime_exp, title=f\"LIME: Instance #{instance_idx}\")\n",
    "            if fig_lime:\n",
    "                fig_lime.show()\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è LIME error: {str(e)[:100]}\")\n",
    "    print()\n",
    "    print(\"=\"*60)\n",
    "    print(\"‚úÖ DONE\")\n",
    "    print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21e6ed18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üìä REGRESSION METRICS\n",
      "============================================================\n",
      "Validation: RMSE: 3.7402 | R¬≤: 0.7162 | MAPE: 29.85%\n",
      "\n",
      "============================================================\n",
      "üìà FEATURE IMPORTANCE\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "importance=%{marker.color}<br>feature=%{y}<br>text=%{text}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": {
           "bdata": "XInh6Q3oLUBG3+wFHeMpQFyaQDoB1iJAGDyVDLZ/IkAUkmWxTf0cQFkSBoZ1CxpALDm/tD+eFkBOuh7tfGwTQDr1xdwrXBBAApgSP8VHEEAg0nSRPY4MQAkPQh7WbgRAqQ89H+pEAEDdQ5/1k3j8P+9uCMKDNPs/",
           "dtype": "f8"
          },
          "coloraxis": "coloraxis",
          "pattern": {
           "shape": ""
          }
         },
         "name": "",
         "orientation": "h",
         "showlegend": false,
         "text": [
          "14.95%",
          "12.94%",
          "9.42%",
          "9.25%",
          "7.25%",
          "6.51%",
          "5.65%",
          "4.86%",
          "4.09%",
          "4.07%",
          "3.57%",
          "2.55%",
          "2.03%",
          "1.78%",
          "1.7%"
         ],
         "textposition": "outside",
         "type": "bar",
         "x": {
          "bdata": "XInh6Q3oLUBG3+wFHeMpQFyaQDoB1iJAGDyVDLZ/IkAUkmWxTf0cQFkSBoZ1CxpALDm/tD+eFkBOuh7tfGwTQDr1xdwrXBBAApgSP8VHEEAg0nSRPY4MQAkPQh7WbgRAqQ89H+pEAEDdQ5/1k3j8P+9uCMKDNPs/",
          "dtype": "f8"
         },
         "xaxis": "x",
         "y": [
          "accumulated_fail_ratio",
          "nam_tuoi",
          "Prev_CPA",
          "prev_completion_rate",
          "semester_number",
          "total_credits_failed",
          "Prev_TC_HOANTHANH",
          "DIEM_TRUNGTUYEN",
          "Prev_GPA",
          "expected_real_credits",
          "DIEM_CHUAN",
          "credit_velocity",
          "prev_gpa_cpa_diff",
          "failed_last_sem",
          "PTXT"
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "barmode": "relative",
        "coloraxis": {
         "colorbar": {
          "title": {
           "text": "importance"
          }
         },
         "colorscale": [
          [
           0,
           "#440154"
          ],
          [
           0.1111111111111111,
           "#482878"
          ],
          [
           0.2222222222222222,
           "#3e4989"
          ],
          [
           0.3333333333333333,
           "#31688e"
          ],
          [
           0.4444444444444444,
           "#26828e"
          ],
          [
           0.5555555555555556,
           "#1f9e89"
          ],
          [
           0.6666666666666666,
           "#35b779"
          ],
          [
           0.7777777777777778,
           "#6ece58"
          ],
          [
           0.8888888888888888,
           "#b5de2b"
          ],
          [
           1,
           "#fde725"
          ]
         ]
        },
        "height": 400,
        "legend": {
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#C8D4E3"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Feature Importance"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Importance"
         }
        },
        "yaxis": {
         "anchor": "x",
         "autorange": "reversed",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Feature"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üîç SHAP SUMMARY PLOT\n",
      "============================================================\n",
      "‚ö†Ô∏è SHAP error: 'data' is numpy array of floating point numerical type, it means no categorical features, but 'cat_f\n",
      "\n",
      "============================================================\n",
      "üî¨ LIME EXPLANATION (Instance #0)\n",
      "============================================================\n",
      "‚ö†Ô∏è LIME error: 'data' is numpy array of floating point numerical type, it means no categorical features, but 'cat_f\n",
      "\n",
      "============================================================\n",
      "‚úÖ DONE\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "show_all(\n",
    "    model=model_cb,\n",
    "    X_valid=X_valid,\n",
    "    y_valid=y_valid_credits,\n",
    "    y_pred=y_pred,\n",
    "    X_train=X_train,          # C·∫ßn cho LIME\n",
    "    model_type='lightgbm',    # 'xgboost', 'lightgbm', 'catboost'\n",
    "    instance_idx=0,           # Instance n√†o ƒë·ªÉ gi·∫£i th√≠ch\n",
    "    top_n_features=15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f5faf7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def submission(model, output_filename):\n",
    "    print(\"\\n--- 4. PREDICTING TEST SET (HK1 2024-2025) ---\")\n",
    "    test_final = full_df_fe[full_df_fe['set_type'] == 'TEST'].copy()\n",
    "    X_test = test_final[feature_cols]\n",
    "    test_dangky = test_final['TC_DANGKY']\n",
    "\n",
    "    # D·ª± b√°o\n",
    "    pred_rate_test = model.predict(X_test)\n",
    "\n",
    "    # H·∫≠u x·ª≠ l√Ω t∆∞∆°ng t·ª±\n",
    "    pred_rate_test = np.clip(pred_rate_test, 0, 1)\n",
    "    pred_credits_test = pred_rate_test * test_dangky\n",
    "    pred_credits_test = np.minimum(pred_credits_test, test_dangky)\n",
    "\n",
    "    final_submission = pred_credits_test\n",
    "\n",
    "    # T·∫°o DataFrame n·ªôp b√†i\n",
    "    submission_df = pd.DataFrame({\n",
    "        'MA_SO_SV': test_final['MA_SO_SV'],\n",
    "        'PRED_TC_HOANTHANH': final_submission\n",
    "    })\n",
    "\n",
    "    # L∆∞u file\n",
    "    submission_df.to_csv(output_filename, index=False)\n",
    "    print(f\"‚úÖ ƒê√£ l∆∞u file k·∫øt qu·∫£: {output_filename}\")\n",
    "    print(submission_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd8facd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 4. PREDICTING TEST SET (HK1 2024-2025) ---\n",
      "‚úÖ ƒê√£ l∆∞u file k·∫øt qu·∫£: submission_catboost_v1.csv\n",
      "        MA_SO_SV  PRED_TC_HOANTHANH\n",
      "2   00003e092652          15.368979\n",
      "3   00027b0dec4c          17.220308\n",
      "10  000e15519006          17.561364\n",
      "13  000ea6e12003          16.335211\n",
      "16  00109b845a3d           4.893423\n"
     ]
    }
   ],
   "source": [
    "submission(model=model_cb, output_filename=\"submission_catboost_v1.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
