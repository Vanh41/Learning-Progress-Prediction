{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81d7ea1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ACADEMIC_PATH = r'../../data/raw/academic_records.csv'\n",
    "ADMISSION_PATH = r'../../data/raw/admission.csv'\n",
    "academic_records = pd.read_csv(ACADEMIC_PATH)\n",
    "admission = pd.read_csv(ADMISSION_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "774798e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def clean_data_pipeline(admission, academic_records):\n",
    "    print(\"--- B·∫ÆT ƒê·∫¶U QUY TR√åNH L√ÄM S·∫†CH D·ªÆ LI·ªÜU ---\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # B∆Ø·ªöC 1: X·ª¨ L√ù ƒê·ªäNH D·∫†NG & KI·ªÇU D·ªÆ LI·ªÜU (Formatting)\n",
    "    # =========================================================================\n",
    "    print(\"Step 1: Formatting & Merging...\")\n",
    "    \n",
    "    # 1.1. Chu·∫©n h√≥a MA_SO_SV v·ªÅ d·∫°ng String\n",
    "    admission['MA_SO_SV'] = admission['MA_SO_SV'].astype(str)\n",
    "    academic_records['MA_SO_SV'] = academic_records['MA_SO_SV'].astype(str)\n",
    "    \n",
    "    # 1.2. Chuy·ªÉn ƒë·ªïi HOC_KY sang s·ªë nguy√™n (gi·∫£ ƒë·ªãnh h√†m hoc_ky_to_code ƒë√£ ƒë∆∞·ª£c ƒë·ªãnh nghƒ©a b√™n ngo√†i)\n",
    "    # N·∫øu ch∆∞a c√≥ h√†m n√†y, b·∫°n c·∫ßn ƒë·ªãnh nghƒ©a logic convert (v√≠ d·ª•: '20231' -> int)\n",
    "    # academic_records['HOC_KY'] = academic_records['HOC_KY'].apply(hoc_ky_to_code)\n",
    "    \n",
    "    # Merge d·ªØ li·ªáu (Inner Join ƒë·ªÉ ch·ªâ l·∫•y sinh vi√™n c√≥ th√¥ng tin ·ªü c·∫£ 2 b·∫£ng)\n",
    "    df = pd.merge(academic_records, admission, on='MA_SO_SV', how='inner')\n",
    "    \n",
    "    # 1.3. ƒê·ªãnh d·∫°ng l·∫°i c√°c c·ªôt s·ªë (√âp ki·ªÉu float/int)\n",
    "    numeric_floats = ['GPA', 'CPA', 'DIEM_TRUNGTUYEN', 'DIEM_CHUAN']\n",
    "    for col in numeric_floats:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce') \n",
    "        \n",
    "    numeric_ints = ['TC_DANGKY', 'TC_HOANTHANH']\n",
    "    for col in numeric_ints:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "    # S·∫Øp x·∫øp d·ªØ li·ªáu\n",
    "    df = df.sort_values(by=['MA_SO_SV', 'HOC_KY']).reset_index(drop=True)\n",
    "\n",
    "    # =========================================================================\n",
    "    # B∆Ø·ªöC 2: KI·ªÇM TRA LOGIC & L√ÄM S·∫†CH NHI·ªÑU (Sanity Checks)\n",
    "    # =========================================================================\n",
    "    print(\"Step 2: Sanity Checks & Logic Cleaning...\")\n",
    "    \n",
    "    initial_rows = len(df)\n",
    "\n",
    "    # 3.1. Logic T√≠n ch·ªâ: Ho√†n th√†nh kh√¥ng ƒë∆∞·ª£c l·ªõn h∆°n ƒêƒÉng k√Ω\n",
    "    df['TC_HOANTHANH'] = np.minimum(df['TC_HOANTHANH'], df['TC_DANGKY'])\n",
    "    \n",
    "    # 3.2. Logic ƒêi·ªÉm s·ªë (0 <= GPA/CPA <= 4.0)\n",
    "    df['GPA'] = df['GPA'].clip(lower=0.0, upper=4.0)\n",
    "    df['CPA'] = df['CPA'].clip(lower=0.0, upper=4.0)\n",
    "    \n",
    "    # -----------------------------------------------------------\n",
    "    # [M·ªöI] 3.3. Logic Tuy·ªÉn sinh: DIEM_TRUNGTUYEN >= DIEM_CHUAN\n",
    "    # -----------------------------------------------------------\n",
    "    # Lo·∫°i b·ªè c√°c d√≤ng m√† ƒëi·ªÉm tr√∫ng tuy·ªÉn nh·ªè h∆°n ƒëi·ªÉm chu·∫©n.\n",
    "    # L∆∞u √Ω: C√°c gi√° tr·ªã NaN (do l·ªói format ·ªü B1) c≈©ng s·∫Ω b·ªã lo·∫°i b·ªè trong ph√©p so s√°nh n√†y.\n",
    "    rows_before_score_filter = len(df)\n",
    "    df = df[df['DIEM_TRUNGTUYEN'] >= df['DIEM_CHUAN']]\n",
    "    dropped_score_rows = rows_before_score_filter - len(df)\n",
    "    print(f\" -> ƒê√£ lo·∫°i b·ªè {dropped_score_rows} d√≤ng do ƒêi·ªÉm tr√∫ng tuy·ªÉn < ƒêi·ªÉm chu·∫©n.\")\n",
    "\n",
    "    # 3.4. X√≥a d·ªØ li·ªáu r√°c (TC_DANGKY = 0)\n",
    "    rows_before_credit_filter = len(df)\n",
    "    df = df[df['TC_DANGKY'] > 0].copy()\n",
    "    dropped_credit_rows = rows_before_credit_filter - len(df)\n",
    "    print(f\" -> ƒê√£ lo·∫°i b·ªè {dropped_credit_rows} d√≤ng r√°c (TC_DANGKY=0).\")\n",
    "    \n",
    "    # T·ªïng k·∫øt\n",
    "    total_dropped = initial_rows - len(df)\n",
    "    print(f\"--- HO√ÄN T·∫§T: T·ªïng c·ªông ƒë√£ lo·∫°i b·ªè {total_dropped} d√≤ng nhi·ªÖu. K√≠ch th∆∞·ªõc data cu·ªëi: {df.shape} ---\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ba9c7d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- B·∫ÆT ƒê·∫¶U QUY TR√åNH L√ÄM S·∫†CH D·ªÆ LI·ªÜU ---\n",
      "Step 1: Formatting & Merging...\n",
      "Step 2: Sanity Checks & Logic Cleaning...\n",
      " -> ƒê√£ lo·∫°i b·ªè 0 d√≤ng do ƒêi·ªÉm tr√∫ng tuy·ªÉn < ƒêi·ªÉm chu·∫©n.\n",
      " -> ƒê√£ lo·∫°i b·ªè 0 d√≤ng r√°c (TC_DANGKY=0).\n",
      "--- HO√ÄN T·∫§T: T·ªïng c·ªông ƒë√£ lo·∫°i b·ªè 0 d√≤ng nhi·ªÖu. K√≠ch th∆∞·ªõc data cu·ªëi: (105726, 11) ---\n"
     ]
    }
   ],
   "source": [
    "df = clean_data_pipeline(admission, academic_records)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b5bc53",
   "metadata": {},
   "source": [
    "### C√°c nh√≥m bi·∫øn n√¢ng cao\n",
    "\n",
    "#### 1. Bi·∫øn xu h∆∞·ªõng & ·ªïn ƒë·ªãnh (Trend & Volatility)\n",
    "- **GPA_Trend_Slope**: ƒêo l∆∞·ªùng xu h∆∞·ªõng h·ªçc t·∫≠p c·ªßa sinh vi√™n (ƒëang ti·∫øn b·ªô hay th·ª•t l√πi) qua nhi·ªÅu k·ª≥. Slope > 0 l√† ti·∫øn b·ªô, < 0 l√† gi·∫£m s√∫t.\n",
    "- **GPA_Std_Dev_Accumulated**: ƒêo ƒë·ªô ·ªïn ƒë·ªãnh k·∫øt qu·∫£ h·ªçc t·∫≠p. Std Dev cao nghƒ©a l√† sinh vi√™n h·ªçc th·∫•t th∆∞·ªùng, Std Dev th·∫•p l√† h·ªçc ƒë·ªÅu.\n",
    "- **GPA_Last_3_Avg**: Trung b√¨nh GPA 3 k·ª≥ g·∫ßn nh·∫•t, gi√∫p l√†m m∆∞·ª£t d·ªØ li·ªáu, gi·∫£m ·∫£nh h∆∞·ªüng c·ªßa c√°c k·ª≥ b·∫•t th∆∞·ªùng.\n",
    "\n",
    "#### 2. Bi·∫øn so s√°nh t∆∞∆°ng ƒë·ªëi (Relative/Cohort Features)\n",
    "- **GPA_ZScore**: Chu·∫©n h√≥a ƒëi·ªÉm s·ªë theo k·ª≥, so s√°nh sinh vi√™n v·ªõi m·∫∑t b·∫±ng chung c√πng kh√≥a. Z-Score d∆∞∆°ng l√† v∆∞·ª£t tr·ªôi, √¢m l√† k√©m h∆°n.\n",
    "- **Percentile Rank**: X·∫øp h·∫°ng ph·∫ßn trƒÉm, cho bi·∫øt sinh vi√™n n·∫±m ·ªü ƒë√¢u trong ph√¢n ph·ªëi ƒëi·ªÉm s·ªë c·ªßa k·ª≥ ƒë√≥ (Top 10%, Bottom 10%,...).\n",
    "\n",
    "#### 3. Bi·∫øn t∆∞∆°ng t√°c (Interaction Features)\n",
    "- **Admission_Score √ó First_Year_GPA**: Ki·ªÉm tra s·ª± t∆∞∆°ng quan gi·ªØa nƒÉng l·ª±c ƒë·∫ßu v√†o v√† k·∫øt qu·∫£ nƒÉm ƒë·∫ßu, ph√°t hi·ªán sinh vi√™n gi·ªØ v·ªØng hay sa s√∫t phong ƒë·ªô.\n",
    "- **Gap_Duration √ó Credits_Failed**: ƒêo √°p l·ª±c t√≠ch l≈©y, sinh vi√™n v·ª´a ngh·ªâ h·ªçc v·ª´a n·ª£ m√¥n nhi·ªÅu c√≥ nguy c∆° b·ªè h·ªçc cao.\n",
    "- **Total_Credits_Failed / Total_Credits_Registered**: T·ª∑ l·ªá n·ª£ m√¥n t√≠ch l≈©y, ph·∫£n √°nh r·ªßi ro h·ªçc t·∫≠p d√†i h·∫°n thay v√¨ ch·ªâ nh√¨n t·ª´ng k·ª≥.\n",
    "\n",
    "_Nh·ªØng bi·∫øn n√†y gi√∫p m√¥ h√¨nh hi·ªÉu s√¢u h∆°n v·ªÅ qu√° tr√¨nh, s·ª± ·ªïn ƒë·ªãnh v√† b·ªëi c·∫£nh h·ªçc t·∫≠p c·ªßa t·ª´ng sinh vi√™n, t·ª´ ƒë√≥ d·ª± b√°o ch√≠nh x√°c h∆°n._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b8a9c13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import linregress\n",
    "\n",
    "def calculate_slope(series):\n",
    "    \"\"\"\n",
    "    H√†m ph·ª• tr·ª£: T√≠nh h·ªá s·ªë g√≥c (slope) c·ªßa ƒë∆∞·ªùng h·ªìi quy tuy·∫øn t√≠nh cho m·ªôt chu·ªói ƒëi·ªÉm s·ªë.\n",
    "    Tr·∫£ v·ªÅ: > 0 (ƒêang ti·∫øn b·ªô), < 0 (ƒêang sa s√∫t), 0 (ƒêi ngang/Kh√¥ng ƒë·ªß d·ªØ li·ªáu)\n",
    "    \"\"\"\n",
    "    y = series.dropna()\n",
    "    if len(y) < 2: # C·∫ßn √≠t nh·∫•t 2 ƒëi·ªÉm ƒë·ªÉ v·∫Ω ƒë∆∞·ªùng th·∫≥ng\n",
    "        return 0\n",
    "    x = np.arange(len(y))\n",
    "    slope, intercept, r_value, p_value, std_err = linregress(x, y)\n",
    "    return slope\n",
    "\n",
    "def generate_advanced_features(df):\n",
    "    \"\"\"\n",
    "    H√†m ch√≠nh t·∫°o ra c√°c bi·∫øn ph√°i sinh n√¢ng cao (Advanced Features).\n",
    "    Input: DataFrame ƒë√£ qua x·ª≠ l√Ω c∆° b·∫£n (c√≥ GPA, MA_SO_SV, HOC_KY, v.v.)\n",
    "    \"\"\"\n",
    "    print(\"üöÄ B·∫Øt ƒë·∫ßu Feature Engineering n√¢ng cao...\")\n",
    "    \n",
    "    # T·∫°o b·∫£n sao ƒë·ªÉ kh√¥ng ·∫£nh h∆∞·ªüng d·ªØ li·ªáu g·ªëc\n",
    "    df_new = df.copy()\n",
    "    \n",
    "    # ƒê·∫£m b·∫£o d·ªØ li·ªáu ƒë∆∞·ª£c sort ƒë√∫ng ƒë·ªÉ d√πng c√°c h√†m window/shift\n",
    "    df_new = df_new.sort_values(['MA_SO_SV', 'HOC_KY'])\n",
    "    \n",
    "    # ---------------------------------------------------------\n",
    "    # 1. NH√ìM BI·∫æN XU H∆Ø·ªöNG & ·ªîN ƒê·ªäNH (Trend & Volatility)\n",
    "    # ---------------------------------------------------------\n",
    "    print(\"- ƒêang t√≠nh to√°n xu h∆∞·ªõng h·ªçc t·∫≠p (Trend)...\")\n",
    "    \n",
    "    # T√≠nh ƒëi·ªÉm trung b√¨nh 3 k·ª≥ g·∫ßn nh·∫•t (Rolling Average) ƒë·ªÉ l√†m m∆∞·ª£t d·ªØ li·ªáu\n",
    "    # D√πng min_periods=1 ƒë·ªÉ v·∫´n t√≠nh d√π m·ªõi h·ªçc 1 k·ª≥\n",
    "    df_new['GPA_Last_3_Avg'] = df_new.groupby('MA_SO_SV')['GPA'].transform(\n",
    "        lambda x: x.rolling(window=3, min_periods=1).mean()\n",
    "    )\n",
    "    \n",
    "    # T√≠nh ƒë·ªô ·ªïn ƒë·ªãnh (ƒê·ªô l·ªách chu·∫©n t√≠ch l≈©y)\n",
    "    # Std c√†ng cao -> H·ªçc c√†ng th·∫•t th∆∞·ªùng (kh√≥ d·ª± ƒëo√°n)\n",
    "    df_new['GPA_Volatility_Accumulated'] = df_new.groupby('MA_SO_SV')['GPA'].expanding().std().reset_index(level=0, drop=True)\n",
    "    df_new['GPA_Volatility_Accumulated'] = df_new['GPA_Volatility_Accumulated'].fillna(0) # K·ª≥ ƒë·∫ßu ti√™n ch∆∞a c√≥ ƒë·ªô l·ªách\n",
    "    \n",
    "    # T√≠nh ƒë·ªô d·ªëc h·ªçc t·∫≠p (GPA Slope) - Sinh vi√™n ƒëang ƒëi l√™n hay ƒëi xu·ªëng?\n",
    "    # L∆∞u √Ω: H√†m apply n√†y c√≥ th·ªÉ ch·∫°y h∆°i l√¢u n·∫øu d·ªØ li·ªáu l·ªõn (>100k d√≤ng)\n",
    "    df_new['GPA_Trend_Slope'] = df_new.groupby('MA_SO_SV')['GPA'].transform(\n",
    "        lambda x: x.rolling(window=4, min_periods=2).apply(calculate_slope, raw=False)\n",
    "    )\n",
    "    df_new['GPA_Trend_Slope'] = df_new['GPA_Trend_Slope'].fillna(0)\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 2. NH√ìM BI·∫æN SO S√ÅNH T∆Ø∆†NG ƒê·ªêI (Cohort Comparison)\n",
    "    # ---------------------------------------------------------\n",
    "    print(\"- ƒêang t√≠nh to√°n so s√°nh v·ªõi b·∫°n ƒë·ªìng l·ª©a (Z-Score)...\")\n",
    "    \n",
    "    # Gom nh√≥m theo t·ª´ng k·ª≥ (HOC_KY) ƒë·ªÉ t√≠nh Mean v√† Std c·ªßa k·ª≥ ƒë√≥\n",
    "    semester_stats = df_new.groupby('HOC_KY')['GPA'].agg(['mean', 'std']).reset_index()\n",
    "    semester_stats.columns = ['HOC_KY', 'Sem_Mean_GPA', 'Sem_Std_GPA']\n",
    "    \n",
    "    # Merge l·∫°i v√†o b·∫£ng ch√≠nh\n",
    "    df_new = df_new.merge(semester_stats, on='HOC_KY', how='left')\n",
    "    \n",
    "    # T√≠nh Z-Score: (ƒêi·ªÉm SV - ƒêi·ªÉm TB K·ª≥) / ƒê·ªô l·ªách chu·∫©n K·ª≥\n",
    "    # Z-Score > 0: Gi·ªèi h∆°n m·∫∑t b·∫±ng chung\n",
    "    # Z-Score < 0: K√©m h∆°n m·∫∑t b·∫±ng chung\n",
    "    df_new['GPA_ZScore'] = (df_new['GPA'] - df_new['Sem_Mean_GPA']) / (df_new['Sem_Std_GPA'] + 1e-5) # C·ªông epsilon ƒë·ªÉ tr√°nh chia cho 0\n",
    "    \n",
    "    # X·∫øp h·∫°ng ph·∫ßn trƒÉm trong k·ª≥ (Percentile)\n",
    "    df_new['GPA_Percentile'] = df_new.groupby('HOC_KY')['GPA'].rank(pct=True)\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 3. NH√ìM BI·∫æN T∆Ø∆†NG T√ÅC (Interaction Features)\n",
    "    # ---------------------------------------------------------\n",
    "    print(\"- ƒêang t·∫°o c√°c bi·∫øn t∆∞∆°ng t√°c (Interaction)...\")\n",
    "    \n",
    "    # T∆∞∆°ng t√°c: √Åp l·ª±c n·ª£ m√¥n (S·ªë t√≠n ch·ªâ ch∆∞a qua * S·ªë k·ª≥ ƒë√£ ngh·ªâ)\n",
    "    # Gi·∫£ ƒë·ªãnh df ƒë√£ c√≥ c·ªôt 'Gap_Duration' v√† 'TC_DANGKY', 'TC_HOANTHANH'\n",
    "    if 'Gap_Duration' in df_new.columns and 'TC_DANGKY' in df_new.columns:\n",
    "        # T√≠nh s·ªë t√≠n ch·ªâ r·ªõt trong k·ª≥\n",
    "        df_new['TC_ROT'] = df_new['TC_DANGKY'] - df_new['TC_HOANTHANH']\n",
    "        \n",
    "        # Interaction: Ngh·ªâ h·ªçc nhi·ªÅu + R·ªõt m√¥n nhi·ªÅu -> R·ªßi ro c·ª±c cao\n",
    "        df_new['Risk_Score_Gap_Fail'] = df_new['Gap_Duration'] * df_new['TC_ROT']\n",
    "        \n",
    "        # T·ª∑ l·ªá r·ªõt m√¥n t√≠ch l≈©y (Cumulative Fail Ratio)\n",
    "        df_new['Cum_TC_ROT'] = df_new.groupby('MA_SO_SV')['TC_ROT'].cumsum()\n",
    "        df_new['Cum_TC_DANGKY'] = df_new.groupby('MA_SO_SV')['TC_DANGKY'].cumsum()\n",
    "        df_new['Fail_Ratio_Accumulated'] = df_new['Cum_TC_ROT'] / (df_new['Cum_TC_DANGKY'] + 1e-5)\n",
    "\n",
    "    # D·ªçn d·∫πp: X√≥a c√°c c·ªôt t·∫°m trung gian n·∫øu mu·ªën\n",
    "    cols_to_drop = ['Sem_Mean_GPA', 'Sem_Std_GPA'] \n",
    "    df_new = df_new.drop(columns=[c for c in cols_to_drop if c in df_new.columns])\n",
    "    \n",
    "    print(\"‚úÖ Ho√†n t·∫•t! ƒê√£ th√™m {} bi·∫øn m·ªõi.\".format(len(df_new.columns) - len(df.columns)))\n",
    "    return df_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e7838714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ B·∫Øt ƒë·∫ßu Feature Engineering n√¢ng cao...\n",
      "- ƒêang t√≠nh to√°n xu h∆∞·ªõng h·ªçc t·∫≠p (Trend)...\n",
      "- ƒêang t√≠nh to√°n so s√°nh v·ªõi b·∫°n ƒë·ªìng l·ª©a (Z-Score)...\n",
      "- ƒêang t·∫°o c√°c bi·∫øn t∆∞∆°ng t√°c (Interaction)...\n",
      "‚úÖ Ho√†n t·∫•t! ƒê√£ th√™m 5 bi·∫øn m·ªõi.\n"
     ]
    }
   ],
   "source": [
    "df = generate_advanced_features(df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d9bc20ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "MA_SO_SV",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "HOC_KY",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "CPA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "GPA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "TC_DANGKY",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "TC_HOANTHANH",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "NAM_TUYENSINH",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "PTXT",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "TOHOP_XT",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "DIEM_TRUNGTUYEN",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "DIEM_CHUAN",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "GPA_Last_3_Avg",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "GPA_Volatility_Accumulated",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "GPA_Trend_Slope",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "GPA_ZScore",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "GPA_Percentile",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "c430e5d8-a61e-4e0e-9e2c-629c713b7858",
       "rows": [
        [
         "0",
         "00003e092652",
         "HK1 2023-2024",
         "1.64",
         "1.97",
         "18",
         "15",
         "2023",
         "100",
         "A00",
         "21.32",
         "20.25",
         "1.97",
         "0.0",
         "0.0",
         "-0.670752294415079",
         "0.23515995087432012"
        ],
        [
         "1",
         "00003e092652",
         "HK2 2023-2024",
         "1.53",
         "2.05",
         "18",
         "13",
         "2023",
         "100",
         "A00",
         "21.32",
         "20.25",
         "2.01",
         "0.056568542494923775",
         "0.07999999999999985",
         "-0.5284975849404875",
         "0.3182448494453249"
        ],
        [
         "2",
         "000e15519006",
         "HK1 2021-2022",
         "3.85",
         "3.85",
         "9",
         "9",
         "2021",
         "1",
         "D07",
         "23.84",
         "22.43",
         "3.85",
         "0.0",
         "0.0",
         "3.031224499321682",
         "0.9922034966136399"
        ],
        [
         "3",
         "000e15519006",
         "HK1 2022-2023",
         "2.83",
         "2.98",
         "21",
         "21",
         "2021",
         "1",
         "D07",
         "23.84",
         "22.43",
         "3.415",
         "0.6151828996322964",
         "-0.8700000000000001",
         "1.3157773628460856",
         "0.9063347539713289"
        ],
        [
         "4",
         "000e15519006",
         "HK1 2023-2024",
         "1.5",
         "2.73",
         "20",
         "14",
         "2021",
         "1",
         "D07",
         "23.84",
         "22.43",
         "3.186666666666667",
         "0.5879058881601148",
         "-0.56",
         "0.8863372101355839",
         "0.825662319433885"
        ]
       ],
       "shape": {
        "columns": 16,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MA_SO_SV</th>\n",
       "      <th>HOC_KY</th>\n",
       "      <th>CPA</th>\n",
       "      <th>GPA</th>\n",
       "      <th>TC_DANGKY</th>\n",
       "      <th>TC_HOANTHANH</th>\n",
       "      <th>NAM_TUYENSINH</th>\n",
       "      <th>PTXT</th>\n",
       "      <th>TOHOP_XT</th>\n",
       "      <th>DIEM_TRUNGTUYEN</th>\n",
       "      <th>DIEM_CHUAN</th>\n",
       "      <th>GPA_Last_3_Avg</th>\n",
       "      <th>GPA_Volatility_Accumulated</th>\n",
       "      <th>GPA_Trend_Slope</th>\n",
       "      <th>GPA_ZScore</th>\n",
       "      <th>GPA_Percentile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00003e092652</td>\n",
       "      <td>HK1 2023-2024</td>\n",
       "      <td>1.64</td>\n",
       "      <td>1.97</td>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "      <td>2023</td>\n",
       "      <td>100</td>\n",
       "      <td>A00</td>\n",
       "      <td>21.32</td>\n",
       "      <td>20.25</td>\n",
       "      <td>1.970000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.670752</td>\n",
       "      <td>0.235160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00003e092652</td>\n",
       "      <td>HK2 2023-2024</td>\n",
       "      <td>1.53</td>\n",
       "      <td>2.05</td>\n",
       "      <td>18</td>\n",
       "      <td>13</td>\n",
       "      <td>2023</td>\n",
       "      <td>100</td>\n",
       "      <td>A00</td>\n",
       "      <td>21.32</td>\n",
       "      <td>20.25</td>\n",
       "      <td>2.010000</td>\n",
       "      <td>0.056569</td>\n",
       "      <td>0.08</td>\n",
       "      <td>-0.528498</td>\n",
       "      <td>0.318245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000e15519006</td>\n",
       "      <td>HK1 2021-2022</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.85</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>D07</td>\n",
       "      <td>23.84</td>\n",
       "      <td>22.43</td>\n",
       "      <td>3.850000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.031224</td>\n",
       "      <td>0.992203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000e15519006</td>\n",
       "      <td>HK1 2022-2023</td>\n",
       "      <td>2.83</td>\n",
       "      <td>2.98</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>D07</td>\n",
       "      <td>23.84</td>\n",
       "      <td>22.43</td>\n",
       "      <td>3.415000</td>\n",
       "      <td>0.615183</td>\n",
       "      <td>-0.87</td>\n",
       "      <td>1.315777</td>\n",
       "      <td>0.906335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000e15519006</td>\n",
       "      <td>HK1 2023-2024</td>\n",
       "      <td>1.50</td>\n",
       "      <td>2.73</td>\n",
       "      <td>20</td>\n",
       "      <td>14</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>D07</td>\n",
       "      <td>23.84</td>\n",
       "      <td>22.43</td>\n",
       "      <td>3.186667</td>\n",
       "      <td>0.587906</td>\n",
       "      <td>-0.56</td>\n",
       "      <td>0.886337</td>\n",
       "      <td>0.825662</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       MA_SO_SV         HOC_KY   CPA   GPA  TC_DANGKY  TC_HOANTHANH  \\\n",
       "0  00003e092652  HK1 2023-2024  1.64  1.97         18            15   \n",
       "1  00003e092652  HK2 2023-2024  1.53  2.05         18            13   \n",
       "2  000e15519006  HK1 2021-2022  3.85  3.85          9             9   \n",
       "3  000e15519006  HK1 2022-2023  2.83  2.98         21            21   \n",
       "4  000e15519006  HK1 2023-2024  1.50  2.73         20            14   \n",
       "\n",
       "   NAM_TUYENSINH PTXT TOHOP_XT  DIEM_TRUNGTUYEN  DIEM_CHUAN  GPA_Last_3_Avg  \\\n",
       "0           2023  100      A00            21.32       20.25        1.970000   \n",
       "1           2023  100      A00            21.32       20.25        2.010000   \n",
       "2           2021    1      D07            23.84       22.43        3.850000   \n",
       "3           2021    1      D07            23.84       22.43        3.415000   \n",
       "4           2021    1      D07            23.84       22.43        3.186667   \n",
       "\n",
       "   GPA_Volatility_Accumulated  GPA_Trend_Slope  GPA_ZScore  GPA_Percentile  \n",
       "0                    0.000000             0.00   -0.670752        0.235160  \n",
       "1                    0.056569             0.08   -0.528498        0.318245  \n",
       "2                    0.000000             0.00    3.031224        0.992203  \n",
       "3                    0.615183            -0.87    1.315777        0.906335  \n",
       "4                    0.587906            -0.56    0.886337        0.825662  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f869ed1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CPA',\n",
       " 'GPA',\n",
       " 'TC_DANGKY',\n",
       " 'NAM_TUYENSINH',\n",
       " 'PTXT',\n",
       " 'DIEM_TRUNGTUYEN',\n",
       " 'DIEM_CHUAN',\n",
       " 'GPA_Last_3_Avg',\n",
       " 'GPA_Volatility_Accumulated',\n",
       " 'GPA_Trend_Slope',\n",
       " 'GPA_ZScore',\n",
       " 'GPA_Percentile']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = [\n",
    "    'CPA', 'GPA', 'TC_DANGKY', 'NAM_TUYENSINH',\n",
    "    'PTXT', 'DIEM_TRUNGTUYEN', 'DIEM_CHUAN',\n",
    "    'GPA_Last_3_Avg', 'GPA_Volatility_Accumulated',\n",
    "    'GPA_Trend_Slope', 'GPA_ZScore', 'GPA_Percentile'\n",
    "]\n",
    "target = 'TC_HOANTHANH'\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "df44aaa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    'CPA', 'GPA', 'TC_DANGKY', 'NAM_TUYENSINH',\n",
    "    'PTXT', 'DIEM_TRUNGTUYEN', 'DIEM_CHUAN',\n",
    "    'GPA_Last_3_Avg', 'GPA_Volatility_Accumulated',\n",
    "    'GPA_Trend_Slope', 'GPA_ZScore', 'GPA_Percentile'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "9ca68737",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "features = ['GPA', 'CPA', 'TC_DANGKY', 'DIEM_TRUNGTUYEN', 'DIEM_CHUAN'] \n",
    "target = 'TC_HOANTHANH'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "162eb4a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- K·∫æT QU·∫¢ SO S√ÅNH RMSE ---\n",
      "Baseline RMSE: 6.6387\n",
      "Linear Regression RMSE: 2.7920\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = df[features], df[target]\n",
    "X_valid, y_valid = df[features], df[target]\n",
    "\n",
    "# ==========================================\n",
    "# B∆Ø·ªöC 1: TEST BASELINE (D√πng gi√° tr·ªã trung b√¨nh)\n",
    "# ==========================================\n",
    "y_train_mean = y_train.mean()\n",
    "y_pred_baseline = np.full_like(y_valid, fill_value=y_train_mean)\n",
    "\n",
    "# RMSE Baseline\n",
    "rmse_baseline = np.sqrt(mean_squared_error(y_valid, y_pred_baseline))\n",
    "\n",
    "# ==========================================\n",
    "# B∆Ø·ªöC 2: TRAIN & TEST LINEAR REGRESSION\n",
    "# ==========================================\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# D·ª± b√°o v√† l√†m tr√≤n v√¨ TC_HOANTHANH ph·∫£i l√† s·ªë nguy√™n [cite: 44]\n",
    "y_pred_model = model.predict(X_valid)\n",
    "y_pred_model_int = np.round(y_pred_model).astype(int)\n",
    "\n",
    "# RMSE Model\n",
    "rmse_model = np.sqrt(mean_squared_error(y_valid, y_pred_model_int))\n",
    "\n",
    "print(f\"--- K·∫æT QU·∫¢ SO S√ÅNH RMSE ---\")\n",
    "print(f\"Baseline RMSE: {rmse_baseline:.4f}\")\n",
    "print(f\"Linear Regression RMSE: {rmse_model:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
